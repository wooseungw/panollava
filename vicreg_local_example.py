#!/usr/bin/env python3
"""
VICReg-L (Local VICReg) ì‚¬ìš© ì˜ˆì œ
=====================================

ê¸°ì¡´ ì½”ë“œì— ìµœì†Œí•œì˜ ë³€ê²½ìœ¼ë¡œ VICReg-Lì„ ì ìš©í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
"""

import torch
from panovlm.config import ModelConfig
from panovlm.model import PanoramaVLM
from panovlm.processors.image import PanoramaImageProcessor

def enable_vicreg_local_example():
    """VICReg-Lì„ í™œì„±í™”í•˜ëŠ” ì˜ˆì œ"""
    
    # 1. ModelConfigì—ì„œ VICReg-L í™œì„±í™”
    config = ModelConfig(
        # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
        vision_name="google/siglip-base-patch16-224",
        language_model_name="Qwen/Qwen2.5-0.5B-Instruct",
        resampler_type="mlp",
        latent_dimension=768,
        
        # ê¸°ì¡´ VICReg ì„¤ì •
        vicreg_loss_weight=1.0,
        vicreg_overlap_ratio=0.5,
        
        # VICReg-L í™œì„±í™” ë° ì„¤ì •
        use_vicreg_local=True,           # ğŸ”¥ VICReg-L í™œì„±í™”
        vicreg_local_weight=0.5,         # ì „ì²´ ì†ì‹¤ì—ì„œ VICReg-L ê°€ì¤‘ì¹˜
        vicreg_local_inv_weight=1.0,     # INV ì†ì‹¤ ê°€ì¤‘ì¹˜
        vicreg_local_var_weight=1.0,     # VAR ì†ì‹¤ ê°€ì¤‘ì¹˜  
        vicreg_local_cov_weight=0.01,    # COV ì†ì‹¤ ê°€ì¤‘ì¹˜ (ë³´í†µ ì‘ê²Œ)
        vicreg_local_inv_type="l2",      # "l2" ë˜ëŠ” "cos"
        vicreg_local_gamma=1.0,          # ë¶„ì‚° ì •ê·œí™” ëª©í‘œ
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬ ì„¤ì • (ë©”íƒ€ë°ì´í„° ìƒì„±ì„ ìœ„í•´)
        crop_strategy="e2p",             # e2p ì „ëµì´ ë©”íƒ€ë°ì´í„° ì§€ì›
        fov_deg=90.0
    )
    
    # 2. ëª¨ë¸ ìƒì„±
    model = PanoramaVLM(config=config)
    print(f"âœ… VICReg-L enabled: {model.use_vicreg_local}")
    print(f"   Local weight: {model.vicreg_local_weight}")
    
    # 3. ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œ (ë©”íƒ€ë°ì´í„° ë°˜í™˜ ê¸°ëŠ¥ í¬í•¨)
    processor = PanoramaImageProcessor(
        crop_strategy="e2p", 
        fov_deg=90.0,
        overlap_ratio=0.5
    )
    
    return model, processor, config

def training_example():
    """í›ˆë ¨ì—ì„œ VICReg-L ì‚¬ìš© ì˜ˆì œ"""
    model, processor, config = enable_vicreg_local_example()
    
    # ê°€ìƒ íŒŒë…¸ë¼ë§ˆ ì´ë¯¸ì§€ (ì‹¤ì œë¡œëŠ” PIL Image ë˜ëŠ” ê²½ë¡œ)
    dummy_pano = torch.randn(3, 512, 1024)  # [C, H, W] ERP ì´ë¯¸ì§€
    
    # ì´ë¯¸ì§€ ì²˜ë¦¬ (ë©”íƒ€ë°ì´í„° í¬í•¨)
    pixel_values, view_metadata = processor(dummy_pano, return_metadata=True)
    
    print(f"ğŸ“· Generated {len(view_metadata)} views")
    print(f"   First view metadata: {view_metadata[0] if view_metadata else 'None'}")
    
    # ë°°ì¹˜ ì¤€ë¹„
    batch_size = 2
    pixel_values_batch = pixel_values.unsqueeze(0).repeat(batch_size, 1, 1, 1, 1)
    # [B, V, C, H, W] -> [B*V, C, H, W]
    pixel_values_flat = pixel_values_batch.flatten(0, 1)
    
    # ë©”íƒ€ë°ì´í„°ë„ ë°°ì¹˜ë¡œ í™•ì¥
    metadata_batch = []
    for b in range(batch_size):
        metadata_batch.extend(view_metadata)
    
    # VICReg-Lì´ í¬í•¨ëœ vision ë‹¨ê³„ í›ˆë ¨
    model.train()
    outputs = model(
        pixel_values=pixel_values_flat,
        stage="vision",
        view_metadata=metadata_batch  # ğŸ”¥ ë©”íƒ€ë°ì´í„° ì „ë‹¬
    )
    
    print("\nğŸ¯ Training outputs:")
    print(f"   Total loss: {outputs['loss'].item():.6f}")
    print(f"   VICReg loss: {outputs['vicreg_loss'].item():.6f}")
    
    if 'vicreg_local_loss' in outputs:
        print(f"   VICReg-L loss: {outputs['vicreg_local_loss'].item():.6f}")
        print(f"   VICReg-L pairs: {outputs['vicreg_local_pairs']}")
        print(f"   VICReg-L INV: {outputs['vicreg_local_inv'].item():.6f}")
        print(f"   VICReg-L VAR: {outputs['vicreg_local_var'].item():.6f}")
        print(f"   VICReg-L COV: {outputs['vicreg_local_cov'].item():.6f}")
    else:
        print("   No VICReg-L loss (check metadata or configuration)")

def gradual_migration_example():
    """ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜ˆì œ: ê¸°ì¡´ -> VICReg-L"""
    
    print("=== ë‹¨ê³„ 1: ê¸°ì¡´ VICRegë§Œ ì‚¬ìš© ===")
    config_old = ModelConfig(use_vicreg_local=False)
    model_old = PanoramaVLM(config=config_old)
    print(f"Old model VICReg-L: {model_old.use_vicreg_local}")
    
    print("\n=== ë‹¨ê³„ 2: VICReg + VICReg-L í˜¼í•© (ë‚®ì€ ê°€ì¤‘ì¹˜) ===")  
    config_mixed = ModelConfig(
        use_vicreg_local=True,
        vicreg_local_weight=0.1  # ë‚®ì€ ê°€ì¤‘ì¹˜ë¡œ ì‹œì‘
    )
    model_mixed = PanoramaVLM(config=config_mixed)
    print(f"Mixed model VICReg-L weight: {model_mixed.vicreg_local_weight}")
    
    print("\n=== ë‹¨ê³„ 3: VICReg-L ì£¼ë„ (ë†’ì€ ê°€ì¤‘ì¹˜) ===")
    config_new = ModelConfig(
        use_vicreg_local=True, 
        vicreg_local_weight=1.0,  # ë†’ì€ ê°€ì¤‘ì¹˜
        vicreg_loss_weight=0.5    # ê¸°ì¡´ VICReg ê°€ì¤‘ì¹˜ ê°ì†Œ
    )
    model_new = PanoramaVLM(config=config_new)
    print(f"New model VICReg-L weight: {model_new.vicreg_local_weight}")
    print(f"New model VICReg weight: {model_new.vicreg_loss_weight}")

if __name__ == "__main__":
    print("ğŸš€ VICReg-L Integration Example")
    print("=" * 50)
    
    try:
        print("\nğŸ“– Example 1: Basic VICReg-L Training")
        training_example()
        
        print("\nğŸ“– Example 2: Gradual Migration Strategy")
        gradual_migration_example()
        
        print(f"\nâœ… All examples completed successfully!")
        print("\nğŸ’¡ Key points:")
        print("   - Set use_vicreg_local=True in ModelConfig")
        print("   - Use return_metadata=True in image processor")  
        print("   - Pass view_metadata to model.forward()")
        print("   - Monitor vicreg_local_* metrics in training logs")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()