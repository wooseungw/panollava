# Small-model comparator: InternVL2-2B on AnyRes-E2P

experiment:
  name: "internvl2b_anyres_e2p"
  description: "Lightweight comparator vs CORA on Table 2 split"
  version: "1.0"

environment:
  cuda_visible_devices: "0"
  wandb_project: "panollava-training"

paths:
  runs_dir: "runs"
  csv_train: "data/quic360/train.csv"
  csv_val: "data/quic360/valid.csv"
  csv_test: "data/quic360/test.csv"

models:
  vision_name: "OpenGVLab/InternVL2-2B"  # small panorama-capable VLM
  language_model_name: "OpenGVLab/InternVL2-2B"
  resampler_type: "mlp"
  use_projection_positional_encoding: true
  resampler_config:
    latent_dimension: 2048
    hidden_dim: 2048
    depth: 3
    use_ln: true
    pool_tokens: 256
    pool_type: "avg"

image_processing:
  crop_strategy: "anyres_e2p"
  overlap_ratio: 0.5
  stitching_mode: "concat"
  stitch_target_to_view_width: true
  stitch_interp: "linear"
  fov_deg: 90.0
  use_vision_processor: true
  anyres_max_patches: 9
  normalize: true

training:
  prefix: "internvl2b_anyres_e2p"
  stages: ["vision", "resampler", "finetune"]
  num_workers: 8
  eval_batch_size: 2
  system_msg: "You are a helpful assistant. Describe the panorama image."
  wandb_project: null
  cache_cleanup_interval: 1000
  deepspeed:
    enabled: false
    strategy:
      stage: 2

  stage_configs:
    vision:
      epochs: 2
      lr: 5e-5
      batch_size: 4
      accumulate_grad_batches: 2
      vicreg_loss_weight: 1.0
      vicreg_mode: "pairwise"
      vision_trainable_blocks: 1
      vicreg_similarity_weight: 25.0
      vicreg_variance_weight: 25.0
      vicreg_covariance_weight: 1.0
      debug_vicreg_loss: false
      max_text_length: 32
      data:
        csv_train:
          - "data/quic360/train.csv"
        csv_val:
          - "data/quic360/valid.csv"

    resampler:
      epochs: 1
      lr: 5e-5
      batch_size: 2
      accumulate_grad_batches: 4
      vicreg_loss_weight: 0.0
      vision_trainable_blocks: 0
      max_text_length: 128

    finetune:
      epochs: 1
      lr: 1e-5
      batch_size: 2
      accumulate_grad_batches: 4
      vicreg_loss_weight: 0.0
      vision_trainable_blocks: 0
      max_text_length: 128

generation:
  max_new_tokens: 128

data:
  train: ["data/quic360/train.csv"]
  val: ["data/quic360/valid.csv"]
  csv_test: "data/quic360/test.csv"
  max_text_length: "auto"
  auto_max_text_length_cap: 256

system_messages:
  default: "You are a helpful assistant. Describe the panorama image."

lora:
  use_lora: false  # keep full fine-tuning for small model size
  rank: 8
  alpha: 16
  dropout: 0.1
  target_modules: []
  save_lora_only: false
