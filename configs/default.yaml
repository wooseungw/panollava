# PanoLLaVA Configuration
# 개선된 YAML 기반 설정 파일

# 실험 메타 정보
experiment:
  name: "SLG3_1_latent768_PE"
  description: "PanoLLaVA multi-stage training with improved config system"
  version: "1.0"

# 기본 경로 설정

# 기본 경로 설정
paths:
  runs_dir: "runs"
  csv_train: "data/quic360/train.csv"
  csv_val: "data/quic360/valid.csv"

# 모델 아키텍처 설정 (모든 스테이지에서 공유)
models:
  vision_name: "google/siglip-base-patch16-224"
  language_model_name: "Qwen/Qwen3-0.6B"
  resampler_type: "mlp"  # 리샘플러 세부 설정은 코드에서 자동 결정

# 기본 이미지 처리 설정
image_processing:
  crop_strategy: "e2p"
  image_size: [224, 224]
  overlap_ratio: 0.5
  stitching_mode: "concat"
  stitch_target_to_view_width: true
  stitch_interp: "linear"
  fov_deg: 90.0
  use_vision_processor: true
  anyres_patch_size: 336
  anyres_max_patches: 12
  normalize: true

# 훈련 설정
training:
  prefix: "SQ3_1_latent768_PE"
  stages: ["vision", "resampler", "finetune"]  # 실행할 스테이지들 (순차 실행)
  num_workers: 8  # Reduced from 16 to prevent OOM
  system_msg: "You are a helpful assistant. Describe the panorama image."
  wandb_project: "panollava-training"
  empty_cache_each_step: 1

  # DeepSpeed 설정
  deepspeed:
    enabled: false
    strategy:
      stage: 3

  # 스테이지별 설정 (config.py 구조와 일치)
  stage_configs:
    vision:
      epochs: 5
      lr: 5e-4  # Increased from 1e-5 (50x increase for better convergence)
      batch_size: 16
      accumulate_grad_batches: 4
      vicreg_loss_weight: 1.0
      vicreg_mode: "pairwise"  # Options: "pairwise" (default), "batchwise" (original VICReg)

      # Vision encoder fine-tuning control
      # 0 = freeze all (default), -1 = unfreeze all, N > 0 = unfreeze last N blocks
      vision_trainable_blocks: 2  # Keep vision encoder frozen during VICReg training

      # VICReg hyperparameters (reduce weights for lower loss magnitude)
      vicreg_similarity_weight: 25.0  # Reduced from 25.0
      vicreg_variance_weight: 25.0    # Reduced from 25.0
      vicreg_covariance_weight: 1.0   # Keep as is

      # Enable debug logging to monitor convergence
      debug_vicreg_loss: true  # Set to true only for debugging

      max_text_length: 32

      # 데이터 설정
      data:
        csv_train: "data/quic360/train.csv"
        csv_val: "data/quic360/valid.csv"

    resampler:
      epochs: 1
      lr: 1e-4  # Increased from 2e-6 (50x increase for better convergence)
      batch_size: 1
      accumulate_grad_batches: 2
      vicreg_loss_weight: 0.0
      vision_trainable_blocks: 0  # Can optionally unfreeze last N layers (e.g., 2-4)
      max_text_length: 128

      # 데이터 설정
      data:
        csv_train: "data/quic360/train.csv"
        csv_val: "data/quic360/valid.csv"

    finetune:
      epochs: 1
      lr: 5e-5  # Increased from 2e-6 (25x increase for stable fine-tuning)
      batch_size: 1
      accumulate_grad_batches: 2
      vicreg_loss_weight: 0.0
      vision_trainable_blocks: 0  # Can optionally unfreeze last N layers for end-to-end tuning
      max_text_length: 128

      # 데이터 설정
      data:
        csv_train: "data/quic360/train.csv"
        csv_val: "data/quic360/valid.csv"

# 생성 설정
generation:
  max_new_tokens: 128

# 환경 설정
environment:
  cuda_visible_devices: "1"
  wandb_project: "panollava-training"

# 데이터 설정
data:
  train: ["data/quic360/train.csv"]
  val: ["data/quic360/valid.csv"]
  max_text_length: "auto"
  auto_max_text_length_cap: 512

# 시스템 메시지
system_messages:
  default: "You are a helpful assistant. Describe the panorama image."

# LoRA 설정
lora:
  use_lora: true
  rank: 32
  alpha: 64
  dropout: 0.1
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"
  save_lora_only: false
