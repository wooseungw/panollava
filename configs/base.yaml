# Base Configuration for Panorama VLM Training
# ==============================================

# 모델 설정
model:
  vision_model_name: "google/siglip-base-patch16-224"
  language_model_name: "Qwen/Qwen2-0.5B"
  resampler_type: "mlp"
  latent_dimension: 768
  
  # LoRA 설정 (기본값 - stage별로 override 가능)
  lora:
    enabled: false
    r: 8
    alpha: 16
    dropout: 0.05
    target_modules: null  # auto-detect

# 데이터 설정
data:
  csv_train: "data/quic360/train.csv"
  csv_val: "data/quic360/valid.csv"
  batch_size: 4
  num_workers: 4
  max_txt_len: 512
  
  # 이미지 처리 설정
  image:
    size: [224, 224]
    crop_strategy: "e2p"  # sliding_window | e2p | cubemap | resize | anyres | anyres_max

# 학습 설정
training:
  epochs: 3
  learning_rate: 5e-5
  optimizer: "adamw"
  weight_decay: 0.05
  warmup_ratio: 0.1
  
  # 스케줄러 설정
  scheduler:
    type: "linear_with_warmup"
    warmup_steps: null  # auto-calculate from warmup_ratio
  
  # 정규화 설정
  gradient_clip_val: 0.5
  precision: "16-mixed"

# VICReg Loss 설정
vicreg:
  loss_weight: 1.0
  similarity_weight: 25.0
  variance_weight: 25.0
  covariance_weight: 1.0

# 로깅 및 체크포인트
logging:
  wandb:
    project: "panorama-vlm"
    name: null  # auto-generate
    dir: "./runs"
  
  # 체크포인트 설정
  checkpoint:
    monitor: "val_loss"
    mode: "min"
    save_top_k: 1
    save_last: true
    every_n_epochs: 1
  
  # Early Stopping
  early_stopping:
    patience: 3
    min_delta: 0.001

# 하드웨어 설정
hardware:
  accelerator: "auto"
  devices: "auto"
  precision: "16-mixed"
  deterministic: false
  benchmark: true
  
  # 메모리 관리
  memory:
    auto_adjust_batch_size: true
    pin_memory: true
    persistent_workers: true

# 검증 및 평가 설정
validation:
  check_interval: 0.25  # 25% of epoch
  log_samples: true
  num_samples: 5
  max_new_tokens: 32
  temperature: 0.7