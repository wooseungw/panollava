# Stage 3: End-to-End Fine-tuning with LoRA
# ===========================================

stage: "finetune"

# 모델 설정 오버라이드 - LoRA 활성화
model:
  lora:
    enabled: true
    r: 16              # Fine-tuning은 더 높은 rank
    alpha: 32          # alpha = 2 * r
    dropout: 0.1       # 더 높은 dropout으로 정규화
    target_modules: null  # auto-detect

# 학습 설정 - Fine-tuning 최적화
training:
  epochs: 3
  learning_rate: 2e-4  # LoRA는 상대적으로 높은 학습률 가능
  optimizer: "adamw"
  weight_decay: 0.01   # LoRA는 낮은 weight decay
  warmup_ratio: 0.05   # 짧은 warmup
  
  scheduler:
    type: "cosine_with_warmup"
    warmup_steps: null

# VICReg Loss는 Fine-tuning에서 비활성화
vicreg:
  loss_weight: 0.0  # Fine-tuning에서는 AR loss만 사용

# 데이터 설정
data:
  batch_size: 2      # Fine-tuning은 메모리 사용량이 높아 작은 배치
  num_workers: 4
  max_txt_len: 128   # 최대 텍스트 길이 사용

# 로깅 설정
logging:
  wandb:
    name: "finetune-lora-stage"
  
  # Fine-tuning은 신중한 early stopping
  early_stopping:
    patience: 5
    min_delta: 0.001

# 검증 설정
validation:
  check_interval: 0.2   # 더 빈번한 검증 (5번 per epoch)
  log_samples: true
  num_samples: 5
  max_new_tokens: 48    # 더 긴 생성
  temperature: 0.7

# 하드웨어 설정
hardware:
  precision: "16-mixed"
  
  # Fine-tuning은 더 많은 메모리 필요
  memory:
    auto_adjust_batch_size: true
    pin_memory: true
    persistent_workers: false  # 메모리 절약

# LoRA 전용 설정
lora_config:
  save_adapter_only: true
  adapter_name: "panorama_vlm_adapter"
  merge_and_unload: false  # 어댑터만 저장