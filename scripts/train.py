# coding: utf-8
"""
Panorama-VLM Training (Config-only)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- ë‹¨ì¼ config.json ì—ì„œë§Œ ëª¨ë“  ì„¤ì •ì„ ì½ìŒ (CLI ì˜¤ë²„ë¼ì´ë“œ ì—†ìŒ)
- stages:
    â€¢ "training.default_stage": ë‹¨ì¼ ìŠ¤í…Œì´ì§€ ì‹¤í–‰
    â€¢ "training.stages": ["vision","resampler","finetune"] ê°™ì´ ì—¬ëŸ¬ ìŠ¤í…Œì´ì§€ ìˆœì°¨ ì‹¤í–‰
"""

import os
import argparse
# Silence HF tokenizers fork/parallelism warnings and avoid deadlocks
os.environ.setdefault("TOKENIZERS_PARALLELISM", "false")

# HuggingFace ìºì‹œ ìµœì í™” ì„¤ì • (ë©”ëª¨ë¦¬ ì ˆì•½)
os.environ.setdefault("HF_HUB_DISABLE_PROGRESS_BARS", "1")
os.environ.setdefault("TRANSFORMERS_NO_ADVISORY_WARNINGS", "1")
os.environ.setdefault("HF_HUB_DISABLE_SYMLINKS_WARNING", "1")

import sys
import json
import time
import gc
import shutil
import subprocess
import logging
from pathlib import Path
from typing import Dict, Any, Optional
from copy import deepcopy
from dataclasses import dataclass

import torch
torch.set_float32_matmul_precision("high")

import lightning as pl
from lightning.pytorch.loggers import WandbLogger
from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint
from lightning.pytorch.tuner import Tuner

try:
    import yaml  # type: ignore
except Exception:  # pragma: no cover - optional dependency for YAML configs
    yaml = None

# Plot ì €ì¥ì„ ìœ„í•œ matplotlib (ì„ íƒì )
try:
    import matplotlib
    matplotlib.use('Agg')  # GUI ì—†ì´ ì‚¬ìš©
    import matplotlib.pyplot as plt
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    MATPLOTLIB_AVAILABLE = False

# â”€â”€ ë‚´ë¶€ ëª¨ë“ˆ ---------------------------------------------------------------
from panovlm.dataset   import VLMDataModule
from panovlm.models.model import PanoramaVLM
from panovlm.utils     import *
from panovlm.config    import ModelConfig, PanoVLMConfig
from panovlm.runtime import (
    StageManager,
    canonical_stage_name,
    ModelFactory,
    load_runtime_config,
)
# ----------------------------------------------------------------------------

# â”€â”€ ë¡œê¹… ì„¤ì • ---------------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(message)s",
    handlers=[logging.StreamHandler(sys.stdout), logging.FileHandler("training.log")]
)
logger = logging.getLogger("panovlm.train")
SCRIPT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SCRIPT_DIR.parent
EVAL_SCRIPT_PATH = SCRIPT_DIR / "eval.py"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Experiment naming helpers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _short_id_from_model_path(model_name: Optional[str], max_len: int = 12, *, siglip_include_patch_res: bool = False) -> str:
    """Extract a compact identifier from a HF-style model name.

    Examples:
      - "google/siglip2-so400m-patch16-256" -> "siglip2"
      - "Qwen/Qwen3-0.6B" -> "Qwen3"
    """
    if not model_name:
        return "model"
    base = str(model_name).split("/")[-1]
    base_lower = base.lower()

    # Special-case SigLIP family: keep first two tokens; optionally add _pXX_YYY
    if base_lower.startswith("siglip"):
        parts = base.split("-")
        first = parts[0] if parts else "siglip"
        second = parts[1] if len(parts) > 1 else None
        core = first if not second else f"{first}-{second}"

        if siglip_include_patch_res and len(parts) > 2:
            import re as _re
            patch_num = None
            res_num = None
            for p in parts[2:]:
                pl = p.lower()
                m = _re.match(r"patch(\d+)", pl)
                if m:
                    patch_num = m.group(1)
                elif pl.isdigit():
                    res_num = pl
            if patch_num and res_num:
                core = f"{core}_p{patch_num}_{res_num}"
        return core

    # Generic fallback: first token before '-' or '_' and keep alnum prefix
    token = base.split("-")[0].split("_")[0]
    import re as _re
    m = _re.match(r"([A-Za-z]+\d+)", token)
    if m:
        token = m.group(1)
    token = token[:max_len]
    return token


def _compute_experiment_name(cfg: Dict[str, Any], crop_strategy: Optional[str] = None) -> str:
    """Build a readable experiment name from config components unless explicitly provided.

    Pattern: {VISION}_{LM}_{RESAMPLER}_{CROP}{_PE}
    - VISION: short id from models.vision_name
    - LM:     short id from models.language_model_name
    - RESAMPLER: models.resampler_type (fallback models.resampler)
    - CROP:   image_processing.crop_strategy, '_' -> '-'
    - PE:     append '_PE' if models.use_projection_positional_encoding is True
    """
    exp_cfg = cfg.get("experiment", {}) or {}

    name_from_cfg = exp_cfg.get("name")
    auto_flag = bool(exp_cfg.get("auto_name", False))
    if isinstance(name_from_cfg, str) and name_from_cfg.strip() and name_from_cfg.strip().lower() not in {"auto", "{auto}"} and not auto_flag:
        return name_from_cfg.strip()
    # Legacy fallback: training.prefix (unless auto_name is explicitly requested)
    if (not name_from_cfg or not str(name_from_cfg).strip() or str(name_from_cfg).strip().lower() in {"auto", "{auto}"}) and not auto_flag:
        legacy_prefix = (cfg.get("training", {}) or {}).get("prefix")
        if isinstance(legacy_prefix, str) and legacy_prefix.strip():
            return legacy_prefix.strip()

    # Compose from components
    models_cfg = cfg.get("models", {}) or {}
    vision_full = models_cfg.get("vision_name")
    lm_full = models_cfg.get("language_model_name")
    resampler = models_cfg.get("resampler_type") or models_cfg.get("resampler", "mlp")
    crop = crop_strategy or (cfg.get("image_processing", {}) or {}).get("crop_strategy", "e2p")
    crop_short = str(crop).replace("_", "-")
    use_pe = bool(models_cfg.get("use_projection_positional_encoding", False))

    siglip_inc = bool((cfg.get("experiment", {}) or {}).get("siglip_include_patch_res", False))
    vision_short = _short_id_from_model_path(vision_full, max_len=12, siglip_include_patch_res=siglip_inc)
    lm_short = _short_id_from_model_path(lm_full, max_len=12)

    parts = [vision_short, lm_short, resampler, crop_short]
    if use_pe:
        parts.append("PE")
    exp_name = "_".join(parts)

    # Sanitize to filesystem-friendly name
    exp_name = exp_name.replace(" ", "_")
    # Keep only [A-Za-z0-9_\-]
    import re as _re
    exp_name = _re.sub(r"[^A-Za-z0-9_\-]", "", exp_name)
    return exp_name

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LightningModule
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class VLMModule(pl.LightningModule):
    """Panorama VLM Lightning ë˜í¼ (stage-aware)"""

    def __init__(self, *, stage: str, model_config: ModelConfig, lr: float,
                 use_lora_cfg: Dict[str, Any], pretrained_dir: Optional[str] = None,
                 vision_trainable_blocks: int = 0, cache_cleanup_interval: int = 1000):
        super().__init__()
        
        # ModelConfigëŠ” ë³„ë„ ì €ì¥ (ì§ë ¬í™” ë¶ˆê°€ëŠ¥í•  ìˆ˜ ìˆìŒ)
        self.model_config: ModelConfig = model_config
        
        # Lightning ê¶Œì¥ ë°©ì‹: ì´ˆê¸°í™” ì‹œì ì— ëª¨ë“  hparams ì €ì¥
        # ì²´í¬í¬ì¸íŠ¸ ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•˜ì—¬ í•œ ë²ˆì— ì €ì¥
        # Note: max_text_lengthëŠ” VLMDataModuleì—ì„œ ê´€ë¦¬í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì œì™¸ (Lightning hparams ì¶©ëŒ ë°©ì§€)
        checkpoint_metadata = {
            # í›ˆë ¨ ì„¤ì •
            "stage": stage,
            "lr": lr,
            "vision_trainable_blocks": vision_trainable_blocks,
            "cache_cleanup_interval": cache_cleanup_interval,
            "use_lora": bool(use_lora_cfg.get("use_lora", False)),
            "lora_rank": use_lora_cfg.get("rank", 16),
            "lora_alpha": use_lora_cfg.get("alpha", 32),
            "lora_dropout": use_lora_cfg.get("dropout", 0.1),
            "pretrained_dir": pretrained_dir,
            # ëª¨ë¸ ì„¤ì • (ë³µì›ì— í•„ìš”)
            "vision_name": model_config.vision_name,
            "language_model_name": model_config.language_model_name,
            "resampler_type": model_config.resampler_type,
            "latent_dimension": model_config.latent_dimension,
            "vicreg_loss_weight": model_config.vicreg_loss_weight,
            # Save model-specific overlap under distinct key to avoid Lightning merging
            # conflicts when DataModule also exposes an 'overlap_ratio' that may be
            # intentionally different. PanoramaVLM.from_checkpoint will accept both.
            "model_overlap_ratio": model_config.overlap_ratio,
            # max_text_lengthëŠ” VLMDataModuleì˜ hparamsì— ì´ë¯¸ ì €ì¥ë¨ (ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ ì œì™¸)
        }
        self.save_hyperparameters(checkpoint_metadata)
        
        # í¸ì˜ì„±ì„ ìœ„í•œ ì†ì„±ë“¤
        self.lr = lr
        self.learning_rate = lr  # Lightning Tunerë¥¼ ìœ„í•œ ì†ì„±
        self.vision_trainable_blocks = vision_trainable_blocks
        self.cache_cleanup_interval = cache_cleanup_interval

        # ëª¨ë¸ ìƒì„± ìš°ì„ ìˆœìœ„: pretrained_dir(.ckpt ë˜ëŠ” HF ë””ë ‰í† ë¦¬) > scratch
        self.model_factory = ModelFactory(self.model_config)

        if pretrained_dir and os.path.isdir(pretrained_dir):
            logger.info(f"ğŸ§© Loading from pretrained dir: {pretrained_dir}")
            try:
                self.model = self.model_factory.load_pretrained_dir(pretrained_dir)
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to load pretrained dir ({pretrained_dir}): {e}. Falling back to scratch init.")
                self.model = self.model_factory.build()
        elif pretrained_dir and os.path.isfile(pretrained_dir) and str(pretrained_dir).endswith('.ckpt'):
            logger.info(f"ğŸ§© Loading from checkpoint file: {pretrained_dir}")
            try:
                self.model = self.model_factory.load_checkpoint(pretrained_dir)
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to load checkpoint file ({pretrained_dir}): {e}. Falling back to scratch init.")
                self.model = self.model_factory.build()
        else:
            self.model = self.model_factory.build()

        # stage ê²€ì¦/ë§¤í•‘
        try:
            self._stage_key = canonical_stage_name(stage)
        except ValueError as exc:
            raise ValueError(str(exc)) from None
        if stage != self._stage_key:
            logger.info(f"Stage alias resolved: '{stage}' â†’ '{self._stage_key}'")

        # LoRA ì„¤ì • (finetuneì—ì„œë§Œ ì ìš©)
        self.use_lora: bool = bool(use_lora_cfg.get("use_lora", False))
        if self.use_lora and self._stage_key == "finetune":
            logger.info("Setting up LoRA for finetune stage...")
            lora_kwargs = {
                "lora_r": use_lora_cfg.get("rank", 16),
                "lora_alpha": use_lora_cfg.get("alpha", 32),
                "lora_dropout": use_lora_cfg.get("dropout", 0.1),
                "target_modules": use_lora_cfg.get("target_modules", None),
            }
            ok = self.model.setup_lora_for_finetune(**lora_kwargs)
            if ok:
                logger.info(f"âœ“ LoRA setup completed: {lora_kwargs}")
            else:
                logger.warning("âš  LoRA setup failed, continue with full finetune")
        elif self.use_lora and self._stage_key != "finetune":
            logger.warning(f"âš  LoRAëŠ” finetune ë‹¨ê³„ì—ì„œë§Œ í™œì„±í™”ë©ë‹ˆë‹¤. (í˜„ì¬: {stage}) â†’ ë¬´ì‹œ")

        # stageë³„ ë™ê²°/í•´ì œ
        self._unfreeze_for_stage(self._stage_key, vision_trainable_blocks=self.vision_trainable_blocks)
        
        logger.info(f"âœ“ VLMModule ì´ˆê¸°í™” ì™„ë£Œ (stage={self._stage_key}, LoRA={self.use_lora})")

    # â”€â”€ Lightning í‘œì¤€ ë©”ì„œë“œë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def forward(self, **batch):
        return self.model(stage=self._stage_key, **batch)
    # VLMModule ë‚´ë¶€: gradient checkpointingì€ fit ì‹œì‘ ì‹œ 1íšŒë§Œ í™œì„±í™”
    def on_fit_start(self) -> None:
        if hasattr(self.model, 'gradient_checkpointing_enable'):
            try:
                self.model.gradient_checkpointing_enable()
                logger.info("âœ“ Gradient checkpointing enabled (once on fit start)")
            except Exception as e:
                logger.warning(f"âš ï¸ Gradient checkpointing enable failed: {e}")

    # VLMModule ë‚´ë¶€: OOM ì‹œ ëª¨ë“  ë­í¬ì—ì„œ '0-loss'ë¥¼ ë°˜í™˜í•´ ìŠ¤í… ëŒ€ì¹­ ìœ ì§€ (None ê¸ˆì§€)
    def training_step(self, batch, batch_idx):
        try:
            out = self(**batch)
            loss = out["loss"]

            bs = None
            try:
                if isinstance(batch.get("pixel_values"), torch.Tensor):
                    bs = batch["pixel_values"].size(0)
            except Exception:
                pass

            if not torch.isfinite(loss):
                logger.error(f"Non-finite loss at step {self.global_step}: {loss}")
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                # ëŒ€ì¹­ ìŠ¤í… ì²˜ë¦¬
                return torch.tensor(0.0, device=self.device, requires_grad=True)

            kw = dict(prog_bar=True, sync_dist=True)
            if bs is not None:
                kw["batch_size"] = bs
            self.log("loss", loss, **kw)

            if "vicreg_loss" in out:
                self.log("train_vicreg_loss", out["vicreg_loss"], prog_bar=False, sync_dist=False, **({"batch_size": bs} if bs else {}))
            if "ar_loss" in out:
                self.log("train_ar_loss", out["ar_loss"], prog_bar=False, sync_dist=False, **({"batch_size": bs} if bs else {}))

            if self.trainer.logger is not None and batch_idx % 10 == 0:
                self.trainer.logger.log_metrics({
                    "train_loss": float(loss.detach().cpu()),
                    "learning_rate": self.trainer.optimizers[0].param_groups[0]["lr"],
                    "global_step": self.global_step
                }, step=self.global_step)

            # ì£¼ê¸°ì  ìºì‹œ ì •ë¦¬ (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€) - ì„¤ì • ê°€ëŠ¥
            if self.cache_cleanup_interval > 0 and batch_idx % self.cache_cleanup_interval == 0 and torch.cuda.is_available():
                torch.cuda.empty_cache()
                gc.collect()

            return loss

        except RuntimeError as e:
            if "out of memory" in str(e).lower():
                logger.error(f"OOM in training step {self.global_step}")
                # ì ê·¹ì  ì •ë¦¬
                try:
                    for k in list(batch.keys()):
                        if torch.is_tensor(batch[k]):
                            del batch[k]
                except Exception:
                    pass
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    torch.cuda.synchronize()
                gc.collect()
                # ëª¨ë“  ë­í¬ ë™ê¸°í™” í›„ 0-loss ë°˜í™˜(ìŠ¤í… ëŒ€ì¹­)
                try:
                    self.trainer.strategy.barrier()
                except Exception:
                    pass
                return torch.tensor(0.0, device=self.device, requires_grad=True)
            else:
                logger.error(f"Runtime error in training step {self.global_step}: {e}")
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                import traceback
                logger.error("Traceback:\n" + traceback.format_exc())
                # ìŠ¤í… ëŒ€ì¹­ ìœ ì§€
                return torch.tensor(0.0, device=self.device, requires_grad=True)
        except Exception as e:
            logger.error(f"Unexpected error in training step {self.global_step}: {e}")
            import traceback
            logger.error("Traceback:\n" + traceback.format_exc())
            # ìŠ¤í… ëŒ€ì¹­ ìœ ì§€
            return torch.tensor(0.0, device=self.device, requires_grad=True)

    # VLMModule ë‚´ë¶€: ê²€ì¦ë„ ë™ì¼í•˜ê²Œ None ê¸ˆì§€(ëŒ€ì¹­ ìŠ¤í… ìœ ì§€)
    def validation_step(self, batch, batch_idx):
        try:
            if batch_idx == 0:
                logger.info(f"[VAL] First validation batch keys: {list(batch.keys())}")
                if "pixel_values" in batch:
                    logger.info(f"[VAL] pixel_values shape: {batch['pixel_values'].shape}")

            out = self(**batch)
            if "loss" not in out:
                logger.error(f"[VAL] No 'loss' key in model output. Keys: {list(out.keys())}")
                return torch.tensor(0.0, device=self.device, requires_grad=True)  # ìŠ¤ì¹¼ë¼ í…ì„œ ë°˜í™˜

            loss = out["loss"]

            if not torch.isfinite(loss):
                logger.warning(f"[VAL] Non-finite val loss at step {batch_idx}: {loss}")
                return torch.tensor(0.0, device=self.device, requires_grad=True)  # ìŠ¤ì¹¼ë¼ í…ì„œ ë°˜í™˜

            kw = dict(prog_bar=True, sync_dist=True, on_epoch=True, on_step=False)
            self.log("val_loss", loss, **kw)

            if "vicreg_loss" in out:
                self.log("val_vicreg_loss", out["vicreg_loss"], prog_bar=False, sync_dist=False, on_epoch=True, on_step=False)
            if "ar_loss" in out:
                self.log("val_ar_loss", out["ar_loss"], prog_bar=False, sync_dist=False, on_epoch=True, on_step=False)

            return loss

        except RuntimeError as e:
            if "out of memory" in str(e).lower():
                logger.error(f"[VAL] OOM in validation step {batch_idx}")
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                gc.collect()
                try:
                    self.trainer.strategy.barrier()
                except Exception:
                    pass
                return torch.tensor(0.0, device=self.device, requires_grad=True)  # ìŠ¤ì¹¼ë¼ í…ì„œ ë°˜í™˜
            else:
                logger.error(f"[VAL] Runtime error in validation step {batch_idx}: {e}")
                import traceback
                logger.error("Traceback:\n" + traceback.format_exc())
                return torch.tensor(0.0, device=self.device, requires_grad=True)  # ìŠ¤ì¹¼ë¼ í…ì„œ ë°˜í™˜
        except Exception as e:
            logger.error(f"[VAL] Error in validation step {batch_idx}: {e}")
            import traceback
            logger.error("Traceback:\n" + traceback.format_exc())
            return torch.tensor(0.0, device=self.device, requires_grad=True)  # ìŠ¤ì¹¼ë¼ í…ì„œ ë°˜í™˜

    def on_validation_epoch_end(self) -> None:
        try:
            if self.trainer is None:
                return
            val_loss = self.trainer.callback_metrics.get("val_loss")
            if val_loss is not None:
                try:
                    val_loss_value = float(val_loss)
                except (TypeError, ValueError):
                    val_loss_value = val_loss
                logger.info(f"[VAL][Epoch {self.current_epoch}] mean loss: {val_loss_value:.6f}" if isinstance(val_loss_value, float)
                            else f"[VAL][Epoch {self.current_epoch}] mean loss: {val_loss_value}")
        except Exception as e:
            logger.warning(f"[VAL] Failed to log epoch summary: {e}")

    # â”€â”€ ë‚´ë¶€ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _set_vision_trainable_blocks(self, num_blocks: int = 0):
        """Vision encoderì˜ ë§ˆì§€ë§‰ Nê°œ ë¸”ë¡ë§Œ í•™ìŠµ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •

        Args:
            num_blocks: í•™ìŠµí•  ë§ˆì§€ë§‰ ë¸”ë¡ ìˆ˜
                       0 = ì „ì²´ freeze (ê¸°ë³¸ê°’)
                       -1 = ì „ì²´ unfreeze
                       N > 0 = ë§ˆì§€ë§‰ Nê°œ ë¸”ë¡ë§Œ unfreeze
        """
        vision = getattr(self.model, "vision_backbone", None)
        if vision is None:
            logger.warning("âš ï¸ vision_backbone not found")
            return

        # VisionBackbone wraps the actual encoder in .encoder attribute
        # Get the actual vision encoder (SigLIP, CLIP, etc.)
        encoder = getattr(vision, "encoder", vision)

        layers = None

        # Try encoder.encoder.layers (SigLIP: SiglipVisionTransformer.encoder.layers)
        if hasattr(encoder, "encoder") and hasattr(encoder.encoder, "layers"):
            layers = list(encoder.encoder.layers)
        # Try encoder.vision_model.encoder.layers (CLIP structure)
        elif hasattr(encoder, "vision_model"):
            vision_model = encoder.vision_model
            if hasattr(vision_model, "encoder") and hasattr(vision_model.encoder, "layers"):
                layers = list(vision_model.encoder.layers)
        # Try encoder.layers (some other architectures)
        elif hasattr(encoder, "layers"):
            layers = list(encoder.layers)

        if layers is None or len(layers) == 0:
            logger.warning(f"âš ï¸ Could not find layers in vision encoder structure: {type(vision)}")
            logger.debug(f"Available attributes: {dir(vision)}")
            return

        total_layers = len(layers)

        if num_blocks == -1:
            # Unfreeze all layers
            for layer in layers:
                layer.requires_grad_(True)
            logger.info(f"âœ“ All {total_layers} vision encoder layers unfrozen")
        elif num_blocks > 0:
            # Unfreeze last N blocks
            num_blocks = min(num_blocks, total_layers)
            for layer in layers[-num_blocks:]:
                layer.requires_grad_(True)
            logger.info(f"âœ“ Last {num_blocks}/{total_layers} vision encoder layers unfrozen")
        else:
            logger.info(f"âœ“ All {total_layers} vision encoder layers remain frozen")
            
    def _unfreeze_for_stage(self, stage: str, vision_trainable_blocks: int = 0):
        """ê° stageì— ë§ê²Œ íŒŒë¼ë¯¸í„°ë¥¼ freeze/unfreeze

        Args:
            stage: í•™ìŠµ ë‹¨ê³„ ("vision", "resampler", "finetune")
            vision_trainable_blocks: Vision encoderì—ì„œ í•™ìŠµí•  ë¸”ë¡ ìˆ˜
                                    0 = ì „ì²´ freeze (ê¸°ë³¸ê°’)
                                    -1 = ì „ì²´ unfreeze
                                    N > 0 = ë§ˆì§€ë§‰ Nê°œ ë¸”ë¡ unfreeze
        """
        # ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ freezeí•œ ë’¤, í•„ìš”í•œ ë¶€ë¶„ë§Œ unfreeze
        self.model.requires_grad_(False)

        if stage == "vision":
            # VICReg stage: Vision Encoder (optional partial) â†’ Resampler (trainable) â†’ VICReg Projector (trainable)
            # Resampler learns to produce meaningful representations via contrastive learning

            # Optionally unfreeze vision encoder layers
            if vision_trainable_blocks != 0:
                self._set_vision_trainable_blocks(vision_trainable_blocks)

            # Always unfreeze resampler and vicreg_projector
            if hasattr(self.model, "resampler"):
                self.model.resampler.requires_grad_(True)
                logger.info("âœ“ Resampler unfrozen for VICReg training")
            if hasattr(self.model, "vicreg_projector"):
                self.model.vicreg_projector.requires_grad_(True)
                logger.info("âœ“ VICReg projector unfrozen")
            else:
                logger.warning("âš ï¸ vicreg_projector not found - vision stage may not train properly")

            if vision_trainable_blocks == 0:
                logger.info("âœ“ Stage 1: Resampler + VICReg projector trainable (vision encoder fully frozen)")
            else:
                logger.info(f"âœ“ Stage 1: Vision encoder (partial) + Resampler + VICReg projector trainable")
        elif stage == "resampler":
            # Resampler stage: Optionally unfreeze more vision layers, always unfreeze resampler + projection

            # Optionally unfreeze vision encoder layers
            if vision_trainable_blocks != 0:
                self._set_vision_trainable_blocks(vision_trainable_blocks)

            # Always unfreeze resampler and projection
            self.model.resampler.requires_grad_(True)
            self.model.vision_to_language_projection.requires_grad_(True)

            if vision_trainable_blocks == 0:
                logger.info("âœ“ Stage 2: Resampler + Projection unfrozen (vision encoder frozen)")
            else:
                logger.info(f"âœ“ Stage 2: Vision encoder (partial) + Resampler + Projection unfrozen")
        elif stage == "finetune":
            # Finetune stage: Optionally unfreeze vision layers, always unfreeze resampler + projection

            # Optionally unfreeze vision encoder layers
            if vision_trainable_blocks != 0:
                self._set_vision_trainable_blocks(vision_trainable_blocks)

            # Always unfreeze resampler and projection
            self.model.resampler.requires_grad_(True)
            self.model.vision_to_language_projection.requires_grad_(True)

            # LMì€ í•­ìƒ freeze (LoRA ì‚¬ìš© ì—¬ë¶€ì™€ ë¬´ê´€)
            for p in self.model.language_model.parameters():
                p.requires_grad = False

            if vision_trainable_blocks == 0:
                logger.info("âœ“ Stage 3: Resampler + Projection unfrozen (vision encoder frozen, LM frozen/LoRA)")
            else:
                logger.info(f"âœ“ Stage 3: Vision encoder (partial) + Resampler + Projection unfrozen (LM frozen/LoRA)")

        trainable = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        total = sum(p.numel() for p in self.model.parameters())
        logger.info(f"Trainable parameters: {trainable:,}/{total:,} ({trainable/total:.1%})")


    def configure_optimizers(self):
        """íŒŒë…¸ë¼ë§ˆ ì ì‘ì„ ìœ„í•œ ì°¨ë³„í™”ëœ í•™ìŠµë¥  ì ìš©"""
        # íŒŒë¼ë¯¸í„° ê·¸ë£¹ ë¶„ë¦¬
        vision_params = []
        resampler_params = []
        projection_params = []
        lm_params = []
        other_params = []
        
        for name, param in self.named_parameters():
            if not param.requires_grad:
                continue
                
            if 'vision_encoder' in name:
                vision_params.append(param)
            elif 'resampler' in name:
                resampler_params.append(param)
            elif 'vision_to_language_projection' in name or 'vicreg_projector' in name:
                projection_params.append(param)
            elif 'language_model' in name:
                lm_params.append(param)
            else:
                other_params.append(param)
        
        # ê¸°ë³¸ í•™ìŠµë¥  (LR Finderê°€ ì—…ë°ì´íŠ¸í•  ìˆ˜ ìˆìŒ)
        base_lr = getattr(self, 'learning_rate', self.hparams.lr)
        
        # íŒŒë¼ë¯¸í„° ê·¸ë£¹ë³„ ì°¨ë³„í™”ëœ í•™ìŠµë¥ 
        param_groups = []
        if vision_params:
            param_groups.append({
                'params': vision_params, 
                'lr': base_lr,  # visionì€ 10ë°° ë‚®ì€ í•™ìŠµë¥ 
                'weight_decay': 0.01
            })
        if resampler_params:
            param_groups.append({
                'params': resampler_params, 
                'lr': base_lr,  # ê¸°ë³¸ í•™ìŠµë¥ 
                'weight_decay': 0.05
            })
        if projection_params:
            param_groups.append({
                'params': projection_params, 
                'lr': base_lr,  # ê¸°ë³¸ í•™ìŠµë¥ 
                'weight_decay': 0.05
            })
        if lm_params:
            param_groups.append({
                'params': lm_params, 
                'lr': base_lr,  # LMì€ ì ˆë°˜ í•™ìŠµë¥ 
                'weight_decay': 0.01
            })
        if other_params:
            param_groups.append({
                'params': other_params, 
                'lr': base_lr,
                'weight_decay': 0.05
            })
        
        optimizer = torch.optim.AdamW(param_groups, betas=(0.9, 0.98), eps=1e-8)
        
        logger.info(f"Optimizer groups: Vision({len(vision_params)} params, lr={base_lr*0.1}), "
                   f"Resampler({len(resampler_params)} params, lr={base_lr}), "
                   f"Projection({len(projection_params)} params, lr={base_lr})")
        
        # ìŠ¤ì¼€ì¤„ëŸ¬
        try:
            from transformers import get_linear_schedule_with_warmup
            steps_per_epoch = len(self.trainer.datamodule.train_dataloader())
            total_steps = steps_per_epoch * self.trainer.max_epochs
            warmup_steps = max(1, int(0.1 * total_steps))
            sch = get_linear_schedule_with_warmup(optimizer, warmup_steps, total_steps)
            logger.info(f"âœ“ Scheduler: warmup {warmup_steps}, total {total_steps}")
            return [optimizer], [{"scheduler": sch, "interval": "step"}]
        except Exception as e:
            logger.warning(f"Scheduler init failed: {e}; Using optimizer only.")
            return optimizer


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì½œë°±: ê°„ë‹¨ ëª¨ë‹ˆí„°ë§ ë° ë©”íƒ€ë°ì´í„° ê´€ë¦¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class MetadataCallback(pl.Callback):
    """ì²´í¬í¬ì¸íŠ¸ì™€ í•¨ê»˜ ë©”íƒ€ë°ì´í„° ë° êµ¬ì„± íŒŒì¼ì„ ì €ì¥í•˜ê³  ì‹¬ë³¼ë¦­ ë§í¬ë¥¼ ê´€ë¦¬"""

    def __init__(self, ckpt_dir: str, metadata: Dict[str, Any], config_path: Optional[str] = None):
        self.ckpt_dir = Path(ckpt_dir)
        self.metadata = metadata
        self.meta_path = self.ckpt_dir / "checkpoint_metadata.json"
        self.config_path = Path(config_path).expanduser().resolve() if config_path else None
        self._config_copied = False

        if self.config_path:
            self.metadata.setdefault("config", {})
            self.metadata["config"]["source_path"] = str(self.config_path)
            self.metadata["config"]["saved_filename"] = "config.yaml"

        self._ensure_config_copy()

    def _ensure_config_copy(self) -> None:
        """Copy the YAML config into the checkpoint directory for downstream use."""
        if not self.config_path or self._config_copied:
            return

        try:
            if not self.config_path.exists():
                logger.warning(f"âš ï¸ Config file does not exist, skip copy: {self.config_path}")
                return

            target_path = self.ckpt_dir / "config.yaml"
            if target_path.exists():
                # Skip copying if the target already points to the same file contents
                try:
                    if target_path.resolve() == self.config_path:
                        self._config_copied = True
                        return
                except Exception:
                    pass

            shutil.copy2(self.config_path, target_path)
            self._config_copied = True
            logger.debug(f"âœ“ Config copied to checkpoint dir: {target_path}")
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to copy config file to checkpoint dir: {e}")

    def on_save_checkpoint(self, trainer, pl_module, checkpoint):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹œ ë©”íƒ€ë°ì´í„°ë„ í•¨ê»˜ ì €ì¥"""
        if not self._config_copied:
            self._ensure_config_copy()

        try:
            # í˜„ì¬ í•™ìŠµ ìƒíƒœ ì •ë³´ ì¶”ê°€
            full_meta = {
                **self.metadata,
                "epoch_info": {
                    "current_epoch": trainer.current_epoch,
                    "global_step": trainer.global_step,
                    "val_loss": float(trainer.callback_metrics.get("val_loss", 0)),
                },
                "checkpoint_info": {
                    "created_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
                    "pytorch_lightning_version": pl.__version__,
                    "torch_version": torch.__version__,
                }
            }
            
            # JSON ì €ì¥
            with self.meta_path.open("w", encoding="utf-8") as f:
                json.dump(full_meta, f, indent=2, ensure_ascii=False)
            
            logger.debug(f"âœ“ Metadata saved: {self.meta_path}")
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to save metadata: {e}")
    
    


class BatchSizeMonitorCallback(pl.Callback):
    def on_train_start(self, trainer, pl_module):
        logger.info("=== TRAIN START ===")
        # ëª¨ë¸ ì„¤ì •
        mc: ModelConfig = pl_module.model_config
        logger.info(f"[MODEL] vision={mc.vision_name} | lm={mc.language_model_name} | resampler={mc.resampler_type} | dim={mc.latent_dimension}")
        logger.info(f"[TEXT] max_len={mc.max_text_length} | LoRA={pl_module.use_lora}")
        # ë°ì´í„°ì…‹/ë¡œë”
        logger.info(f"[DATA] train_csv={trainer.datamodule.hparams.csv_train}")
        logger.info(f"[DATA] val_csv={trainer.datamodule.hparams.csv_val}")
        logger.info(f"[DATA] crop={trainer.datamodule.hparams.crop_strategy}")
        logger.info(f"[DATA] vision_model_name={trainer.datamodule.hparams.vision_model_name}")
        logger.info(f"[DATA] use_vision_processor={trainer.datamodule.hparams.use_vision_processor}")
        logger.info(f"[DATA] Actual processor image_size={trainer.datamodule.processor.img_proc.image_size}")
        # ë¡œë” í¬ê¸°
        logger.info(f"[LOADER] train_batches={len(trainer.datamodule.train_dataloader())} | val_batches={len(trainer.datamodule.val_dataloader())}")
        # í™˜ê²½
        if torch.cuda.is_available():
            logger.info(f"[GPU] count={torch.cuda.device_count()} | name={torch.cuda.get_device_name()}")

    def on_train_epoch_start(self, trainer, pl_module):
        _ = pl_module  # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë§¤ê°œë³€ìˆ˜ ë¬´ì‹œ
        logger.info(f"[Epoch {trainer.current_epoch}] start")

    def on_train_epoch_end(self, trainer, pl_module):
        # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë§¤ê°œë³€ìˆ˜ë“¤ì„ ëª…ì‹œì ìœ¼ë¡œ ë¬´ì‹œ
        _ = trainer, pl_module

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹¤í–‰ ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_config_dict(config_path: Optional[str] = None) -> Dict[str, Any]:
    """Backward-compatible shim for modules that import this helper from train.py."""
    bundle = load_runtime_config(config_path)
    cfg = bundle.raw
    cfg["_pano_config_obj"] = bundle.pano
    cfg["_model_config_obj"] = bundle.model
    if "_config_path" in cfg:
        logger.info(f"âœ“ Loaded config: {cfg['_config_path']}")
    return cfg


def _validate_required_model_fields(cfg: Dict[str, Any]) -> None:
    models_cfg = cfg.get("models")
    if not isinstance(models_cfg, dict):
        raise ValueError("YAML configì— 'models' ì„¹ì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤. vision/language/resamplerë¥¼ ëª…ì‹œí•˜ì„¸ìš”.")
    required = ("vision_name", "language_model_name", "resampler_type")
    missing = [key for key in required if not models_cfg.get(key)]
    if missing:
        raise ValueError(f"models ì„¹ì…˜ì— í•„ìˆ˜ íŒŒë¼ë¯¸í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {missing}. YAMLì„ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.")

    # Stage configuration structure sanity check
    training_cfg = cfg.get("training", {}) or {}
    stage_cfgs = training_cfg.get("stage_configs", {})
    if not isinstance(stage_cfgs, dict) or not stage_cfgs:
        raise ValueError("training.stage_configsê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ìŠ¤í…Œì´ì§€ë³„ ì„¤ì •ì„ YAMLë¡œ ì •ì˜í•˜ì„¸ìš”.")
    for stage_name, stage_def in stage_cfgs.items():
        if not isinstance(stage_def, dict):
            raise ValueError(f"stage '{stage_name}' ì„¤ì •ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. dict í˜•íƒœë¡œ ì •ì˜í•˜ì„¸ìš”.")


def _preview_stage_configs(stage_manager: StageManager) -> None:
    planned_stages = stage_manager.available_stage_names()
    print("\n=== Stage Configuration Preview ===")
    print(f"Planned stages: {planned_stages}")
    for summary in stage_manager.preview():
        stage = summary.pop("stage")
        print(f"\n[{stage}] ->")
        print(json.dumps(summary, indent=2, ensure_ascii=False))
    print("=== Preview End ===\n")


def _ensure_model_config(cfg: Dict[str, Any]) -> ModelConfig:
    _validate_required_model_fields(cfg)
    cached = cfg.get("_model_config_obj")
    if isinstance(cached, ModelConfig):
        return cached

    pano_cfg = cfg.get("_pano_config_obj")
    if isinstance(pano_cfg, PanoVLMConfig):
        model_config = pano_cfg.models
    else:
        try:
            pano_cfg = PanoVLMConfig(**cfg)
        except Exception as exc:
            raise RuntimeError("Failed to construct PanoVLMConfig from configuration") from exc
        cfg["_pano_config_obj"] = pano_cfg
        model_config = pano_cfg.models

    cfg["_model_config_obj"] = model_config
    return model_config

def _resolve_stage_image_processing(cfg: Dict[str, Any], stage_cfg: Dict[str, Any]) -> Dict[str, Any]:
    """Merge global image_processing config with per-stage overrides."""
    base = dict(cfg.get("image_processing", {}) or {})
    # ëª…ì‹œì ìœ¼ë¡œ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš° Vision ëª¨ë¸ ì´ë¦„ì„ stage-levelë¡œ í—ˆìš©
    # ì£¼ì˜: YAMLê³¼ ModelConfigì—ì„œëŠ” 'vision_name', train.py ì¼ë¶€ì—ì„œëŠ” 'vision_model_name' ì‚¬ìš©
    # ë‘ ê°€ì§€ ëª¨ë‘ ì§€ì›í•˜ë˜, 'vision_name'ì„ ìš°ì„ 
    models_cfg = cfg.get("models", {}) or {}
    if "vision_model_name" not in base:
        # ìš°ì„ ìˆœìœ„: vision_name > vision_model_name
        vision_identifier = models_cfg.get("vision_name") or models_cfg.get("vision_model_name")
        if vision_identifier:
            base["vision_model_name"] = vision_identifier
    stage_overrides = None

    if isinstance(stage_cfg, dict):
        stage_overrides = stage_cfg.get("image_processing")

    if isinstance(stage_overrides, dict):
        base.update(stage_overrides)

    return base


def _normalize_data_paths(value):
    if value is None:
        return None
    if isinstance(value, (list, tuple)):
        return [str(v) for v in value if v is not None]
    return str(value)


def _resolve_stage_data(cfg: Dict[str, Any], stage_cfg: Dict[str, Any]) -> tuple[Any, Any]:
    paths_cfg = cfg.get("paths", {}) or {}
    data_cfg = cfg.get("data", {}) or {}

    base_train = (
        _normalize_data_paths(paths_cfg.get("csv_train"))
        or _normalize_data_paths(data_cfg.get("csv_train"))
        or _normalize_data_paths(data_cfg.get("train"))
    )
    base_val = (
        _normalize_data_paths(paths_cfg.get("csv_val"))
        or _normalize_data_paths(data_cfg.get("csv_val"))
        or _normalize_data_paths(data_cfg.get("val"))
    )

    stage_train = base_train
    stage_val = base_val

    if isinstance(stage_cfg, dict):
        stage_data = stage_cfg.get("data") or {}
        if stage_data:
            train_override = (
                _normalize_data_paths(stage_data.get("csv_train"))
                or _normalize_data_paths(stage_data.get("train"))
            )
            val_override = (
                _normalize_data_paths(stage_data.get("csv_val"))
                or _normalize_data_paths(stage_data.get("val"))
            )
            if train_override is not None:
                stage_train = train_override
            if val_override is not None:
                stage_val = val_override

    return stage_train, stage_val


def _to_list_str(value):
    if value is None:
        return []
    if isinstance(value, (list, tuple)):
        return [str(v) for v in value]
    return [str(value)]


def _save_stage_snapshot(
    cfg: Dict[str, Any],
    stage: str,
    stage_cfg: Dict[str, Any],
    image_cfg: Dict[str, Any],
    csv_train: Any,
    csv_val: Any,
) -> None:
    try:
        snapshot_dir = (
            cfg.get("paths", {}).get("stage_snapshot_dir")
            or "configs/stage_snapshots"
        )
        out_dir = Path(snapshot_dir)
        out_dir.mkdir(parents=True, exist_ok=True)

        training_cfg = deepcopy(stage_cfg)
        training_cfg.pop("image_processing", None)
        training_cfg.pop("data", None)

        payload = {
            "stage": stage,
            "training": training_cfg,
            "data": {
                "train": _to_list_str(csv_train),
                "val": _to_list_str(csv_val),
            },
            "image_processing": image_cfg,
            "models": cfg.get("models", {}),
            "environment": cfg.get("environment", {}),
        }

        out_path = out_dir / f"{stage}.json"
        with out_path.open("w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)
        logger.info(f"âœ“ Stage config snapshot saved: {out_path}")
    except Exception as e:
        logger.warning(f"âš ï¸ Failed to save stage snapshot for {stage}: {e}")


def build_datamodule(cfg: Dict[str, Any], stage_cfg: Dict[str, Any]) -> VLMDataModule:
    ip = _resolve_stage_image_processing(cfg, stage_cfg)
    csv_train, csv_val = _resolve_stage_data(cfg, stage_cfg)

    # Vision processorê°€ ìë™ ì •ê·œí™”ë¥¼ ì‹¤í–‰í•˜ë„ë¡ mean/stdê°€ ì—†ìœ¼ë©´ Noneìœ¼ë¡œ ìœ ì§€
    image_mean = ip.get("image_mean", None)
    image_std = ip.get("image_std", None)
    
    # image_size ì²˜ë¦¬: Noneì´ë©´ PanoramaImageProcessorê°€ ìë™ ì¶”ë¡ 
    image_size_value = ip.get("image_size")
    if image_size_value is not None:
        image_size_tuple = tuple(image_size_value)
    else:
        image_size_tuple = None  # PanoramaImageProcessorê°€ vision_model_nameì—ì„œ ì¶”ë¡ 
    
    dm = VLMDataModule(
        csv_train=csv_train,
        csv_val=csv_val,
        batch_size=stage_cfg.get("batch_size", 1),  # Tunerê°€ ìµœì  í¬ê¸°ë¥¼ ì°¾ì„ ê²ƒ
        num_workers=cfg.get("training", {}).get("num_workers", 16),
        image_size=image_size_tuple,  # None í—ˆìš©
        tokenizer_name=(
            cfg.get("models", {}).get("language_model_name")
            or cfg.get("models", {}).get("lm_model", "Qwen/Qwen2.5-0.5B-Instruct")
        ),
        # Allow "auto" to use tokenizer.model_max_length with cap from config
        max_text_length=stage_cfg.get("max_text_length", cfg.get("data", {}).get("max_text_length", 256)),
        crop_strategy=ip.get("crop_strategy", "e2p"),
        system_msg=cfg.get("system_messages", {}).get("default", None),
        # Image processing extras
        overlap_ratio=ip.get("overlap_ratio", 0.5),
        fov_deg=ip.get("fov_deg", 90.0),
        image_mean=image_mean,
        image_std=image_std,
        use_vision_processor=ip.get("use_vision_processor", False),
        vision_model_name=ip.get("vision_model_name", cfg.get("models", {}).get("vision_model_name")),
        anyres_patch_size=ip.get("anyres_patch_size"),  # Noneì´ë©´ image_sizeì—ì„œ ìë™ ì¶”ë¡ 
        anyres_max_patches=ip.get("anyres_max_patches", 12),
        normalize=ip.get("normalize", True),
        auto_max_text_length_cap=int(cfg.get("data", {}).get("auto_max_text_length_cap", 8192)),
        auto_max_text_length_floor=int(cfg.get("data", {}).get("auto_max_text_length_floor", 512)),
        auto_max_text_length_scan_limit=int(cfg.get("data", {}).get("auto_max_text_length_scan_limit", 1000)),
    )
    return dm

def build_model(cfg: Dict[str, Any], stage: str, stage_cfg: Dict[str, Any], pretrained_dir_override: Optional[str] = None) -> VLMModule:
    # ModelConfig: derive from file if available, otherwise from resolved config dict
    model_config = _ensure_model_config(cfg)

    # í•™ìŠµë¥ /LoRAë§Œ ì™¸ë¶€ë¡œ
    lr = stage_cfg.get("lr", 2e-5)
    use_lora_cfg = dict(cfg.get("lora", {}))

    stage_lora_cfg = stage_cfg.get("model_config", {}).get("lora") if isinstance(stage_cfg.get("model_config"), dict) else None
    if isinstance(stage_lora_cfg, dict) and "enabled" in stage_lora_cfg:
        use_lora_cfg["use_lora"] = bool(stage_lora_cfg.get("enabled"))
        for key in ("rank", "alpha", "dropout", "target_modules"):
            if stage_lora_cfg.get(key) is not None:
                use_lora_cfg[key] = stage_lora_cfg.get(key)

    # ì‚¬ì „í•™ìŠµ ë””ë ‰í† ë¦¬ (override > config)
    pretrained_dir = pretrained_dir_override or cfg.get("paths", {}).get("pretrained_dir")

    # Vision encoder trainable blocks ì„¤ì • (stage configì—ì„œ ì½ê¸°)
    vision_trainable_blocks = stage_cfg.get("vision_trainable_blocks", 0)

    # ìºì‹œ ì •ë¦¬ ê°„ê²© ì„¤ì • (training configì—ì„œ ì½ê¸°)
    cache_cleanup_interval = cfg.get("training", {}).get("cache_cleanup_interval", 1000)

    module = VLMModule(
        stage=stage,
        model_config=model_config,
        lr=lr,
        use_lora_cfg=use_lora_cfg,
        pretrained_dir=pretrained_dir,
        vision_trainable_blocks=vision_trainable_blocks,
        cache_cleanup_interval=cache_cleanup_interval,
    )
    return module

def build_logger_and_callbacks(cfg: Dict[str, Any], stage: str, stage_cfg: Dict[str, Any], dm: VLMDataModule, lit_model: VLMModule):
    """WandB loggerì™€ ì½œë°± ìƒì„± (ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ ë° íŒŒì¼ëª… í¬í•¨)
    
    ì´ë¦„ ìƒì„± ê·œì¹™ (ë‹¨ì¼ ì¥ì†Œì—ì„œ ê´€ë¦¬):
    =====================================================
    1. experiment_name: YAMLì˜ experiment.name í•„ë“œ
       ì˜ˆ: "ADDDATA_S2Q3_1_latent768_PE"
       
    2. ë””ë ‰í† ë¦¬ êµ¬ì¡°:
       runs/{experiment_name}/{stage}/{crop_short}_{resampler}/
       ì˜ˆ: runs/ADDDATA_S2Q3/vision/anyres-e2p_mlp/
       
    3. ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ëª…:
       {vision_short}_{resampler}_{crop_short}_{dataset}_epoch{XX}_loss{Y.YYYY}.ckpt
       ì˜ˆ: siglip_mlp_anyres-e2p_quic360_epoch03_loss0.4523.ckpt
       
    4. WandB Run Name:
       {experiment_name}/{stage}/{vision_short}_{resampler}_{crop_short}_{dataset}_{timestamp}
       ì˜ˆ: ADDDATA_S2Q3/vision/siglip_mlp_anyres-e2p_quic360_1015-1430
    =====================================================
    """
    
    # ========== ê³µí†µ ì´ë¦„ êµ¬ì„± ìš”ì†Œ ìƒì„± (ë‹¨ì¼ ì¥ì†Œì—ì„œ ê´€ë¦¬) ==========
    def _csv_name(csv_value) -> str:
        """CSV ê²½ë¡œì—ì„œ ë°ì´í„°ì…‹ ì´ë¦„ ì¶”ì¶œ"""
        try:
            if isinstance(csv_value, (list, tuple)) and len(csv_value) > 0:
                first = Path(str(csv_value[0]))
                suffix = f"plus{len(csv_value)-1}" if len(csv_value) > 1 else ""
                return f"{first.stem}{('_' + suffix) if suffix else ''}"
            return Path(str(csv_value)).stem
        except Exception:
            return "csv"
    
    # YAMLì—ì„œ ê°€ì ¸ì˜¨ experiment ì´ë¦„ (ì—†ê±°ë‚˜ autoë©´ êµ¬ì„±ìš”ì†Œë¡œ ìƒì„±)
    # YAML ì˜ˆì‹œ: experiment: { name: "ADDDATA_S2Q3_1_latent768_PE" }
    experiment_name = _compute_experiment_name(cfg, crop_strategy=dm.hparams.crop_strategy)
    
    # ëª¨ë¸ êµ¬ì„± ìš”ì†Œ
    vision_full = cfg.get("models", {}).get("vision_name", "unknown")
    vision_short = vision_full.split("/")[-1].split("-")[0][:10]  # "google/siglip-base-patch16-224" -> "siglip"
    
    resampler = (
        cfg.get("models", {}).get("resampler_type")
        or cfg.get("models", {}).get("resampler", "mlp")
    )
    
    # ì´ë¯¸ì§€ ì²˜ë¦¬ ì „ëµ
    crop_strategy = dm.hparams.crop_strategy
    crop_short = crop_strategy.replace("_", "-")  # anyres_e2p -> anyres-e2p
    
    # ë°ì´í„°ì…‹ ì´ë¦„
    dataset_name = _csv_name(dm.hparams.csv_train)
    
    # ========== ë””ë ‰í† ë¦¬ ë° íŒŒì¼ ê²½ë¡œ ==========
    runs_dir = cfg.get("paths", {}).get("runs_dir", "runs")
    
    # ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬: {experiment_name}/{stage}/{crop_strategy}_{resampler}
    # ì˜ˆ: runs/ADDDATA_S2Q3/vision/anyres-e2p_mlp/
    ckpt_dir = f"{runs_dir}/{experiment_name}/{stage}/{crop_short}_{resampler}"
    Path(ckpt_dir).mkdir(parents=True, exist_ok=True)

    # wandb
    wandb_logger = None
    try:
        # í™˜ê²½ë³€ìˆ˜ ì„¸íŒ… (ë³´ì•ˆí‚¤ëŠ” í™˜ê²½ì—ì„œ). í”„ë¡œì íŠ¸ëª…ì€ JSONì—ì„œ ì§ì ‘ ì½ìŒ.
        env = cfg.get("environment", {})

        # ê¸°ì¡´ ëŸ° ë‹«ê¸°
        try:
            import wandb
            if wandb.run is not None:
                wandb.finish()
        except Exception:
            pass

        # ========== WandB Run Name ==========
        # ë‚ ì§œ/ì‹œê°„ ì¶”ê°€ (ê°„ê²°í•˜ê²Œ: MMDD-HHMM)
        from datetime import datetime
        timestamp = datetime.now().strftime("%m%d-%H%M")
        
        # í˜•ì‹: {experiment_name}/{stage}/{vision}_{resampler}_{crop}_{dataset}_{timestamp}
        # ì˜ˆ: ADDDATA_SQ3/vision/siglip_mlp_anyres-e2p_quic360_1015-1430
        run_name = f"{experiment_name}/{stage}/{vision_short}_{resampler}_{crop_short}_{dataset_name}_{timestamp}"
        
        # WandB Config: í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ì‹¤í—˜ ì„¤ì • ìƒì„¸ ê¸°ë¡
        wandb_config = {
            # Stage & Experiment
            "experiment_name": experiment_name,
            "stage": stage,
            "stage_canonical": canonical_stage_name(stage),
            
            # Model Architecture
            "vision_encoder": vision_full,
            "language_model": cfg.get("models", {}).get("language_model_name"),
            "resampler_type": resampler,
            "latent_dimension": lit_model.model_config.latent_dimension,
            "vision_trainable_blocks": lit_model.vision_trainable_blocks,
            
            # Training Hyperparameters
            "learning_rate": lit_model.hparams.lr,
            "batch_size": dm.hparams.batch_size,
            "accumulate_grad_batches": stage_cfg.get("accumulate_grad_batches", 1),
            "epochs": stage_cfg.get("epochs"),
            "gradient_clip_val": 1.0,
            "optimizer": "AdamW",
            "weight_decay": 0.05,
            
            # Image Processing
            "image_size": dm.hparams.image_size,
            "crop_strategy": dm.hparams.crop_strategy,
            "fov_deg": dm.hparams.fov_deg,
            "overlap_ratio": dm.hparams.overlap_ratio,
            "use_vision_processor": dm.hparams.use_vision_processor,
            "normalize": dm.hparams.normalize,
            
            # Text Processing
            "max_text_length": dm.hparams.max_text_length,
            "tokenizer": dm.hparams.tokenizer_name,
            
            # Dataset
            "train_dataset": dataset_name,
            "num_train_samples": len(dm.train_ds) if hasattr(dm, 'train_ds') and dm.train_ds else 0,
            "num_val_samples": len(dm.val_ds) if hasattr(dm, 'val_ds') and dm.val_ds else 0,
            "num_workers": dm.hparams.num_workers,
            
            # LoRA (if applicable)
            "use_lora": lit_model.use_lora,
            "lora_rank": lit_model.hparams.lora_rank if lit_model.use_lora else None,
            "lora_alpha": lit_model.hparams.lora_alpha if lit_model.use_lora else None,
            
            # VICReg (for vision stage)
            "vicreg_loss_weight": lit_model.model_config.vicreg_loss_weight if stage == "vision" else None,
            
            # System
            "num_gpus": torch.cuda.device_count() if torch.cuda.is_available() else 0,
            "mixed_precision": "bf16-mixed",
        }

        # WandB Tags: ë¹ ë¥¸ í•„í„°ë§ì„ ìœ„í•œ íƒœê·¸
        wandb_tags = [
            stage,  # ìŠ¤í…Œì´ì§€ë³„ í•„í„°ë§
            resampler,  # Resampler íƒ€ì…ë³„
            crop_short,  # Crop ì „ëµë³„
            dataset_name,  # ë°ì´í„°ì…‹ë³„
            vision_short,  # Vision ëª¨ë¸ë³„
        ]
        if lit_model.use_lora:
            wandb_tags.append("lora")
        if stage == "vision":
            wandb_tags.append("vicreg")
        
        # WandB Notes: ì‹¤í—˜ ì„¤ëª…
        wandb_notes = f"""
        Stage: {stage}
        Vision: {cfg.get("models", {}).get("vision_name")}
        LM: {cfg.get("models", {}).get("language_model_name")}
        Resampler: {resampler}
        Dataset: {dataset_name}
        Image Size: {dm.hparams.image_size}
        Crop Strategy: {dm.hparams.crop_strategy}
        """

        project_name = (
            cfg.get("training", {}).get("wandb_project")
            or cfg.get("environment", {}).get("wandb_project")
            or "panovlm"
        )
        
        wandb_logger = WandbLogger(
            project=project_name,
            name=run_name,
            config=wandb_config,
            tags=wandb_tags,
            notes=wandb_notes.strip(),
            dir="./runs",
            save_dir="./runs",
            log_model=False,  # ì²´í¬í¬ì¸íŠ¸ëŠ” ModelCheckpointë¡œ ê´€ë¦¬
        )
    except Exception as e:
        logger.warning(f"WandB logger init failed: {e}; continue without WandB.")

    # ========== ì²´í¬í¬ì¸íŠ¸ ë©”íƒ€ë°ì´í„° ì¤€ë¹„ ==========
    checkpoint_metadata: Dict[str, Any] = {
        "experiment_name": experiment_name,
        "stage": stage,
        "stage_canonical": canonical_stage_name(stage),
        
        "model_config": {
            "vision_name": vision_full,
            "language_model_name": cfg.get("models", {}).get("language_model_name"),
            "resampler_type": resampler,
            "latent_dimension": lit_model.model_config.latent_dimension,
            "image_size": list(dm.hparams.image_size) if isinstance(dm.hparams.image_size, tuple) else dm.hparams.image_size,
            "max_text_length": dm.hparams.max_text_length,
            "vicreg_loss_weight": lit_model.model_config.vicreg_loss_weight,
            "overlap_ratio": lit_model.model_config.overlap_ratio,
            # âœ¨ Resampler ìƒì„¸ ì„¤ì • ì¶”ê°€ (dimension mismatch ë°©ì§€ìš©)
            "resampler_config": getattr(lit_model.model_config, 'resampler_config', None),
            "resampler_hidden_dim": getattr(lit_model.model_config, 'resampler_hidden_dim', None),
        },
        
        "training_config": {
            "learning_rate": lit_model.hparams.lr,
            "batch_size": dm.hparams.batch_size,
            "accumulate_grad_batches": stage_cfg.get("accumulate_grad_batches", 1),
            "epochs": stage_cfg.get("epochs"),
            "crop_strategy": crop_strategy,
            "fov_deg": dm.hparams.fov_deg,
            "overlap_ratio": dm.hparams.overlap_ratio,
            "use_vision_processor": dm.hparams.use_vision_processor,
            "normalize": dm.hparams.normalize,
            "use_lora": lit_model.use_lora,
            "lora_rank": lit_model.hparams.lora_rank if lit_model.use_lora else None,
            "lora_alpha": lit_model.hparams.lora_alpha if lit_model.use_lora else None,
            "vision_trainable_blocks": lit_model.vision_trainable_blocks,
        },
        
        "dataset": {
            "train_csv": str(dm.hparams.csv_train),
            "val_csv": str(dm.hparams.csv_val),
            "dataset_name": dataset_name,
            "num_train_samples": len(dm.train_ds) if hasattr(dm, 'train_ds') and dm.train_ds else 0,
            "num_val_samples": len(dm.val_ds) if hasattr(dm, 'val_ds') and dm.val_ds else 0,
            "num_workers": dm.hparams.num_workers,
        },
        
        "system": {
            "num_gpus": torch.cuda.device_count() if torch.cuda.is_available() else 0,
            "mixed_precision": "bf16-mixed",
        },
        
        "wandb": {
            "project": wandb_logger.experiment.project if wandb_logger else None,
            "run_name": run_name if wandb_logger else None,
            "run_id": wandb_logger.experiment.id if wandb_logger and hasattr(wandb_logger.experiment, 'id') else None,
        } if wandb_logger else None,
    }
    if cfg.get("_config_path"):
        checkpoint_metadata.setdefault("config", {})
        checkpoint_metadata["config"].update(
            {
                "source_path": cfg["_config_path"],
                "saved_filename": "config.yaml",
            }
        )

    # callbacks
    callbacks = [
        BatchSizeMonitorCallback(),
        MetadataCallback(ckpt_dir, checkpoint_metadata, config_path=cfg.get("_config_path")),  # ë©”íƒ€ë°ì´í„° ë° config ì €ì¥
    ]
    
    # EarlyStopping (ë©”íŠ¸ë¦­ ë¡œê¹… ê°œì„ ë¨)
    early_stop = EarlyStopping(
        monitor="val_loss", patience=2, mode="min", verbose=True, check_on_train_epoch_end=False
    )
    callbacks.append(early_stop)

    # ========== ModelCheckpoint: ê°€ë…ì„± ë†’ì€ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥ ==========
    # save_weights_only=True: ëª¨ë¸ ê°€ì¤‘ì¹˜ë§Œ ì €ì¥ (optimizer/scheduler ìƒíƒœ ì œì™¸)
    # â†’ ì²´í¬í¬ì¸íŠ¸ í¬ê¸° ê°ì†Œ, ë¡œë”© ì†ë„ ê°œì„ 
    # â†’ í›ˆë ¨ ì¬ê°œê°€ ì•„ë‹Œ inference/ë‹¤ìŒ stage ìš©ë„ë¡œ ì¶©ë¶„
    
    # íŒŒì¼ëª… í˜•ì‹: {vision}_{resampler}_{crop}_{dataset}_epoch{XX}_loss{Y.YYYY}
    # ì˜ˆ: siglip_mlp_anyres-e2p_quic360_epoch03_loss0.4523.ckpt
    # ì£¼ì˜: ì´ë¯¸ ìœ„ì—ì„œ ì •ì˜ëœ ë³€ìˆ˜ë“¤ ì¬ì‚¬ìš© (ì¤‘ë³µ ì œê±°)
    filename_base = f"{vision_short}_{resampler}_{crop_short}_{dataset_name}_epoch{{epoch:02d}}_loss{{val_loss:.4f}}"
    
    ckpt_cb = ModelCheckpoint(
        dirpath=ckpt_dir,
        filename=filename_base,
        monitor="val_loss",
        mode="min",
        save_top_k=1,
        save_last=True,
        save_weights_only=True,  # ëª¨ë¸ ê°€ì¤‘ì¹˜ë§Œ ì €ì¥ (íš¨ìœ¨ì„±)
        auto_insert_metric_name=False,
    )
    callbacks.append(ckpt_cb)

    return wandb_logger, callbacks, ckpt_dir


@dataclass
class StageResult:
    stage: str
    status: str
    best_checkpoint: Optional[str] = None
    last_checkpoint: Optional[str] = None
    artifact_dir: Optional[str] = None
    elapsed_minutes: Optional[float] = None
    error: Optional[str] = None

    def get_load_path(self) -> Optional[str]:
        for candidate in (self.best_checkpoint, self.last_checkpoint, self.artifact_dir):
            if candidate:
                return candidate
        return None


class StageExecutionError(RuntimeError):
    def __init__(self, stage: str, original_exception: Exception, result: StageResult):
        message = f"Stage '{stage}' failed: {original_exception}"
        super().__init__(message)
        self.stage = stage
        self.original_exception = original_exception
        self.result = result


def run_stage(
    cfg: Dict[str, Any],
    stage: str,
    stage_manager: StageManager,
    prev_artifact_dir: Optional[str] = None,
    resume_checkpoint_path: Optional[str] = None,
) -> StageResult:
    logger.info(f"=== RUN STAGE: {stage} ===")

    stage_def = stage_manager.get_stage_definition(stage)
    sdef = stage_def.config
    logger.info(f"[STAGE DEFAULTS] {sdef}")

    stage_ip = _resolve_stage_image_processing(cfg, sdef)
    stage_train_data, stage_val_data = _resolve_stage_data(cfg, sdef)
    _save_stage_snapshot(cfg, stage, sdef, stage_ip, stage_train_data, stage_val_data)

    runs_dir = cfg.get("paths", {}).get("runs_dir", "runs")
    # experiment.nameì´ ì—†ê±°ë‚˜ autoë©´ êµ¬ì„±ìš”ì†Œë¡œ ìƒì„±
    crop = stage_ip.get("crop_strategy", "e2p")
    experiment_name = _compute_experiment_name(cfg, crop_strategy=crop)
    crop_short = crop.replace("_", "-")
    resampler = (
        cfg.get("models", {}).get("resampler_type")
        or cfg.get("models", {}).get("resampler", "mlp")
    )
    # ìƒˆë¡œìš´ ë””ë ‰í† ë¦¬ êµ¬ì¡°: {experiment_name}/{stage}/{crop_strategy}_{resampler}
    ckpt_dir = f"{runs_dir}/{experiment_name}/{stage}/{crop_short}_{resampler}"

    dm = build_datamodule(cfg, sdef)
    lit_model = build_model(cfg, stage, sdef, pretrained_dir_override=prev_artifact_dir)

    def _select_resume_checkpoint(candidate: Optional[str]) -> Optional[str]:
        if not candidate:
            return None
        path = Path(candidate)
        if path.is_file() and path.suffix == ".ckpt":
            return str(path.resolve())
        if path.is_dir():
            for name in ("last.ckpt", "best.ckpt"):
                resolved = path / name
                if resolved.exists():
                    return str(resolved.resolve())
            ckpt_files = sorted(
                path.glob("*.ckpt"),
                key=lambda item: item.stat().st_mtime,
                reverse=True,
            )
            if ckpt_files:
                return str(ckpt_files[0].resolve())
        logger.warning(f"Resume checkpoint provided but no .ckpt file found: {candidate}")
        return None

    resume_ckpt = _select_resume_checkpoint(resume_checkpoint_path)
    if resume_checkpoint_path and not resume_ckpt:
        logger.warning(f"Unable to resolve resume checkpoint for stage '{stage}': {resume_checkpoint_path}")
    if resume_ckpt:
        logger.info(f"Resuming stage '{stage}' from checkpoint: {resume_ckpt}")

    wandb_logger, callbacks, ckpt_dir = build_logger_and_callbacks(cfg, stage, sdef, dm, lit_model)

    val_check_interval_cfg = sdef.get("val_check_interval", cfg.get("training", {}).get("val_check_interval", 1.0))
    try:
        val_check_interval = float(val_check_interval_cfg)
    except (TypeError, ValueError):
        logger.warning(f"Invalid val_check_interval={val_check_interval_cfg!r}; falling back to 1.0")
        val_check_interval = 1.0

    trainer_kwargs = dict(
        logger=wandb_logger,
        callbacks=callbacks,
        val_check_interval=val_check_interval,
        max_epochs=sdef.get("epochs", 1),
        precision="bf16-mixed",  # BFloat16 mixed precision for better stability
        gradient_clip_val=1.0,
        default_root_dir=ckpt_dir,
        enable_checkpointing=True,
        enable_progress_bar=True,
        deterministic=False,
        benchmark=True,
        accumulate_grad_batches=sdef.get("accumulate_grad_batches", 2),
    )

    env_cfg = cfg.get("environment", {})
    if torch.cuda.is_available():
        trainer_kwargs["accelerator"] = "gpu"
        cuda_vis = str(env_cfg.get("cuda_visible_devices", "")).strip()
        if cuda_vis:
            try:
                dev_list = [int(x) for x in cuda_vis.split(",") if x.strip() != ""]
                if len(dev_list) == 1:
                    trainer_kwargs["devices"] = dev_list
                elif len(dev_list) > 1:
                    trainer_kwargs["devices"] = dev_list
            except Exception:
                pass
    else:
        trainer_kwargs["accelerator"] = "cpu"

    num_devices = 0
    if torch.cuda.is_available():
        devices_cfg = trainer_kwargs.get("devices")
        if isinstance(devices_cfg, (list, tuple)):
            num_devices = len(devices_cfg)
        elif isinstance(devices_cfg, int):
            num_devices = devices_cfg
        elif isinstance(devices_cfg, str):
            try:
                num_devices = len([d for d in devices_cfg.split(",") if d.strip()])
            except Exception:
                num_devices = torch.cuda.device_count()
        else:
            num_devices = torch.cuda.device_count()

    chosen_strategy = None
    deepspeed_cfg = (cfg.get("training", {}).get("deepspeed") or {})
    deepspeed_enabled = bool(deepspeed_cfg.get("enabled", False))
    if num_devices > 1:
        if deepspeed_enabled:
            try:
                from lightning.pytorch.strategies import DeepSpeedStrategy

                ds_kwargs = dict(deepspeed_cfg.get("strategy", {}) or {})
                if "stage" in ds_kwargs:
                    try:
                        ds_kwargs["stage"] = int(ds_kwargs["stage"])
                    except (TypeError, ValueError):
                        pass
                chosen_strategy = DeepSpeedStrategy(**ds_kwargs)
                logger.info(f"Using DeepSpeed strategy (kwargs={ds_kwargs})")
            except ImportError:
                logger.warning("DeepSpeedStrategy import failed; falling back to DDP")
            except TypeError as e:
                logger.warning(f"DeepSpeedStrategy init failed ({e}); falling back to DDP")

        if chosen_strategy is None:
            try:
                from lightning.pytorch.strategies import DDPStrategy

                chosen_strategy = DDPStrategy(find_unused_parameters=True)
                logger.info("Using DDP strategy (find_unused_parameters=True)")
            except ImportError:
                chosen_strategy = "ddp_find_unused_parameters_true"
                logger.warning("DDPStrategy import failed; using string alias 'ddp_find_unused_parameters_true'")

    if chosen_strategy is not None:
        trainer_kwargs["strategy"] = chosen_strategy
    elif deepspeed_enabled:
        logger.info("DeepSpeed enabled but only a single device detected; running without distributed strategy")

    trainer = pl.Trainer(**trainer_kwargs)

    if torch.cuda.is_available():
        memory_allocated = torch.cuda.memory_allocated() / (1024**3)
        memory_reserved = torch.cuda.memory_reserved() / (1024**3)
        logger.info(f"ğŸ“Š GPU Memory after tuning - Allocated: {memory_allocated:.2f}GB, Reserved: {memory_reserved:.2f}GB")

    logger.info(f"Starting training (stage={stage})")
    stage_exception: Optional[Exception] = None
    start_time = time.time()
    try:
        fit_kwargs = {"datamodule": dm}
        if resume_ckpt:
            fit_kwargs["ckpt_path"] = resume_ckpt
        trainer.fit(lit_model, **fit_kwargs)
    except Exception as exc:
        stage_exception = exc
        logger.error(f"Training failed (stage={stage}): {exc}")
    finally:
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    elapsed_minutes = round((time.time() - start_time) / 60, 3) if start_time else None
    if stage_exception is None and elapsed_minutes is not None:
        logger.info(f"Training finished in {elapsed_minutes:.1f} min")

    best_ckpt = None
    last_ckpt = None
    try:
        for cb in trainer.callbacks:
            if isinstance(cb, ModelCheckpoint):
                if getattr(cb, "best_model_path", None):
                    best_ckpt = cb.best_model_path
                if getattr(cb, "last_model_path", None):
                    last_ckpt = cb.last_model_path
        if best_ckpt:
            logger.info(f"ğŸ Best checkpoint: {best_ckpt}")
        if last_ckpt and last_ckpt != best_ckpt:
            logger.info(f"ğŸ§· Last checkpoint: {last_ckpt}")
    except Exception as err:
        logger.warning(f"âš ï¸ Could not summarize checkpoints: {err}")

    canonical_stage = getattr(lit_model, "_stage_key", stage)
    if stage_exception is None and canonical_stage == "finetune" and lit_model.use_lora:
        # LoRA ê°€ì¤‘ì¹˜ ì¶”ê°€ ì €ì¥ (HuggingFace í˜¸í™˜ í˜•ì‹)
        # ì£¼ì˜: Lightning ì²´í¬í¬ì¸íŠ¸(.ckpt)ê°€ ì´ë¯¸ LoRA í¬í•¨ state_dictë¥¼ ì €ì¥í•¨
        # ì´ ë³„ë„ ì €ì¥ì€ HuggingFace PEFT ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ê²ƒ
        try:
            lora_dir = str(Path(ckpt_dir) / "lora_weights")
            success = lit_model.model.save_lora_weights(lora_dir)
            if success:
                logger.info(f"âœ“ LoRA weights (HF PEFT format) saved: {lora_dir}")
                logger.info("âš ï¸  Lightning checkpoint (.ckpt) already contains full LoRA state_dict")
                logger.info("   â†’ Use .ckpt for PanoramaVLM.from_checkpoint() (recommended)")
                logger.info("   â†’ Use lora_weights/ for HuggingFace PEFT compatibility only")
            else:
                logger.warning("âš ï¸ LoRA weight save returned False")
        except Exception as err:
            logger.warning(f"âš ï¸ Additional LoRA save failed: {err}")
            logger.info("   Lightning checkpoint still contains full model state")

    if stage_exception is None:
        logger.info("=" * 80)
        logger.info("ğŸ‰ í›ˆë ¨ ì™„ë£Œ! ì €ì¥ëœ ëª¨ë¸ ì‚¬ìš©ë²•:")
        logger.info("=" * 80)
        if best_ckpt:
            logger.info("ğŸ“– CKPT ë¡œë”© ì˜ˆì‹œ:")
            logger.info("   from panovlm.model import PanoramaVLM")
            logger.info(f'   model = PanoramaVLM.from_checkpoint("{best_ckpt}")')
        elif last_ckpt:
            logger.info("ğŸ“– CKPT ë¡œë”© ì˜ˆì‹œ:")
            logger.info("   from panovlm.model import PanoramaVLM")
            logger.info(f'   model = PanoramaVLM.from_checkpoint("{last_ckpt}")')

    result = StageResult(
        stage=stage,
        status="completed" if stage_exception is None else "failed",
        best_checkpoint=best_ckpt,
        last_checkpoint=last_ckpt,
        artifact_dir=ckpt_dir,
        elapsed_minutes=elapsed_minutes,
        error=str(stage_exception) if stage_exception else None,
    )

    if stage_exception is not None:
        raise StageExecutionError(stage, stage_exception, result) from stage_exception

    return result


class StageOrchestrator:
    STATE_VERSION = 1

    def __init__(self, cfg: Dict[str, Any], stage_manager: StageManager):
        self.cfg = cfg
        self.stage_manager = stage_manager
        self.stages = stage_manager.available_stage_names()
        runs_dir = cfg.get("paths", {}).get("runs_dir", "runs")
        # experiment.name ìš°ì„ , fallbackìœ¼ë¡œ training.prefix ì‚¬ìš© (í•˜ìœ„ í˜¸í™˜ì„±)
        experiment_name = cfg.get("experiment", {}).get("name") or cfg.get("training", {}).get("prefix") or "panovlm_exp"
        self.state_path = Path(runs_dir) / f"{experiment_name}_stage_state.json"
        self.state = self._load_state()
        self.state.setdefault("version", self.STATE_VERSION)
        self.state.setdefault("stages", {})
        force_env = os.environ.get("PANOVLM_FORCE_STAGES", "")
        self.force_stages = {s.strip() for s in force_env.split(",") if s.strip()}
        if self.force_stages:
            logger.info(f"Force rerun stages: {sorted(self.force_stages)}")
        logger.info(f"Stage state file: {self.state_path}")

    def _auto_eval_config(self) -> Dict[str, Any]:
        training = self.cfg.get("training", {}) or {}
        auto_eval = training.get("auto_eval")
        if isinstance(auto_eval, bool):
            return {"enabled": auto_eval}
        if isinstance(auto_eval, dict):
            return dict(auto_eval)
        return {}

    @staticmethod
    def _first_path(value: Any) -> Optional[str]:
        if value is None:
            return None
        if isinstance(value, (list, tuple)):
            return value[0] if value else None
        return str(value)

    def _resolve_auto_eval_csv(self, settings: Dict[str, Any]) -> Optional[str]:
        for key in ("csv",):
            if key in settings:
                path = self._first_path(settings[key])
                if path:
                    return path
        paths_cfg = self.cfg.get("paths", {}) or {}
        data_cfg = self.cfg.get("data", {}) or {}
        for candidate in (
            paths_cfg.get("csv_test"),
            data_cfg.get("csv_test"),
        ):
            path = self._first_path(candidate)
            if path:
                return path
        return None

    @staticmethod
    def _select_auto_eval_checkpoint(result: StageResult, preference: str) -> Optional[str]:
        pref = (preference or "last").lower()
        if pref == "best":
            return result.best_checkpoint or result.last_checkpoint or result.artifact_dir
        if pref == "artifact":
            return result.artifact_dir or result.best_checkpoint or result.last_checkpoint
        # default last/current
        return result.last_checkpoint or result.best_checkpoint or result.artifact_dir

    def _maybe_run_auto_eval(self, stage: str, result: StageResult) -> None:
        settings = self._auto_eval_config()
        if not settings.get("enabled"):
            return

        target_stage = settings.get("stage") or "finetune"
        try:
            canonical_target = canonical_stage_name(target_stage)
        except Exception:
            canonical_target = target_stage
        try:
            canonical_current = canonical_stage_name(stage)
        except Exception:
            canonical_current = stage

        if canonical_current != canonical_target:
            return

        checkpoint_path = self._select_auto_eval_checkpoint(result, settings.get("checkpoint", "last"))
        if not checkpoint_path:
            logger.warning("Auto-eval enabled but no checkpoint found after stage '%s'. Skipping.", stage)
            return

        csv_input = self._resolve_auto_eval_csv(settings)
        if not csv_input:
            logger.warning(
                "Auto-eval enabled but no CSV test file provided (set training.auto_eval.csv or paths.csv_test)."
            )
            return

        if not EVAL_SCRIPT_PATH.exists():
            logger.warning("Auto-eval requested but eval.py was not found at %s", EVAL_SCRIPT_PATH)
            return

        cfg_path = self.cfg.get("_config_path")
        cmd = [
            sys.executable,
            str(EVAL_SCRIPT_PATH),
            "--checkpoint",
            str(checkpoint_path),
            "--csv-input",
            str(csv_input),
        ]
        if cfg_path:
            cmd += ["--config", cfg_path]

        if settings.get("metrics_only"):
            cmd.append("--metrics-only")
        if settings.get("log_samples"):
            cmd.append("--log-samples")

        optional_numeric_args = {
            "max_samples": "--max-samples",
            "log_interval": "--log-interval",
            "log_max_samples": "--log-max-samples",
        }
        for key, flag in optional_numeric_args.items():
            value = settings.get(key)
            if value is not None:
                cmd += [flag, str(value)]

        logger.info("ğŸ” Auto-evaluating stage '%s' with command: %s", stage, " ".join(cmd))
        env = os.environ.copy()
        try:
            subprocess.run(cmd, check=True, cwd=str(PROJECT_ROOT), env=env)
        except subprocess.CalledProcessError as exc:
            logger.error("Auto evaluation failed (exit=%s). Command: %s", exc.returncode, " ".join(cmd))
        except FileNotFoundError as exc:
            logger.error("Auto evaluation failed because python executable was not found: %s", exc)

    def _load_state(self) -> Dict[str, Any]:
        if self.state_path.exists():
            try:
                with self.state_path.open("r", encoding="utf-8") as f:
                    data = json.load(f)
                if isinstance(data, dict):
                    return data
            except Exception as exc:
                logger.warning(f"Failed to load stage state ({self.state_path}): {exc}; starting fresh.")
        return {}

    @staticmethod
    def _now_iso() -> str:
        return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())

    def _save_state(self) -> None:
        self.state_path.parent.mkdir(parents=True, exist_ok=True)
        tmp_path = self.state_path.with_suffix(".tmp")
        with tmp_path.open("w", encoding="utf-8") as f:
            json.dump(self.state, f, ensure_ascii=False, indent=2)
        tmp_path.replace(self.state_path)

    def _stage_entry(self, stage: str) -> Dict[str, Any]:
        stages = self.state.setdefault("stages", {})
        return stages.setdefault(stage, {"stage": stage})

    def _record_stage(self, stage: str, **updates) -> None:
        entry = self._stage_entry(stage)
        for key, value in updates.items():
            if value is None:
                entry.pop(key, None)
            else:
                entry[key] = value
        entry["updated_at"] = self._now_iso()
        self._save_state()

    def _get_stage_artifact(self, stage: str) -> Optional[str]:
        entry = self.state.get("stages", {}).get(stage, {})
        for key in ("best_checkpoint", "last_checkpoint", "artifact_dir"):
            path = entry.get(key)
            if path:
                return path
        return None

    def _resolve_resume_checkpoint(self, stage: str, upstream_checkpoint: Optional[str]) -> Optional[str]:
        entry = self.state.get("stages", {}).get(stage, {})
        for key in ("resume_checkpoint", "best_checkpoint", "last_checkpoint", "artifact_dir"):
            candidate = entry.get(key)
            if candidate:
                return candidate
        return upstream_checkpoint

    def _should_skip_stage(self, stage: str) -> bool:
        entry = self.state.get("stages", {}).get(stage, {})
        return entry.get("status") == "completed" and stage not in self.force_stages

    def _cleanup_state_if_completed(self) -> None:
        """Remove stage state file if every planned stage finished successfully."""
        try:
            if not self.state_path.exists():
                return
            stages_state = self.state.get("stages", {})
            for stage in self.stages:
                if stages_state.get(stage, {}).get("status") != "completed":
                    return
            self.state_path.unlink()
            logger.info(f"Removed stage state file: {self.state_path}")
        except Exception as exc:
            logger.warning(f"Failed to remove stage state file ({self.state_path}): {exc}")

    def run(self) -> Optional[str]:
        logger.info(f"Planned stages: {self.stages}")
        prev_artifact = None
        for stage in self.stages:
            if self._should_skip_stage(stage):
                artifact = self._get_stage_artifact(stage)
                prev_artifact = artifact or prev_artifact
                logger.info(f"Skipping stage '{stage}' (already completed). Using checkpoint: {artifact}")
                continue

            resume_candidate = self._resolve_resume_checkpoint(stage, prev_artifact)
            upstream_checkpoint = prev_artifact

            # resume_candidateëŠ” stageë³„ ì¬ì‹œì‘ í›„ë³´ì´ë©°, ìµœì´ˆ ì‹¤í–‰ ì‹œì—ëŠ” upstreamê³¼ ë™ì¼í•  ìˆ˜ ìˆìŒ
            resume_checkpoint = None
            if resume_candidate:
                if upstream_checkpoint is None:
                    resume_checkpoint = resume_candidate
                elif os.path.normpath(str(resume_candidate)) != os.path.normpath(str(upstream_checkpoint)):
                    resume_checkpoint = resume_candidate

            init_checkpoint = resume_candidate or upstream_checkpoint

            self._record_stage(
                stage,
                status="running",
                started_at=self._now_iso(),
                error=None,
                upstream_checkpoint=upstream_checkpoint,
                resume_checkpoint=resume_checkpoint,
            )

            try:
                result = run_stage(
                    self.cfg,
                    stage,
                    self.stage_manager,
                    prev_artifact_dir=init_checkpoint,
                    resume_checkpoint_path=resume_checkpoint,
                )
            except StageExecutionError as err:
                result = err.result
                self._record_stage(
                    stage,
                    status="failed",
                    error=str(err.original_exception),
                    failed_at=self._now_iso(),
                    best_checkpoint=result.best_checkpoint,
                    last_checkpoint=result.last_checkpoint,
                    artifact_dir=result.artifact_dir,
                    elapsed_minutes=result.elapsed_minutes,
                )
                raise err
            else:
                self._record_stage(
                    stage,
                    status=result.status,
                    completed_at=self._now_iso(),
                    best_checkpoint=result.best_checkpoint,
                    last_checkpoint=result.last_checkpoint,
                    artifact_dir=result.artifact_dir,
                    elapsed_minutes=result.elapsed_minutes,
                    error=None,
                    resume_checkpoint=None,
                )
                self._maybe_run_auto_eval(stage, result)
                prev_artifact = result.get_load_path() or prev_artifact

        self._cleanup_state_if_completed()
        return prev_artifact


def run_all(cfg: Dict[str, Any], stage_manager: StageManager) -> Optional[str]:
    orchestrator = StageOrchestrator(cfg, stage_manager)
    final_artifact = orchestrator.run()
    if final_artifact:
        logger.info(f"Pipeline finished. Final artifact: {final_artifact}")
    else:
        logger.info("Pipeline finished without checkpoint artifacts.")
    return final_artifact

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI entrypoint
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def _parse_cli_arguments() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Panorama VLM training")
    parser.add_argument(
        "--config",
        "-c",
        type=str,
        default="config.yaml",
        help="Path to the configuration file (JSON or YAML).",
    )
    parser.add_argument(
        "--stage",
        type=str,
        default=None,
        help="(Optional) Comma-separated stage names or 1-based indices to override config.yaml stages.",
    )
    parser.add_argument(
        "--preview",
        action="store_true",
        help="Print resolved stage configurations and exit.",
    )
    return parser.parse_args()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# main
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    args = _parse_cli_arguments()
    bundle = load_runtime_config(args.config)
    cfg = bundle.raw
    cfg["_pano_config_obj"] = bundle.pano
    cfg["_model_config_obj"] = bundle.model
    stage_manager = StageManager(cfg)

    if args.stage:
        try:
            stage_override = stage_manager.resolve_stage_override(args.stage)
        except ValueError as exc:
            logger.error(str(exc))
            sys.exit(2)
        if stage_override:
            cfg["_cli_stage_override"] = stage_override
            stage_manager = StageManager(cfg)
            logger.info(f"CLI stage override â†’ {stage_override}")
    else:
        logger.info(f"Using stages from config: {stage_manager.available_stage_names()}")

    if getattr(args, "preview", False):
        _preview_stage_configs(stage_manager)
        sys.exit(0)
    try:
        run_all(cfg, stage_manager)
    except StageExecutionError as err:
        logger.error(f"Stage orchestration failed: {err}")
        sys.exit(1)
