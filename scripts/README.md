# PanoLLaVA Training Scripts

μ΄ λ””λ ‰ν† λ¦¬λ” PanoLLaVA λ¨λΈμ 3λ‹¨κ³„ ν›λ ¨μ„ μ„ν• μ¤ν¬λ¦½νΈλ“¤μ„ ν¬ν•¨ν•©λ‹λ‹¤.

## νμΌ κµ¬μ΅°

```
scripts/
β”β”€β”€ config.sh                   # π†• κ³µν†µ μ„¤μ • νμΌ (λ¨λ“  μ¤ν¬λ¦½νΈμ—μ„ μ‚¬μ©)
β”β”€β”€ stage1_vision_train.sh      # Stage 1: Vision Encoder ν›λ ¨
β”β”€β”€ stage2_resampler_train.sh   # Stage 2: Resampler ν›λ ¨  
β”β”€β”€ stage3_finetune_train.sh    # Stage 3: End-to-End Fine-tuning
β”β”€β”€ train_all_stages.sh         # μ „μ²΄ 3λ‹¨κ³„ μλ™ ν›λ ¨
β”β”€β”€ train_custom.sh             # μ‚¬μ©μ μ •μ ν›λ ¨
β”β”€β”€ eval_finetune.sh            # Finetune λ¨λΈ ν‰κ°€
β”β”€β”€ eval_resampler.sh           # Resampler λ¨λΈ ν‰κ°€
β”β”€β”€ eval_compare.sh             # λ¨λΈ λΉ„κµ ν‰κ°€
β””β”€β”€ README.md                   # μ΄ νμΌ
```

## π€ μƒλ΅μ΄ μ¤‘μ•™ν™”λ μ„¤μ • κ΄€λ¦¬

### config.sh
λ¨λ“  μ¤ν¬λ¦½νΈλ” `config.sh`μ—μ„ κ³µν†µ μ„¤μ •μ„ λ΅λ“ν•©λ‹λ‹¤:
- λ¨λΈ μ„¤μ • (Vision/Language λ¨λΈλ…)
- λ°μ΄ν„° κ²½λ΅
- ν•™μµ ν•μ΄νΌνλΌλ―Έν„°
- GPU λ° ν™κ²½ μ„¤μ •
- λ””λ ‰ν† λ¦¬ κµ¬μ΅°

### μ„¤μ • μμ • λ°©λ²•
1. **μ „μ—­ μ„¤μ • λ³€κ²½**: `config.sh` νμΌμ„ μ§μ ‘ μμ •
2. **μ¤ν¬λ¦½νΈλ³„ μ¤λ²„λΌμ΄λ“**: κ° μ¤ν¬λ¦½νΈμ—μ„ ν•„μ”μ‹ μ„¤μ • μ¤λ²„λΌμ΄λ“

## μ‚¬μ©λ²•

### 1. μμ°¨μ  3λ‹¨κ³„ ν›λ ¨

#### Stage 1: Vision Encoder ν›λ ¨
```bash
chmod +x scripts/train_stage1_vision.sh
./scripts/train_stage1_vision.sh
```

#### Stage 2: Resampler ν›λ ¨
```bash
chmod +x scripts/train_stage2_resampler.sh
./scripts/train_stage2_resampler.sh runs/vlm_vision/checkpoints/epoch=00-val_loss=4.006.ckpt
```

#### Stage 3: End-to-End Fine-tuning
```bash
chmod +x scripts/train_stage3_finetune.sh
./scripts/train_stage3_finetune.sh runs/vlm_resampler/checkpoints/epoch=01-val_loss=0.000.ckpt
```

### 2. μλ™ μ „μ²΄ ν›λ ¨

```bash
chmod +x scripts/train_all_stages.sh
./scripts/train_all_stages.sh
```

### 3. μ‚¬μ©μ μ •μ ν›λ ¨

```bash
chmod +x scripts/train_custom.sh

# νΉμ • μ¤ν…μ΄μ§€ ν›λ ¨
./scripts/train_custom.sh --stage vision --epochs 5 --batch-size 16

# μ „μ²΄ ν›λ ¨
./scripts/train_custom.sh --stage all --data-dir /path/to/data

# μ²΄ν¬ν¬μΈνΈμ—μ„ μ¬μ‹μ‘
./scripts/train_custom.sh --stage finetune --resume runs/vlm_resampler/checkpoints/best.ckpt

# λ„μ›€λ§
./scripts/train_custom.sh --help
```

## ν›λ ¨ λ‹¨κ³„ μ„¤λ…

### Stage 1: Vision Encoder ν›λ ¨
- **λ©ν‘**: νλ…ΈλΌλ§ μ΄λ―Έμ§€μ μ‹κ°μ  ν‘ν„ ν•™μµ
- **μ†μ‹¤ ν•¨μ**: VICReg Loss
- **ν›λ ¨ λ€μƒ**: Vision Encoderλ§
- **νΉμ§•**: μΈμ ‘ν• νλ…ΈλΌλ§ λ·° κ°„μ μΌκ΄€μ„± ν•™μµ

### Stage 2: Resampler ν›λ ¨  
- **λ©ν‘**: μ‹κ°μ  νΉμ§•μ„ μ–Έμ–΄ λ¨λΈμ— λ§λ” ν•νƒλ΅ λ³€ν™
- **μ†μ‹¤ ν•¨μ**: Autoregressive Loss
- **ν›λ ¨ λ€μƒ**: Vision Encoder + Resampler + Projection Layer
- **νΉμ§•**: μ‹κ°-μ–Έμ–΄ μ •λ ¬ ν•™μµ

### Stage 3: End-to-End Fine-tuning
- **λ©ν‘**: μµμΆ… λ©€ν‹°λ¨λ‹¬ μ„±λ¥ μµμ ν™”
- **μ†μ‹¤ ν•¨μ**: Autoregressive Loss
- **ν›λ ¨ λ€μƒ**: Resampler + Projection Layer (Language Model κ³ μ •)
- **νΉμ§•**: μ „μ²΄ μ‹μ¤ν…μ ν†µν•© μµμ ν™”

## μ„¤μ • νλΌλ―Έν„°

### κΈ°λ³Έ μ„¤μ •
- **Vision Model**: `google/siglip-base-patch16-224`
- **Language Model**: `Qwen/Qwen2.5-0.5B`
- **Resampler**: `mlp`
- **Data**: `data/quic360/train.csv`, `data/quic360/valid.csv`

### Stageλ³„ κΈ°λ³Έ ν•μ΄νΌνλΌλ―Έν„°

| Stage | Epochs | Batch Size | Learning Rate | Max Text Length |
|-------|--------|------------|---------------|-----------------|
| Vision | 3 | 32 | 5e-6 | 32 |
| Resampler | 5 | 16 | 2e-5 | 64 |
| Finetune | 10 | 8 | 1e-5 | 128 |

## μ¶λ ¥ κµ¬μ΅°

```
runs/
β”β”€β”€ vlm_vision/
β”‚   β”β”€β”€ checkpoints/           # Stage 1 μ²΄ν¬ν¬μΈνΈ
β”‚   β””β”€β”€ model_final.safetensors
β”β”€β”€ vlm_resampler/
β”‚   β”β”€β”€ checkpoints/           # Stage 2 μ²΄ν¬ν¬μΈνΈ
β”‚   β””β”€β”€ model_final.safetensors
β””β”€β”€ vlm_finetune/
    β”β”€β”€ checkpoints/           # Stage 3 μ²΄ν¬ν¬μΈνΈ
    β””β”€β”€ model_final.safetensors  # μµμΆ… λ¨λΈ
```

## λ΅κ·Έ νμΌ

λ¨λ“  ν›λ ¨ λ΅κ·Έλ” `logs/` λ””λ ‰ν† λ¦¬μ— μ €μ¥λ©λ‹λ‹¤:
- `logs/stage1_vision_YYYYMMDD_HHMMSS.log`
- `logs/stage2_resampler_YYYYMMDD_HHMMSS.log`
- `logs/stage3_finetune_YYYYMMDD_HHMMSS.log`
- `logs/full_pipeline_YYYYMMDD_HHMMSS.log`

## λ¨λ‹ν„°λ§

- **WandB**: λ¨λ“  ν›λ ¨ λ©”νΈλ¦­μ΄ WandBμ— μλ™μΌλ΅ λ΅κΉ…λ©λ‹λ‹¤
- **λ΅μ»¬ λ΅κ·Έ**: μ½μ†” μ¶λ ¥κ³Ό νμΌ λ΅κΉ…μ΄ λ™μ‹μ— μ§„ν–‰λ©λ‹λ‹¤
- **μ²΄ν¬ν¬μΈνΈ**: κ° epochλ§λ‹¤ validation loss κΈ°μ¤€μΌλ΅ μµμ  λ¨λΈ μ €μ¥

## λ¬Έμ  ν•΄κ²°

### λ©”λ¨λ¦¬ λ¶€μ΅±
- λ°°μΉ ν¬κΈ°λ¥Ό μ¤„μ—¬λ³΄μ„Έμ”: `--batch-size 8`
- μ›μ»¤ μλ¥Ό μ¤„μ—¬λ³΄μ„Έμ”: `--num-workers 2`

### λ°μ΄ν„° νμΌ μ¤λ¥
- λ°μ΄ν„° κ²½λ΅λ¥Ό ν™•μΈν•μ„Έμ”: `--data-dir /correct/path`
- CSV νμΌ ν•μ‹μ„ ν™•μΈν•μ„Έμ”

### μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ‹¤ν¨
- μ²΄ν¬ν¬μΈνΈ νμΌ κ²½λ΅λ¥Ό ν™•μΈν•μ„Έμ”
- νμΌ κ¶ν•μ„ ν™•μΈν•μ„Έμ”

## μ»¤μ¤ν„°λ§μ΄μ§•

μ¤ν¬λ¦½νΈλ¥Ό μμ •ν•μ—¬ λ‹¤μμ„ λ³€κ²½ν•  μ μμµλ‹λ‹¤:
- λ¨λΈ μ•„ν‚¤ν…μ²
- ν•μ΄νΌνλΌλ―Έν„°
- λ°μ΄ν„° κ²½λ΅
- λ΅κΉ… μ„¤μ •

μμ„Έν• μ„¤μ •μ€ `train.py`μ argparse μµμ…μ„ μ°Έμ΅°ν•μ„Έμ”.