{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "934e8b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 10:12:50,405 - __main__ - INFO - ============================================================\n",
      "2025-08-18 10:12:50,407 - __main__ - INFO - 🚀 1단계: 모델 및 LoRA 가중치 로드\n",
      "2025-08-18 10:12:50,408 - __main__ - INFO - ============================================================\n",
      "2025-08-18 10:12:50,410 - __main__ - INFO - 📂 체크포인트 로드: runs/siglipv2qwen25Instruct_e2p_finetune_mlp/best.ckpt\n",
      "2025-08-18 10:12:51,630 - panovlm.utils - INFO - Successfully loaded checkpoint: runs/siglipv2qwen25Instruct_e2p_finetune_mlp/best.ckpt\n",
      "2025-08-18 10:12:53,103 - train - INFO - VICReg loss weight set to: 0.0 for stage: finetune\n",
      "[Tokenizer Setup] Warning: No bos_token defined\n",
      "[Tokenizer Setup] Warning: No unk_token defined\n",
      "[Tokenizer Setup] Added 1 special tokens: ['<|vision|>', '<|endoftext|>']\n",
      "[Tokenizer Setup] Resized embeddings: 151936 -> 151666\n",
      "[Tokenizer Setup] Final token configuration:\n",
      "  - Vocabulary size: 151666 (was 151665)\n",
      "  - pad_token: '<|endoftext|>' (id: 151643)\n",
      "  - eos_token: '<|im_end|>' (id: 151645)\n",
      "  - bos_token: 'None' (id: None)\n",
      "  - unk_token: 'None' (id: None)\n",
      "  - padding_side: right\n",
      "[TextFormatter] Detected: qwen2.5 (Instruct)\n",
      "[TextFormatter] Assistant start: '<|im_start|>assistant\n",
      "'\n",
      "[Model] Initialized UniversalTextFormatter for qwen2.5\n",
      "2025-08-18 10:12:57,049 - train - INFO - Setting up LoRA for finetune stage...\n",
      "✓ LoRA setup completed:\n",
      "  - Rank: 32\n",
      "  - Alpha: 64\n",
      "  - Dropout: 0.1\n",
      "  - Target modules: ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj']\n",
      "  - Trainable parameters: 17,596,416/511,387,264 (3.44%)\n",
      "2025-08-18 10:12:57,434 - train - INFO - ✓ LoRA setup completed successfully\n",
      "2025-08-18 10:12:57,439 - train - INFO - ✓ Stage 3: Vision components + LoRA adapters unfrozen\n",
      "2025-08-18 10:12:57,448 - train - INFO - Trainable parameters: 1,871,744/606,144,768 (0.3%)\n",
      "2025-08-18 10:12:58,947 - __main__ - INFO - 🔧 LoRA 가중치 로드: runs/siglipv2qwen25Instruct_e2p_finetune_mlp/lora_weights\n",
      "Model already has PEFT config. Attempting to load adapter weights...\n",
      "✓ LoRA adapter 'eval_adapter' loaded and activated\n",
      "2025-08-18 10:12:59,558 - __main__ - INFO - ✅ LoRA 가중치 로드 성공!\n",
      "2025-08-18 10:12:59,559 - __main__ - INFO - 📊 LoRA 설정 - Rank: 32, Alpha: 64\n",
      "2025-08-18 10:12:59,560 - __main__ - INFO -    Target modules: {'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj'}\n",
      "2025-08-18 10:12:59,589 - __main__ - INFO - ✓ 모델 준비 완료 - Device: cuda, Stage: finetune\n"
     ]
    }
   ],
   "source": [
    "from panovlm.model import  PanoramaVLM\n",
    "from train import VLMModule, safe_load_checkpoint\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_model_and_lora(checkpoint_path: str, lora_weights_path: Optional[str], device: torch.device, **model_kwargs) -> VLMModule:\n",
    "    \"\"\"\n",
    "    1단계: 체크포인트와 LoRA 가중치를 로드하여 생성용 모델 준비\n",
    "    \"\"\"\n",
    "    logger.info(\"=\" * 60)\n",
    "    logger.info(\"🚀 1단계: 모델 및 LoRA 가중치 로드\")\n",
    "    logger.info(\"=\" * 60)\n",
    "    \n",
    "    # 체크포인트 로드\n",
    "    logger.info(f\"📂 체크포인트 로드: {checkpoint_path}\")\n",
    "    checkpoint = safe_load_checkpoint(checkpoint_path)\n",
    "    if not checkpoint:\n",
    "        raise ValueError(f\"체크포인트 로드 실패: {checkpoint_path}\")\n",
    "    \n",
    "    # LoRA 경로 자동 감지\n",
    "    if lora_weights_path is None:\n",
    "        checkpoint_dir = Path(checkpoint_path).parent\n",
    "        potential_lora_path = checkpoint_dir / \"lora_weights\"\n",
    "        if potential_lora_path.exists():\n",
    "            lora_weights_path = str(potential_lora_path)\n",
    "            logger.info(f\"🔍 LoRA 가중치 자동 감지: {lora_weights_path}\")\n",
    "    \n",
    "    # 모델 로드 (finetune 단계)\n",
    "    model = VLMModule.load_from_checkpoint(\n",
    "        checkpoint_path,\n",
    "        stage=\"finetune\",\n",
    "        map_location=device,\n",
    "        strict=False,\n",
    "        **model_kwargs\n",
    "    )\n",
    "    \n",
    "    # LoRA 가중치 로드\n",
    "    if lora_weights_path and Path(lora_weights_path).exists():\n",
    "        logger.info(f\"🔧 LoRA 가중치 로드: {lora_weights_path}\")\n",
    "        \n",
    "        # LoRA 파일 구조 검증\n",
    "        lora_path = Path(lora_weights_path)\n",
    "        adapter_config = lora_path / \"adapter_config.json\"\n",
    "        adapter_model = lora_path / \"adapter_model.safetensors\"\n",
    "        \n",
    "        if adapter_config.exists() and adapter_model.exists():\n",
    "            success = model.model.load_lora_weights(lora_weights_path)\n",
    "            if success:\n",
    "                logger.info(\"✅ LoRA 가중치 로드 성공!\")\n",
    "                \n",
    "                # LoRA 설정 정보 출력\n",
    "                lora_info = model.model.get_lora_info()\n",
    "                if lora_info.get(\"is_lora_enabled\", False):\n",
    "                    logger.info(f\"📊 LoRA 설정 - Rank: {lora_info.get('lora_r')}, Alpha: {lora_info.get('lora_alpha')}\")\n",
    "                    logger.info(f\"   Target modules: {lora_info.get('target_modules')}\")\n",
    "            else:\n",
    "                logger.warning(\"⚠️ LoRA 가중치 로드 실패, 기본 모델로 진행\")\n",
    "        else:\n",
    "            logger.warning(f\"⚠️ LoRA 파일 누락: {lora_weights_path}\")\n",
    "    else:\n",
    "        logger.info(\"📝 LoRA 가중치 없음, 기본 모델 사용\")\n",
    "    \n",
    "    # 평가 모드 설정\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    model.model.requires_grad_(False)\n",
    "    \n",
    "    logger.info(f\"✓ 모델 준비 완료 - Device: {device}, Stage: {model._stage_key}\")\n",
    "    return model\n",
    "\n",
    "model = load_model_and_lora(\n",
    "    checkpoint_path=\"runs/siglipv2qwen25Instruct_e2p_finetune_mlp/best.ckpt\",\n",
    "    lora_weights_path=\"runs/siglipv2qwen25Instruct_e2p_finetune_mlp/lora_weights\",  # LoRA 가중치 경로를 지정하거나\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9750a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from panovlm.dataset import ChatPanoDataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panovlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
