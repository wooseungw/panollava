{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "934e8b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 10:12:50,405 - __main__ - INFO - ============================================================\n",
      "2025-08-18 10:12:50,407 - __main__ - INFO - ğŸš€ 1ë‹¨ê³„: ëª¨ë¸ ë° LoRA ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
      "2025-08-18 10:12:50,408 - __main__ - INFO - ============================================================\n",
      "2025-08-18 10:12:50,410 - __main__ - INFO - ğŸ“‚ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: runs/siglipv2qwen25Instruct_e2p_finetune_mlp/best.ckpt\n",
      "2025-08-18 10:12:51,630 - panovlm.utils - INFO - Successfully loaded checkpoint: runs/siglipv2qwen25Instruct_e2p_finetune_mlp/best.ckpt\n",
      "2025-08-18 10:12:53,103 - train - INFO - VICReg loss weight set to: 0.0 for stage: finetune\n",
      "[Tokenizer Setup] Warning: No bos_token defined\n",
      "[Tokenizer Setup] Warning: No unk_token defined\n",
      "[Tokenizer Setup] Added 1 special tokens: ['<|vision|>', '<|endoftext|>']\n",
      "[Tokenizer Setup] Resized embeddings: 151936 -> 151666\n",
      "[Tokenizer Setup] Final token configuration:\n",
      "  - Vocabulary size: 151666 (was 151665)\n",
      "  - pad_token: '<|endoftext|>' (id: 151643)\n",
      "  - eos_token: '<|im_end|>' (id: 151645)\n",
      "  - bos_token: 'None' (id: None)\n",
      "  - unk_token: 'None' (id: None)\n",
      "  - padding_side: right\n",
      "[TextFormatter] Detected: qwen2.5 (Instruct)\n",
      "[TextFormatter] Assistant start: '<|im_start|>assistant\n",
      "'\n",
      "[Model] Initialized UniversalTextFormatter for qwen2.5\n",
      "2025-08-18 10:12:57,049 - train - INFO - Setting up LoRA for finetune stage...\n",
      "âœ“ LoRA setup completed:\n",
      "  - Rank: 32\n",
      "  - Alpha: 64\n",
      "  - Dropout: 0.1\n",
      "  - Target modules: ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj']\n",
      "  - Trainable parameters: 17,596,416/511,387,264 (3.44%)\n",
      "2025-08-18 10:12:57,434 - train - INFO - âœ“ LoRA setup completed successfully\n",
      "2025-08-18 10:12:57,439 - train - INFO - âœ“ Stage 3: Vision components + LoRA adapters unfrozen\n",
      "2025-08-18 10:12:57,448 - train - INFO - Trainable parameters: 1,871,744/606,144,768 (0.3%)\n",
      "2025-08-18 10:12:58,947 - __main__ - INFO - ğŸ”§ LoRA ê°€ì¤‘ì¹˜ ë¡œë“œ: runs/siglipv2qwen25Instruct_e2p_finetune_mlp/lora_weights\n",
      "Model already has PEFT config. Attempting to load adapter weights...\n",
      "âœ“ LoRA adapter 'eval_adapter' loaded and activated\n",
      "2025-08-18 10:12:59,558 - __main__ - INFO - âœ… LoRA ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ!\n",
      "2025-08-18 10:12:59,559 - __main__ - INFO - ğŸ“Š LoRA ì„¤ì • - Rank: 32, Alpha: 64\n",
      "2025-08-18 10:12:59,560 - __main__ - INFO -    Target modules: {'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj'}\n",
      "2025-08-18 10:12:59,589 - __main__ - INFO - âœ“ ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ - Device: cuda, Stage: finetune\n"
     ]
    }
   ],
   "source": [
    "from panovlm.model import  PanoramaVLM\n",
    "from train import VLMModule, safe_load_checkpoint\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_model_and_lora(checkpoint_path: str, lora_weights_path: Optional[str], device: torch.device, **model_kwargs) -> VLMModule:\n",
    "    \"\"\"\n",
    "    1ë‹¨ê³„: ì²´í¬í¬ì¸íŠ¸ì™€ LoRA ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•˜ì—¬ ìƒì„±ìš© ëª¨ë¸ ì¤€ë¹„\n",
    "    \"\"\"\n",
    "    logger.info(\"=\" * 60)\n",
    "    logger.info(\"ğŸš€ 1ë‹¨ê³„: ëª¨ë¸ ë° LoRA ê°€ì¤‘ì¹˜ ë¡œë“œ\")\n",
    "    logger.info(\"=\" * 60)\n",
    "    \n",
    "    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ\n",
    "    logger.info(f\"ğŸ“‚ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: {checkpoint_path}\")\n",
    "    checkpoint = safe_load_checkpoint(checkpoint_path)\n",
    "    if not checkpoint:\n",
    "        raise ValueError(f\"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {checkpoint_path}\")\n",
    "    \n",
    "    # LoRA ê²½ë¡œ ìë™ ê°ì§€\n",
    "    if lora_weights_path is None:\n",
    "        checkpoint_dir = Path(checkpoint_path).parent\n",
    "        potential_lora_path = checkpoint_dir / \"lora_weights\"\n",
    "        if potential_lora_path.exists():\n",
    "            lora_weights_path = str(potential_lora_path)\n",
    "            logger.info(f\"ğŸ” LoRA ê°€ì¤‘ì¹˜ ìë™ ê°ì§€: {lora_weights_path}\")\n",
    "    \n",
    "    # ëª¨ë¸ ë¡œë“œ (finetune ë‹¨ê³„)\n",
    "    model = VLMModule.load_from_checkpoint(\n",
    "        checkpoint_path,\n",
    "        stage=\"finetune\",\n",
    "        map_location=device,\n",
    "        strict=False,\n",
    "        **model_kwargs\n",
    "    )\n",
    "    \n",
    "    # LoRA ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
    "    if lora_weights_path and Path(lora_weights_path).exists():\n",
    "        logger.info(f\"ğŸ”§ LoRA ê°€ì¤‘ì¹˜ ë¡œë“œ: {lora_weights_path}\")\n",
    "        \n",
    "        # LoRA íŒŒì¼ êµ¬ì¡° ê²€ì¦\n",
    "        lora_path = Path(lora_weights_path)\n",
    "        adapter_config = lora_path / \"adapter_config.json\"\n",
    "        adapter_model = lora_path / \"adapter_model.safetensors\"\n",
    "        \n",
    "        if adapter_config.exists() and adapter_model.exists():\n",
    "            success = model.model.load_lora_weights(lora_weights_path)\n",
    "            if success:\n",
    "                logger.info(\"âœ… LoRA ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ!\")\n",
    "                \n",
    "                # LoRA ì„¤ì • ì •ë³´ ì¶œë ¥\n",
    "                lora_info = model.model.get_lora_info()\n",
    "                if lora_info.get(\"is_lora_enabled\", False):\n",
    "                    logger.info(f\"ğŸ“Š LoRA ì„¤ì • - Rank: {lora_info.get('lora_r')}, Alpha: {lora_info.get('lora_alpha')}\")\n",
    "                    logger.info(f\"   Target modules: {lora_info.get('target_modules')}\")\n",
    "            else:\n",
    "                logger.warning(\"âš ï¸ LoRA ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë¸ë¡œ ì§„í–‰\")\n",
    "        else:\n",
    "            logger.warning(f\"âš ï¸ LoRA íŒŒì¼ ëˆ„ë½: {lora_weights_path}\")\n",
    "    else:\n",
    "        logger.info(\"ğŸ“ LoRA ê°€ì¤‘ì¹˜ ì—†ìŒ, ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©\")\n",
    "    \n",
    "    # í‰ê°€ ëª¨ë“œ ì„¤ì •\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    model.model.requires_grad_(False)\n",
    "    \n",
    "    logger.info(f\"âœ“ ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ - Device: {device}, Stage: {model._stage_key}\")\n",
    "    return model\n",
    "\n",
    "model = load_model_and_lora(\n",
    "    checkpoint_path=\"runs/siglipv2qwen25Instruct_e2p_finetune_mlp/best.ckpt\",\n",
    "    lora_weights_path=\"runs/siglipv2qwen25Instruct_e2p_finetune_mlp/lora_weights\",  # LoRA ê°€ì¤‘ì¹˜ ê²½ë¡œë¥¼ ì§€ì •í•˜ê±°ë‚˜\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9750a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from panovlm.dataset import ChatPanoDataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panovlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
