#!/usr/bin/env python3
# coding: utf-8
"""
PanoramaVLM ê°„í¸ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
===========================

ìƒˆë¡œ ì¶”ê°€ëœ í†µí•© ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‚¬ìš©í•œ ê°„ë‹¨í•œ ì¶”ë¡  ì˜ˆì‹œì…ë‹ˆë‹¤.
ë³µì¡í•œ ì„¤ì • ì—†ì´ ë‹¨ ëª‡ ì¤„ë¡œ íŒŒë…¸ë¼ë§ˆ ì´ë¯¸ì§€ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python simple_inference.py --image panorama.jpg --checkpoint runs/best.ckpt
"""

import argparse
import torch
from PIL import Image
from pathlib import Path

def main():
    parser = argparse.ArgumentParser(description="PanoramaVLM ê°„í¸ ì¶”ë¡ ")
    parser.add_argument("--image", required=True, help="íŒŒë…¸ë¼ë§ˆ ì´ë¯¸ì§€ ê²½ë¡œ")
    parser.add_argument("--checkpoint", default="runs/panorama-vlm_e2p_finetune_mlp/best.ckpt", 
                       help="ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ")
    parser.add_argument("--prompt", default="Describe this panoramic image in detail.", 
                       help="ì…ë ¥ í”„ë¡¬í”„íŠ¸")
    parser.add_argument("--max-tokens", type=int, default=128, help="ìµœëŒ€ ìƒì„± í† í° ìˆ˜")
    parser.add_argument("--temperature", type=float, default=0.7, help="ìƒì„± ì˜¨ë„")
    parser.add_argument("--device", default="auto", help="ë””ë°”ì´ìŠ¤ (auto, cuda, cpu)")
    
    args = parser.parse_args()
    
    print("ğŸš€ PanoramaVLM ê°„í¸ ì¶”ë¡  ì‹œì‘")
    print("=" * 50)
    
    # 1. ëª¨ë¸ ë¡œë”© (í•œ ì¤„!)
    print(f"ğŸ“‚ ëª¨ë¸ ë¡œë”©: {args.checkpoint}")
    try:
        from panovlm.model import PanoramaVLM
        model = PanoramaVLM.from_checkpoint(args.checkpoint, device=args.device)
        print(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ - Device: {next(model.parameters()).device}")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        return
    
    # 2. ì´ë¯¸ì§€ ë¡œë”© ë° ì „ì²˜ë¦¬
    print(f"ğŸ–¼ï¸  ì´ë¯¸ì§€ ë¡œë”©: {args.image}")
    try:
        image_path = Path(args.image)
        if not image_path.exists():
            raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.image}")
        
        from panovlm.processors.image import PanoramaImageProcessor
        image_processor = PanoramaImageProcessor(
            image_size=(224, 224),  # ëª¨ë¸ì— ë§ëŠ” ì´ë¯¸ì§€ í¬ê¸°
            crop_strategy="e2p",  # MLP ë¦¬ìƒ˜í”ŒëŸ¬ ì‚¬ìš©
            fov_deg=90,
            overlap_ratio=0.5  # ì˜¤ë²„ë© ë¹„ìœ¨
        )
        
        # PanoramaImageProcessorì˜ __call__ ë©”ì„œë“œ ì‚¬ìš© (ì˜¬ë°”ë¥¸ ë°©ë²•)
        image = Image.open(image_path).convert("RGB")
        print(f"   - ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {image.size}")
        
        pixel_values = image_processor(image)  # __call__ ë©”ì„œë“œ ì‚¬ìš©
        print(f"   - ì „ì²˜ë¦¬ ì™„ë£Œ: {pixel_values.shape}")
        print(f"   - ë·° ìˆ˜: {pixel_values.shape[0]}, í¬ë¡­ ì „ëµ: {image_processor.crop_strategy}")
        
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return
    
    # 3. í…ìŠ¤íŠ¸ ì…ë ¥ ì¤€ë¹„
    print(f"ğŸ’¬ í”„ë¡¬í”„íŠ¸: {args.prompt}")
    try:
        # í† í¬ë‚˜ì´ì €ëŠ” ëª¨ë¸ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        tokenizer = model.tokenizer
        
        inputs = tokenizer(
            args.prompt,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=128
        )
        
        input_ids = inputs["input_ids"]
        attention_mask = inputs.get("attention_mask")
        
        print(f"   - í† í°í™” ì™„ë£Œ: {input_ids.shape}")
        
    except Exception as e:
        print(f"âŒ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return
    
    # 4. ì¶”ë¡  ì‹¤í–‰
    print(f"ğŸ¤– ì¶”ë¡  ì‹¤í–‰ ì¤‘...")
    try:
        with torch.no_grad():
            # ì…ë ¥ì„ ëª¨ë¸ê³¼ ê°™ì€ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            device = next(model.parameters()).device
            pixel_values = pixel_values.to(device)
            input_ids = input_ids.to(device)
            if attention_mask is not None:
                attention_mask = attention_mask.to(device)
            
            # ìƒì„± ì‹¤í–‰
            output = model.generate(
                pixel_values=pixel_values,
                input_ids=input_ids,
                attention_mask=attention_mask,
                max_new_tokens=args.max_tokens,
                temperature=args.temperature,
                do_sample=True,
                top_p=0.9,
                pad_token_id=tokenizer.pad_token_id,
                eos_token_id=tokenizer.eos_token_id
            )
        
        print(f"âœ… ì¶”ë¡  ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì¶”ë¡  ì‹¤íŒ¨: {e}")
        return
    
    # 5. ê²°ê³¼ ì¶œë ¥
    print("=" * 50)
    print("ğŸ¯ ê²°ê³¼")
    print("=" * 50)
    
    try:
        if isinstance(output, dict) and "text" in output:
            generated_text = output["text"][0]
        elif isinstance(output, torch.Tensor):
            # í† í° IDì—ì„œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            generated_text = tokenizer.decode(output[0], skip_special_tokens=True)
        else:
            generated_text = str(output)
        
        print(f"ğŸ“ ìƒì„±ëœ í…ìŠ¤íŠ¸:")
        print(f"   {generated_text}")
        
        # ì¶”ê°€ ì •ë³´
        print(f"\nğŸ“Š ìƒì„± ì •ë³´:")
        print(f"   - ì…ë ¥ ì´ë¯¸ì§€: {args.image}")
        print(f"   - í”„ë¡¬í”„íŠ¸: {args.prompt}")
        print(f"   - ìµœëŒ€ í† í°: {args.max_tokens}")
        print(f"   - ì˜¨ë„: {args.temperature}")
        print(f"   - ë””ë°”ì´ìŠ¤: {device}")
        
        # LoRA ì •ë³´ (ìˆë‹¤ë©´)
        lora_info = model.get_lora_info()
        if lora_info.get("is_lora_enabled", False):
            print(f"   - LoRA: Rank {lora_info.get('lora_r')}, Alpha {lora_info.get('lora_alpha')}")
        else:
            print(f"   - LoRA: ë¹„í™œì„±í™”")
        
    except Exception as e:
        print(f"âŒ ê²°ê³¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return
    
    print("=" * 50)
    print("ğŸ‰ ì¶”ë¡  ì™„ë£Œ!")


if __name__ == "__main__":
    main()