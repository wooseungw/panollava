# VLM í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì • ìš”ì•½

## ë¬¸ì œì 

`scripts/evaluate_vlm_models.py`ì—ì„œ Gemma3ì™€ LLaVA-OneVision ëª¨ë¸ì˜ ì˜ˆì¸¡(pred) ê²°ê³¼ê°€ ìƒì„±ë˜ì§€ ì•Šê³  í‰ê°€ ë©”íŠ¸ë¦­ë„ ì‘ë™í•˜ì§€ ì•ŠëŠ” ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤.

## ìˆ˜ì • ì‚¬í•­

### 1. LLaVA-OneVision ì²˜ë¦¬ ê°œì„  (ë¼ì¸ 820-930)

**ë¬¸ì œ**: LLaVA-OneVisionì€ `requires_vision_utils=True`ë¡œ ì„¤ì •ë˜ì–´ ìˆì—ˆì§€ë§Œ, ë°°ì¹˜ ì²˜ë¦¬ ë°©ì‹ì´ ë¶ˆì•ˆì •í–ˆìŠµë‹ˆë‹¤.

**ìˆ˜ì •**: 
- ë°°ì¹˜ ì²˜ë¦¬ì—ì„œ **ê°œë³„ ìƒ˜í”Œ ì²˜ë¦¬**ë¡œ ë³€ê²½
- ê° ìƒ˜í”Œë§ˆë‹¤ `process_vision_info`ë¥¼ í˜¸ì¶œí•˜ì—¬ ì´ë¯¸ì§€ ì…ë ¥ ì²˜ë¦¬
- ëª…í™•í•œ ë””ë²„ê·¸ ë¡œê¹… ì¶”ê°€
- ì˜ˆì™¸ ë°œìƒ ì‹œ ìƒì„¸í•œ ì—ëŸ¬ ì •ë³´ ì¶œë ¥

```python
# LLaVA-OneVisionê³¼ Qwen2.5-VLì€ ê°œë³„ ì²˜ë¦¬ê°€ ë” ì•ˆì •ì 
for sample_idx, (inst, img, ref, path) in enumerate(zip(...)):
    try:
        # ê°œë³„ ìƒ˜í”Œ ì²˜ë¦¬
        messages = [{"role": "user", "content": [...]}]
        text = self.processor.apply_chat_template(...)
        image_inputs, video_inputs = process_vision_info(messages)
        inputs = self.processor(text=[text], images=image_inputs, ...)
        outputs = self.model.generate(**inputs, **gen_kwargs)
        # ... ë””ì½”ë”© ë° ê²°ê³¼ ì €ì¥
    except Exception as e:
        # ìƒì„¸í•œ ì—ëŸ¬ ë¡œê¹…
        logging.error(f"âŒ ìƒ˜í”Œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        # ë¹ˆ ì˜ˆì¸¡ ì¶”ê°€í•˜ì—¬ ë ˆí¼ëŸ°ìŠ¤ì™€ ë§¤ì¹­ ìœ ì§€
        predictions.append("")
```

### 2. Gemma3 ì²˜ë¦¬ ê°œì„  (ë¼ì¸ 930-1050)

**ë¬¸ì œ**: Gemma3ì˜ ê°œë³„ ì²˜ë¦¬ëŠ” êµ¬í˜„ë˜ì–´ ìˆì—ˆì§€ë§Œ, ì˜ˆì™¸ ì²˜ë¦¬ê°€ ë¶ˆì¶©ë¶„í–ˆìŠµë‹ˆë‹¤.

**ìˆ˜ì •**:
- ì˜ˆì™¸ ë°œìƒ ì‹œ ë” ìƒì„¸í•œ ì •ë³´ ì¶œë ¥ (ì´ë¯¸ì§€ ê²½ë¡œ, instruction ë“±)
- ì—ëŸ¬ ë¡œê¹… ê°œì„ 

### 3. ë©”íŠ¸ë¦­ ê³„ì‚° ê°•í™” (ë¼ì¸ 300-370)

**ë¬¸ì œ**: 
- ë¹ˆ ì˜ˆì¸¡ì´ ìˆì„ ë•Œ ë©”íŠ¸ë¦­ ê³„ì‚°ì´ ì‹¤íŒ¨í•˜ê±°ë‚˜ ê²½ê³  ì—†ì´ ë„˜ì–´ê°
- eval.py ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨ ì‹œ tracebackì´ ì¶œë ¥ë˜ì§€ ì•ŠìŒ

**ìˆ˜ì •**:
```python
def compute_text_metrics(predictions, references):
    logging.info(f"ğŸ“Š ë©”íŠ¸ë¦­ ê³„ì‚° ì‹œì‘: {len(predictions)} predictions")
    
    # ë°ì´í„° ê²€ì¦
    valid_count = sum(1 for p, r in zip(predictions, references) 
                     if p.strip() and r.strip())
    empty_pred_count = sum(1 for p in predictions if not p.strip())
    
    logging.info(f"  - ìœ íš¨í•œ ìŒ: {valid_count}/{len(predictions)}")
    logging.info(f"  - ë¹ˆ ì˜ˆì¸¡: {empty_pred_count}")
    
    if valid_count == 0:
        logging.error("âŒ ìœ íš¨í•œ ì˜ˆì¸¡-ì •ë‹µ ìŒì´ ì—†ìŠµë‹ˆë‹¤!")
        return {}
```

### 4. í‰ê°€ ì™„ë£Œ ìš”ì•½ ê°œì„  (ë¼ì¸ 1115-1140)

**ë¬¸ì œ**: ë¹ˆ ì˜ˆì¸¡ì´ ìˆì„ ë•Œ ì–´ë–¤ ìƒ˜í”Œì—ì„œ ë¬¸ì œê°€ ë°œìƒí–ˆëŠ”ì§€ ì•Œ ìˆ˜ ì—†ìŒ

**ìˆ˜ì •**:
```python
empty_pred_count = sum(1 for p in predictions if not p.strip())
if empty_pred_count > 0:
    logging.warning(f"âš ï¸ {empty_pred_count}ê°œì˜ ë¹ˆ ì˜ˆì¸¡ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
    # ì²˜ìŒ 5ê°œì˜ ë¹ˆ ì˜ˆì¸¡ ìƒ˜í”Œ ì •ë³´ ì¶œë ¥
    empty_indices = [i for i, p in enumerate(predictions) if not p.strip()][:5]
    for idx in empty_indices:
        logging.warning(f"  - ìƒ˜í”Œ {idx}: image={image_paths[idx]}")
        logging.warning(f"    instruction={instructions[idx][:80]}...")
```

## í…ŒìŠ¤íŠ¸ ë°©ë²•

### 1. ì†Œê·œëª¨ í…ŒìŠ¤íŠ¸ (ê¶Œì¥)

```bash
# Gemma3 í…ŒìŠ¤íŠ¸ (1ê°œ ìƒ˜í”Œë§Œ)
python scripts/evaluate_vlm_models.py \
  --data_csv data/train_stanford_dummy_anno.csv \
  --models gemma-3-4b \
  --max_samples 1 \
  --log_level DEBUG \
  --output_dir eval_results/debug

# LLaVA-OneVision í…ŒìŠ¤íŠ¸ (1ê°œ ìƒ˜í”Œë§Œ)
python scripts/evaluate_vlm_models.py \
  --data_csv data/train_stanford_dummy_anno.csv \
  --models llava-onevision-0.5b \
  --max_samples 1 \
  --log_level DEBUG \
  --output_dir eval_results/debug
```

### 2. ì „ì²´ í…ŒìŠ¤íŠ¸

```bash
# ì—¬ëŸ¬ ëª¨ë¸ í‰ê°€ (10ê°œ ìƒ˜í”Œ)
python scripts/evaluate_vlm_models.py \
  --data_csv data/train_stanford_dummy_anno.csv \
  --models gemma-3-4b llava-onevision-0.5b llava-onevision-7b \
  --max_samples 10 \
  --log_level INFO \
  --output_dir eval_results
```

## ë””ë²„ê¹… íŒ

### 1. ë¡œê·¸ í™•ì¸

ë””ë²„ê·¸ ëª¨ë“œ(`--log_level DEBUG`)ì—ì„œ ë‹¤ìŒ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”:

```
ğŸ” [DEBUG] Using vision_utils path for llava-onevision-0.5b
ğŸ” [DEBUG] Processing 1 samples individually
ğŸ” [DEBUG] === Sample 0/1 ===
ğŸ” [DEBUG] Instruction: ...
ğŸ” [DEBUG] Chat template output length: 123
ğŸ” [DEBUG] image_inputs=1, video_inputs=0
ğŸ” [DEBUG] Processor output keys: dict_keys([...])
ğŸ” [DEBUG] Starting generation...
ğŸ” [DEBUG] Generation complete. Output shape: torch.Size([1, 456])
ğŸ” [DEBUG] Decoded prediction: ...
```

### 2. ì—ëŸ¬ ë°œìƒ ì‹œ

ì—ëŸ¬ê°€ ë°œìƒí•˜ë©´ ë‹¤ìŒ ì •ë³´ê°€ ì¶œë ¥ë©ë‹ˆë‹¤:

```
âŒ ìƒ˜í”Œ ì²˜ë¦¬ ì‹¤íŒ¨ (batch=0, sample=0, model=gemma-3-4b)
   Error: ...
   Image: data/path/to/image.jpg
   Instruction: What is shown in this image?...
   Traceback:
   ...
```

### 3. ë¹ˆ ì˜ˆì¸¡ í™•ì¸

í‰ê°€ ì™„ë£Œ í›„ ë‹¤ìŒê³¼ ê°™ì€ ìš”ì•½ì´ ì¶œë ¥ë©ë‹ˆë‹¤:

```
âœ… í‰ê°€ ì™„ë£Œ: gemma-3-4b
ì´ ì˜ˆì¸¡ ìˆ˜: 10
ì´ ë ˆí¼ëŸ°ìŠ¤ ìˆ˜: 10
ë¹ˆ ì˜ˆì¸¡ ìˆ˜: 3
âš ï¸ 3ê°œì˜ ë¹ˆ ì˜ˆì¸¡ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤!
  - ìƒ˜í”Œ 2: image=data/...
    instruction=Describe the scene...
```

### 4. ë©”íŠ¸ë¦­ ê³„ì‚° í™•ì¸

```
ğŸ“Š ë©”íŠ¸ë¦­ ê³„ì‚° ì‹œì‘: 10 predictions, 10 references
  - ìœ íš¨í•œ ìŒ: 7/10
  - ë¹ˆ ì˜ˆì¸¡: 3
  - ë¹ˆ ì°¸ì¡°: 0
ğŸ“Š ë¡œì»¬ ë©”íŠ¸ë¦­ ê³„ì‚°: 7 ìœ íš¨ ìŒ
```

## ì˜ˆìƒ ê²°ê³¼

ìˆ˜ì • í›„ ë‹¤ìŒê³¼ ê°™ì€ ê°œì„ ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. **Gemma3**: ì˜ˆì¸¡ì´ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ë©°, ì—ëŸ¬ ë°œìƒ ì‹œ ìƒì„¸í•œ ì •ë³´ ì¶œë ¥
2. **LLaVA-OneVision**: ê°œë³„ ìƒ˜í”Œ ì²˜ë¦¬ë¡œ ì•ˆì •ì„± í–¥ìƒ, ì˜ˆì¸¡ ìƒì„± ì„±ê³µ
3. **ë©”íŠ¸ë¦­ ê³„ì‚°**: ë¹ˆ ì˜ˆì¸¡ì´ ìˆì–´ë„ ìœ íš¨í•œ ìƒ˜í”Œì— ëŒ€í•´ ë©”íŠ¸ë¦­ ê³„ì‚°
4. **ë””ë²„ê¹…**: ëª…í™•í•œ ë¡œê·¸ë¡œ ë¬¸ì œ ì›ì¸ íŒŒì•… ìš©ì´

## ê²°ê³¼ íŒŒì¼

í‰ê°€ ì™„ë£Œ í›„ ë‹¤ìŒ íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤:

```
eval_results/
â””â”€â”€ ablation/
    â”œâ”€â”€ gemma-3-4b/
    â”‚   â”œâ”€â”€ metrics.json        # ë©”íŠ¸ë¦­ ê²°ê³¼
    â”‚   â””â”€â”€ predictions.csv     # ì˜ˆì¸¡ ê²°ê³¼ (instruction, reference, prediction)
    â””â”€â”€ llava-onevision-0.5b/
        â”œâ”€â”€ metrics.json
        â””â”€â”€ predictions.csv
```

## ì¶”ê°€ ê°œì„  ì‚¬í•­ (í–¥í›„)

1. **ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”**: Gemma3ì™€ LLaVA-OneVisionì˜ ë°°ì¹˜ ì²˜ë¦¬ ì•ˆì •í™”
2. **ì¬ì‹œë„ ë¡œì§**: ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ ë“± ì¼ì‹œì  ë¬¸ì œ ì‹œ ìë™ ì¬ì‹œë„
3. **ìºì‹±**: ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ê²°ê³¼ ìºì‹±ìœ¼ë¡œ ì†ë„ í–¥ìƒ
4. **ë³‘ë ¬ ì²˜ë¦¬**: ì—¬ëŸ¬ ëª¨ë¸ í‰ê°€ ì‹œ ë³‘ë ¬ ì‹¤í–‰

## ë¬¸ì˜ì‚¬í•­

ë¬¸ì œê°€ ê³„ì†ë˜ë©´ ë‹¤ìŒ ì •ë³´ì™€ í•¨ê»˜ ë¬¸ì˜í•˜ì„¸ìš”:

1. ì „ì²´ ë¡œê·¸ (`--log_level DEBUG`)
2. ì‚¬ìš©í•œ ëª…ë ¹ì–´
3. `predictions.csv` íŒŒì¼ (ì²˜ìŒ ëª‡ í–‰)
4. GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (`nvidia-smi`)
