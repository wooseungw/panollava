{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093f9482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from typing import Optional, List, Dict, Any\n",
    "\n",
    "from panovlm.model import PanoramaVLM\n",
    "from panovlm.processors.image import PanoramaImageProcessor\n",
    "\n",
    "def denormalize(tensor):\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    tensor = tensor.clone().permute(1, 2, 0).numpy()\n",
    "    tensor = std * tensor + mean\n",
    "    tensor = np.clip(tensor, 0, 1)\n",
    "    return tensor\n",
    "\n",
    "def visualize_views(\n",
    "    pixel_values: torch.Tensor,\n",
    "    title: str,\n",
    "    *,  # [핵심 수정] 이 뒤의 인자는 반드시 키워드로만 전달해야 함\n",
    "    titles: Optional[List[str]] = None,\n",
    "    filename: Optional[str] = None,\n",
    "    show_plot: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Create and save or show a visualization of the processed views.\n",
    "    Optional arguments after '*' must be passed as keyword arguments.\n",
    "    \"\"\"\n",
    "    if not filename and not show_plot:\n",
    "        print(\"Warning: No action taken. Either 'filename' must be provided or 'show_plot' must be True.\")\n",
    "        return\n",
    "\n",
    "    views = pixel_values.squeeze(0)\n",
    "    num_views = views.shape[0]\n",
    "    \n",
    "    if num_views <= 4:\n",
    "        nrows, ncols = 1, num_views\n",
    "    else:\n",
    "        nrows = 2\n",
    "        ncols = math.ceil(num_views / 2)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(ncols * 4, nrows * 4 + 1))\n",
    "    axes = np.ravel(axes)\n",
    "    \n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    \n",
    "    for i in range(num_views):\n",
    "        view_tensor = views[i]\n",
    "        img = denormalize(view_tensor)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        if titles and i < len(titles):\n",
    "            axes[i].set_title(titles[i])\n",
    "\n",
    "    for i in range(num_views, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    \n",
    "    if filename:\n",
    "        plt.savefig(filename)\n",
    "        print(f\"Saved visualization to {filename}\")\n",
    "    \n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "checkpoint_path = 'runs/siglipv2qwen25Instruct_e2p_finetune_mlp/best_v1.ckpt'\n",
    "# 설정 시스템을 통한 모델 로딩\n",
    "model = PanoramaVLM.from_checkpoint(checkpoint_path, device=\"auto\")\n",
    "model.eval()\n",
    "\n",
    "sample_image = \"data/quic360/downtest/images/26286679561_2bc4360f7d_f.jpg\"\n",
    "sample_text = \"이 사진에서 가장 눈에 띄는 것은 무엇인가요?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1a8687",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_proc = PanoramaImageProcessor(\n",
    "    image_size    =(224, 224),\n",
    "    crop_strategy =\"e2p\",   # 또는 \"e2p\" / \"cubemap\" /\"anyres\"/\"sliding_window\"\n",
    "    fov_deg       =90,\n",
    "    overlap_ratio =0.5,\n",
    "    normalize= True,\n",
    "    anyres_max_patches=8\n",
    ")\n",
    "\n",
    "img = img_proc(sample_image)\n",
    "img = img.unsqueeze(0)  # 배치 차원 추가\n",
    "visualize_views(img, title=\"Sample Image\", show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a6eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_views, normalized_pixels = model._normalize_pixel_values(img.cuda())\n",
    "print(f\"Batch size: {batch_size}, Number of views: {num_views}, Normalized pixels shape: {normalized_pixels.shape}\")\n",
    "\n",
    "last_hidden_states = model._extract_vision_features(\n",
    "    pixel_values=normalized_pixels,\n",
    "    batch_size=batch_size,\n",
    "    num_views=num_views\n",
    ")\n",
    "print(f\"Last hidden states shape: {last_hidden_states.shape}\")\n",
    "last_hidden_states = last_hidden_states.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0191afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from panovlm.vis.dino import DinoVisualizer\n",
    "visualizer = DinoVisualizer(last_hidden_states,remove_cls_token=False)\n",
    "visualizer.fit_pca(use_global_scaling=True)\n",
    "visualizer.get_hidden_similarity()\n",
    "metadata = img_proc.view_metadata  # E2P에서 자동 생성\n",
    "similarity = visualizer.get_hidden_similarity(\n",
    "    pairs=[(0, 1)], view_metadata=metadata\n",
    ")\n",
    "visualizer.plot_pca_results(\n",
    "    titles=checkpoint_path.split(\"/\")[1],\n",
    "    save_path=f\"{checkpoint_path.split(\"/\")[1]}.png\",\n",
    "    )\n",
    "\n",
    "visualizer.create_comprehensive_dashboard(\n",
    "    titles=checkpoint_path.split(\"/\")[1],\n",
    "    view_metadata=metadata,\n",
    "    save_path=f\"{checkpoint_path.split('/')[1]}_dashboard.png\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panovlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
