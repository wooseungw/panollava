# coding: utf-8
"""
Panorama-VLM Training (Config-only)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- ë‹¨ì¼ config.json ì—ì„œë§Œ ëª¨ë“  ì„¤ì •ì„ ì½ìŒ (CLI ì˜¤ë²„ë¼ì´ë“œ ì—†ìŒ)
- stages:
    â€¢ "training.default_stage": ë‹¨ì¼ ìŠ¤í…Œì´ì§€ ì‹¤í–‰
    â€¢ "training.stages": ["vision","resampler","finetune"] ê°™ì´ ì—¬ëŸ¬ ìŠ¤í…Œì´ì§€ ìˆœì°¨ ì‹¤í–‰
"""

import os
# Silence HF tokenizers fork/parallelism warnings and avoid deadlocks
os.environ.setdefault("TOKENIZERS_PARALLELISM", "false")

import sys
import json
import time
import gc
import logging
from pathlib import Path
from typing import Dict, Any, Optional
from copy import deepcopy

import torch
torch.set_float32_matmul_precision("high")

import lightning as pl
from lightning.pytorch.loggers import WandbLogger
from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint
from lightning.pytorch.tuner import Tuner

# Plot ì €ì¥ì„ ìœ„í•œ matplotlib (ì„ íƒì )
try:
    import matplotlib
    matplotlib.use('Agg')  # GUI ì—†ì´ ì‚¬ìš©
    import matplotlib.pyplot as plt
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    MATPLOTLIB_AVAILABLE = False

# â”€â”€ ë‚´ë¶€ ëª¨ë“ˆ ---------------------------------------------------------------
from panovlm.dataset   import VLMDataModule
from panovlm.model     import PanoramaVLM
from panovlm.utils     import *
from panovlm.config    import Config, ModelConfig, ConfigManager
# ----------------------------------------------------------------------------

# â”€â”€ ë¡œê¹… ì„¤ì • ---------------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(message)s",
    handlers=[logging.StreamHandler(sys.stdout), logging.FileHandler("training.log")]
)
logger = logging.getLogger("panovlm.train")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LightningModule
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class VLMModule(pl.LightningModule):
    """Panorama VLM Lightning ë˜í¼ (stage-aware)"""
    _STAGE_MAP = {"vision": "vision", "resampler": "resampler", "finetune": "finetune", "generate": "generate"}

    def __init__(self, *, stage: str, model_config: ModelConfig, lr: float,
                 use_lora_cfg: Dict[str, Any], pretrained_dir: Optional[str] = None):
        super().__init__()
        self.save_hyperparameters(ignore=["model_config"])  # hparamsì— ëœì–´ëƒ„
        self.model_config: ModelConfig = model_config
        self.lr = lr  # ëª…ì‹œì ìœ¼ë¡œ ì €ì¥
        self.learning_rate = lr  # Lightning Tunerë¥¼ ìœ„í•œ ì†ì„±

        # ëª¨ë¸ ìƒì„± ìš°ì„ ìˆœìœ„: pretrained_dir(.ckpt ë˜ëŠ” HF ë””ë ‰í† ë¦¬) > scratch
        if pretrained_dir and os.path.isdir(pretrained_dir):
            logger.info(f"ğŸ§© Loading from pretrained dir: {pretrained_dir}")
            try:
                self.model = PanoramaVLM.from_pretrained_dir(
                    pretrained_dir,
                    **self.model_config.get_model_kwargs()
                )
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to load pretrained dir ({pretrained_dir}): {e}. Falling back to scratch init.")
                self.model = PanoramaVLM(**self.model_config.get_model_kwargs())
        elif pretrained_dir and os.path.isfile(pretrained_dir) and str(pretrained_dir).endswith('.ckpt'):
            logger.info(f"ğŸ§© Loading from checkpoint file: {pretrained_dir}")
            try:
                self.model = PanoramaVLM.from_checkpoint(
                    pretrained_dir,
                    **self.model_config.get_model_kwargs()
                )
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to load checkpoint file ({pretrained_dir}): {e}. Falling back to scratch init.")
                self.model = PanoramaVLM(**self.model_config.get_model_kwargs())
        else:
            self.model = PanoramaVLM(**self.model_config.get_model_kwargs())

        # stage ê²€ì¦/ë§¤í•‘
        if stage not in self._STAGE_MAP:
            raise ValueError(f"stageëŠ” {list(self._STAGE_MAP.keys())} ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤ (got: {stage})")
        self._stage_key = self._STAGE_MAP[stage]

        # LoRA ì„¤ì • (finetuneì—ì„œë§Œ ì ìš©)
        self.use_lora: bool = bool(use_lora_cfg.get("use_lora", False))
        if self.use_lora and stage == "finetune":
            logger.info("Setting up LoRA for finetune stage...")
            lora_kwargs = {
                "lora_r": use_lora_cfg.get("rank", 16),
                "lora_alpha": use_lora_cfg.get("alpha", 32),
                "lora_dropout": use_lora_cfg.get("dropout", 0.1),
                "target_modules": use_lora_cfg.get("target_modules", None),
            }
            ok = self.model.setup_lora_for_finetune(**lora_kwargs)
            if ok:
                logger.info(f"âœ“ LoRA setup completed: {lora_kwargs}")
            else:
                logger.warning("âš  LoRA setup failed, continue with full finetune")
        elif self.use_lora and stage != "finetune":
            logger.warning(f"âš  LoRAëŠ” finetune ë‹¨ê³„ì—ì„œë§Œ í™œì„±í™”ë©ë‹ˆë‹¤. (í˜„ì¬: {stage}) â†’ ë¬´ì‹œ")

        # stageë³„ ë™ê²°/í•´ì œ
        self._freeze_for_stage(stage)

        # ë©”íƒ€ë°ì´í„°(hparams)ì— í•µì‹¬ ì„¤ì • ì €ì¥
        self._prepare_checkpoint_metadata()

    # â”€â”€ Lightning í‘œì¤€ ë©”ì„œë“œë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def forward(self, **batch):
        return self.model(stage=self._stage_key, **batch)

    def training_step(self, batch, batch_idx):
        try:
            # ë©”ëª¨ë¦¬ ìµœì í™”: gradient checkpointing í™œì„±í™”
            if hasattr(self.model, 'gradient_checkpointing_enable'):
                self.model.gradient_checkpointing_enable()
            
            # ë©”ëª¨ë¦¬ ìµœì í™”: ì¤‘ê°„ ê²°ê³¼ë¬¼ë“¤ì„ ì¦‰ì‹œ í•´ì œ
            with torch.cuda.device(self.device) if torch.cuda.is_available() else torch.no_grad():
                out = self(**batch)
                loss = out["loss"]

            # ë°°ì¹˜í¬ê¸°
            bs = None
            try:
                if isinstance(batch.get("pixel_values"), torch.Tensor):
                    bs = batch["pixel_values"].size(0)
            except Exception:
                pass

            # ìˆ˜ì¹˜ ì•ˆì •ì„±
            if not torch.isfinite(loss):
                logger.error(f"Non-finite loss at step {self.global_step}: {loss}")
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                if 'out' in locals():
                    del out
                torch.cuda.empty_cache() if torch.cuda.is_available() else None
                return None

            # ë¡œê¹…
            kw = dict(prog_bar=True, sync_dist=True)
            if bs is not None: kw["batch_size"] = bs
            self.log("loss", loss, **kw)

            if "vicreg_loss" in out:
                self.log("train_vicreg_loss", out["vicreg_loss"], prog_bar=False, sync_dist=False, **({"batch_size": bs} if bs else {}))
            if "ar_loss" in out:
                self.log("train_ar_loss", out["ar_loss"], prog_bar=False, sync_dist=False, **({"batch_size": bs} if bs else {}))

            # wandb logger ì¶”ê°€ ë©”íŠ¸ë¦­
            if self.trainer.logger is not None and batch_idx % 10 == 0:
                self.trainer.logger.log_metrics({
                    "train_loss": float(loss.detach().cpu()),
                    "learning_rate": self.trainer.optimizers[0].param_groups[0]["lr"],
                    "global_step": self.global_step
                }, step=self.global_step)

            return loss

        except RuntimeError as e:
            if "out of memory" in str(e).lower():
                logger.error(f"OOM in training step {self.global_step}")
                # ì ê·¹ì ì¸ ë©”ëª¨ë¦¬ ì •ë¦¬
                if 'out' in locals():
                    del out
                if 'loss' in locals():
                    del loss
                # ë°°ì¹˜ ë°ì´í„°ë„ ì •ë¦¬
                for key in list(batch.keys()):
                    if torch.is_tensor(batch[key]):
                        del batch[key]
                # GPU ë©”ëª¨ë¦¬ ì™„ì „íˆ ë¹„ìš°ê¸°
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    torch.cuda.synchronize()
                import gc
                gc.collect()
                # ë©”ëª¨ë¦¬ ìƒíƒœ ë¡œê¹…
                if torch.cuda.is_available():
                    memory_allocated = torch.cuda.memory_allocated() / (1024**3)  # GB
                    memory_reserved = torch.cuda.memory_reserved() / (1024**3)   # GB
                    logger.error(f"GPU Memory - Allocated: {memory_allocated:.2f}GB, Reserved: {memory_reserved:.2f}GB")
                return None
            else:
                logger.error(f"Runtime error in training step {self.global_step}: {e}")
                # ì¼ë°˜ ëŸ°íƒ€ì„ ì—ëŸ¬ì—ë„ ë©”ëª¨ë¦¬ ì •ë¦¬
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                return None
        except Exception as e:
            logger.error(f"Unexpected error in training step {self.global_step}: {e}")
            import traceback
            logger.error("Traceback:\n" + traceback.format_exc())
            return None

    def validation_step(self, batch, batch_idx):
        try:
            # ë°°ì¹˜ ì •ë³´ ë¡œê¹… (ì²« ë²ˆì§¸ ë°°ì¹˜ì—ì„œë§Œ)
            if batch_idx == 0:
                logger.info(f"[VAL] First validation batch keys: {list(batch.keys())}")
                if "pixel_values" in batch:
                    logger.info(f"[VAL] pixel_values shape: {batch['pixel_values'].shape}")
            
            out = self(**batch)
            if "loss" not in out:
                logger.error(f"[VAL] No 'loss' key in model output. Keys: {list(out.keys())}")
                return None
                
            loss = out["loss"]

            bs = None
            try:
                if isinstance(batch.get("pixel_values"), torch.Tensor):
                    bs = batch["pixel_values"].size(0)
            except Exception:
                pass

            if not torch.isfinite(loss):
                logger.warning(f"[VAL] Non-finite val loss at step {batch_idx}: {loss}")
                return None

            # ë©”íŠ¸ë¦­ ë¡œê¹… - on_epoch=True ì¶”ê°€ë¡œ epoch ë ˆë²¨ì—ì„œ ì§‘ê³„ë˜ë„ë¡ í•¨
            kw = dict(prog_bar=True, sync_dist=True, on_epoch=True, on_step=False)
            if bs is not None: kw["batch_size"] = bs
            self.log("val_loss", loss, **kw)

            # ì¶”ê°€ ë©”íŠ¸ë¦­ë“¤ë„ on_epoch=Trueë¡œ ì„¤ì •
            if "vicreg_loss" in out:
                kw_extra = dict(prog_bar=False, sync_dist=False, on_epoch=True, on_step=False)
                if bs is not None: kw_extra["batch_size"] = bs
                self.log("val_vicreg_loss", out["vicreg_loss"], **kw_extra)
            if "ar_loss" in out:
                kw_extra = dict(prog_bar=False, sync_dist=False, on_epoch=True, on_step=False)
                if bs is not None: kw_extra["batch_size"] = bs
                self.log("val_ar_loss", out["ar_loss"], **kw_extra)

            # ì²« ë²ˆì§¸ validation stepì—ì„œ ì„±ê³µ ë©”ì‹œì§€
            if batch_idx == 0:
                logger.info(f"[VAL] First validation step successful. Loss: {loss.item():.6f}")

            return loss

        except RuntimeError as e:
            if "out of memory" in str(e).lower():
                logger.error(f"[VAL] OOM in validation step {batch_idx}")
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                if hasattr(torch.cuda, 'empty_cache'):
                    torch.cuda.empty_cache()
                import gc
                gc.collect()
                return None
            else:
                logger.error(f"[VAL] Runtime error in validation step {batch_idx}: {e}")
                return None
        except Exception as e:
            logger.error(f"[VAL] Error in validation step {batch_idx}: {e}")
            import traceback
            logger.error("Traceback:\n" + traceback.format_exc())
            return None

    # â”€â”€ ë‚´ë¶€ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _freeze_for_stage(self, stage: str):
        self.model.requires_grad_(False)
        if stage == "vision":
            # íŒŒë…¸ë¼ë§ˆ ì ì‘ì„ ìœ„í•œ ì„ íƒì  vision encoder í•™ìŠµ
            self.model.resampler.requires_grad_(True)
            self.model.vicreg_projector.requires_grad_(True)
            logger.info("âœ“ Stage 1: Selective vision layers + Resampler + VICReg projector unfrozen")
        elif stage == "resampler":
            # ë” ë§ì€ vision encoder ë ˆì´ì–´ í•´ì œ
            
            self.model.resampler.requires_grad_(True)
            self.model.vision_to_language_projection.requires_grad_(True)
            logger.info("âœ“ Stage 2: Progressive vision layers + Resampler + Projection unfrozen")
        elif stage == "finetune":
            # ì „ì²´ vision encoder ë¯¸ì„¸ì¡°ì • (ë‚®ì€ í•™ìŠµë¥ ë¡œ)
            
            self.model.resampler.requires_grad_(True)
            self.model.vision_to_language_projection.requires_grad_(True)
            if not self.use_lora:
                for p in self.model.language_model.parameters():
                    p.requires_grad = True
                logger.info("âœ“ Stage 3: Full model with adaptive learning rates")
            else:
                logger.info("âœ“ Stage 3: Vision + LoRA adapters with adaptive rates")

        trainable = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        total = sum(p.numel() for p in self.model.parameters())
        logger.info(f"Trainable parameters: {trainable:,}/{total:,} ({trainable/total:.1%})")


    def configure_optimizers(self):
        """íŒŒë…¸ë¼ë§ˆ ì ì‘ì„ ìœ„í•œ ì°¨ë³„í™”ëœ í•™ìŠµë¥  ì ìš©"""
        # íŒŒë¼ë¯¸í„° ê·¸ë£¹ ë¶„ë¦¬
        vision_params = []
        resampler_params = []
        projection_params = []
        lm_params = []
        other_params = []
        
        for name, param in self.named_parameters():
            if not param.requires_grad:
                continue
                
            if 'vision_encoder' in name:
                vision_params.append(param)
            elif 'resampler' in name:
                resampler_params.append(param)
            elif 'vision_to_language_projection' in name or 'vicreg_projector' in name:
                projection_params.append(param)
            elif 'language_model' in name:
                lm_params.append(param)
            else:
                other_params.append(param)
        
        # ê¸°ë³¸ í•™ìŠµë¥  (LR Finderê°€ ì—…ë°ì´íŠ¸í•  ìˆ˜ ìˆìŒ)
        base_lr = getattr(self, 'learning_rate', self.hparams.lr)
        
        # íŒŒë¼ë¯¸í„° ê·¸ë£¹ë³„ ì°¨ë³„í™”ëœ í•™ìŠµë¥ 
        param_groups = []
        if vision_params:
            param_groups.append({
                'params': vision_params, 
                'lr': base_lr * 0.1,  # visionì€ 10ë°° ë‚®ì€ í•™ìŠµë¥ 
                'weight_decay': 0.01
            })
        if resampler_params:
            param_groups.append({
                'params': resampler_params, 
                'lr': base_lr,  # ê¸°ë³¸ í•™ìŠµë¥ 
                'weight_decay': 0.05
            })
        if projection_params:
            param_groups.append({
                'params': projection_params, 
                'lr': base_lr,  # ê¸°ë³¸ í•™ìŠµë¥ 
                'weight_decay': 0.05
            })
        if lm_params:
            param_groups.append({
                'params': lm_params, 
                'lr': base_lr * 0.5,  # LMì€ ì ˆë°˜ í•™ìŠµë¥ 
                'weight_decay': 0.01
            })
        if other_params:
            param_groups.append({
                'params': other_params, 
                'lr': base_lr,
                'weight_decay': 0.05
            })
        
        optimizer = torch.optim.AdamW(param_groups, betas=(0.9, 0.98), eps=1e-8)
        
        logger.info(f"Optimizer groups: Vision({len(vision_params)} params, lr={base_lr*0.1}), "
                   f"Resampler({len(resampler_params)} params, lr={base_lr}), "
                   f"Projection({len(projection_params)} params, lr={base_lr})")
        
        # ìŠ¤ì¼€ì¤„ëŸ¬
        try:
            from transformers import get_linear_schedule_with_warmup
            steps_per_epoch = len(self.trainer.datamodule.train_dataloader())
            total_steps = steps_per_epoch * self.trainer.max_epochs
            warmup_steps = max(1, int(0.1 * total_steps))
            sch = get_linear_schedule_with_warmup(optimizer, warmup_steps, total_steps)
            logger.info(f"âœ“ Scheduler: warmup {warmup_steps}, total {total_steps}")
            return [optimizer], [{"scheduler": sch, "interval": "step"}]
        except Exception as e:
            logger.warning(f"Scheduler init failed: {e}; Using optimizer only.")
            return optimizer

    def _prepare_checkpoint_metadata(self):
        meta = {
            "vision_name": self.model_config.vision_name,
            "language_model_name": self.model_config.language_model_name,
            "resampler_type": self.model_config.resampler_type,
            "latent_dimension": self.model_config.latent_dimension,
            "vicreg_loss_weight": self.model_config.vicreg_loss_weight,
            "overlap_ratio": self.model_config.overlap_ratio,
            "max_text_length": self.model_config.max_text_length,
            "stage": self._stage_key,
            "use_lora": self.use_lora
        }
        for k, v in meta.items():
            if k not in self.hparams:
                self.hparams[k] = v
        logger.info(f"âœ“ ì²´í¬í¬ì¸íŠ¸ ë©”íƒ€ë°ì´í„° ì¤€ë¹„ ({len(meta)} í•­ëª©)")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì½œë°±: ê°„ë‹¨ ëª¨ë‹ˆí„°ë§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class BatchSizeMonitorCallback(pl.Callback):
    def on_train_start(self, trainer, pl_module):
        logger.info("=== TRAIN START ===")
        # ëª¨ë¸ ì„¤ì •
        mc: ModelConfig = pl_module.model_config
        logger.info(f"[MODEL] vision={mc.vision_name} | lm={mc.language_model_name} | resampler={mc.resampler_type} | dim={mc.latent_dimension}")
        logger.info(f"[TEXT] max_len={mc.max_text_length} | LoRA={pl_module.use_lora}")
        # ë°ì´í„°ì…‹/ë¡œë”
        logger.info(f"[DATA] train_csv={trainer.datamodule.hparams.csv_train}")
        logger.info(f"[DATA] val_csv={trainer.datamodule.hparams.csv_val}")
        logger.info(f"[DATA] image_size={trainer.datamodule.hparams.image_size} | crop={trainer.datamodule.hparams.crop_strategy}")
        # ë¡œë” í¬ê¸°
        logger.info(f"[LOADER] train_batches={len(trainer.datamodule.train_dataloader())} | val_batches={len(trainer.datamodule.val_dataloader())}")
        # í™˜ê²½
        if torch.cuda.is_available():
            logger.info(f"[GPU] count={torch.cuda.device_count()} | name={torch.cuda.get_device_name()}")

    def on_train_epoch_start(self, trainer, pl_module):
        _ = pl_module  # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë§¤ê°œë³€ìˆ˜ ë¬´ì‹œ
        logger.info(f"[Epoch {trainer.current_epoch}] start")

    def on_train_epoch_end(self, trainer, pl_module):
        # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë§¤ê°œë³€ìˆ˜ë“¤ì„ ëª…ì‹œì ìœ¼ë¡œ ë¬´ì‹œ
        _ = trainer, pl_module

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹¤í–‰ ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_config_dict() -> Dict[str, Any]:
    """config.json ë¡œë“œ (í™˜ê²½ë³€ìˆ˜ PANOVLM_CONFIGë¡œ ê²½ë¡œ ì§€ì • ê°€ëŠ¥)"""
    cfg_path = os.environ.get("PANOVLM_CONFIG", "config.json")
    p = Path(cfg_path)
    if not p.exists():
        raise FileNotFoundError(f"Config file not found: {p.resolve()}")
    with open(p, "r", encoding="utf-8") as f:
        cfg = json.load(f)
    logger.info(f"âœ“ Loaded config: {p}")
    return cfg

def get_stage_list(cfg: Dict[str, Any]):
    tr = cfg.get("training", {})
    stages = tr.get("stages", None)
    if isinstance(stages, list) and len(stages) > 0:
        return stages
    default_stage = tr.get("default_stage", None)
    if isinstance(default_stage, str):
        return [default_stage]
    # fallback
    return ["vision"]

def stage_defaults(cfg: Dict[str, Any], stage: str) -> Dict[str, Any]:
    """ì½”ë“œ ê¸°ë³¸ + íŒŒì¼ ì„¤ì • ë³‘í•© (íŒŒì¼ ìš°ì„ )"""
    code_default = Config.STAGE_DEFAULTS.get(stage, {})
    training_cfg = cfg.get("training", {}) or {}
    stage_configs = training_cfg.get("stage_configs")
    if isinstance(stage_configs, dict):
        file_default = stage_configs.get(stage, {}) or {}
    else:
        file_default = training_cfg.get(stage, {}) or {}
    merged = {**code_default, **file_default}
    return merged

def _infer_default_image_size(vision_model_name: Optional[str]) -> Optional[tuple[int, int]]:
    if not vision_model_name:
        return None
    name = str(vision_model_name).lower()
    size_candidates = [
        720, 704, 640, 608, 600, 576, 560, 512, 500, 480, 448,
        432, 416, 400, 392, 384, 368, 360, 352, 336, 320,
        312, 300, 288, 272, 256, 240, 224
    ]
    for candidate in size_candidates:
        token = str(candidate)
        if token in name:
            return (candidate, candidate)
    return (224, 224)


def _resolve_stage_image_processing(cfg: Dict[str, Any], stage_cfg: Dict[str, Any]) -> Dict[str, Any]:
    """Merge global image_processing config with per-stage overrides."""
    base = dict(cfg.get("image_processing", {}) or {})
    # ëª…ì‹œì ìœ¼ë¡œ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš° Vision ëª¨ë¸ ì´ë¦„ì„ stage-levelë¡œ í—ˆìš©
    models_cfg = cfg.get("models", {}) or {}
    if "vision_model_name" not in base and models_cfg.get("vision_model_name"):
        base["vision_model_name"] = models_cfg.get("vision_model_name")
    stage_overrides = None

    if isinstance(stage_cfg, dict):
        stage_overrides = stage_cfg.get("image_processing")

    if isinstance(stage_overrides, dict):
        base.update(stage_overrides)

    if not base.get("image_size") and base.get("vision_model_name"):
        inferred = _infer_default_image_size(base.get("vision_model_name"))
        if inferred:
            base["image_size"] = list(inferred)

    return base


def _normalize_data_paths(value):
    if value is None:
        return None
    if isinstance(value, (list, tuple)):
        return [str(v) for v in value if v is not None]
    return str(value)


def _resolve_stage_data(cfg: Dict[str, Any], stage_cfg: Dict[str, Any]) -> tuple[Any, Any]:
    paths_cfg = cfg.get("paths", {}) or {}
    data_cfg = cfg.get("data", {}) or {}

    base_train = (
        _normalize_data_paths(paths_cfg.get("csv_train"))
        or _normalize_data_paths(data_cfg.get("csv_train"))
        or _normalize_data_paths(data_cfg.get("train"))
    )
    base_val = (
        _normalize_data_paths(paths_cfg.get("csv_val"))
        or _normalize_data_paths(data_cfg.get("csv_val"))
        or _normalize_data_paths(data_cfg.get("val"))
    )

    stage_train = base_train
    stage_val = base_val

    if isinstance(stage_cfg, dict):
        stage_data = stage_cfg.get("data") or {}
        if stage_data:
            train_override = (
                _normalize_data_paths(stage_data.get("csv_train"))
                or _normalize_data_paths(stage_data.get("train"))
            )
            val_override = (
                _normalize_data_paths(stage_data.get("csv_val"))
                or _normalize_data_paths(stage_data.get("val"))
            )
            if train_override is not None:
                stage_train = train_override
            if val_override is not None:
                stage_val = val_override

    return stage_train, stage_val


def _to_list_str(value):
    if value is None:
        return []
    if isinstance(value, (list, tuple)):
        return [str(v) for v in value]
    return [str(value)]


def _save_stage_snapshot(
    cfg: Dict[str, Any],
    stage: str,
    stage_cfg: Dict[str, Any],
    image_cfg: Dict[str, Any],
    csv_train: Any,
    csv_val: Any,
) -> None:
    try:
        snapshot_dir = (
            cfg.get("paths", {}).get("stage_snapshot_dir")
            or "configs/stage_snapshots"
        )
        out_dir = Path(snapshot_dir)
        out_dir.mkdir(parents=True, exist_ok=True)

        training_cfg = deepcopy(stage_cfg)
        training_cfg.pop("image_processing", None)
        training_cfg.pop("data", None)

        payload = {
            "stage": stage,
            "training": training_cfg,
            "data": {
                "train": _to_list_str(csv_train),
                "val": _to_list_str(csv_val),
            },
            "image_processing": image_cfg,
            "models": cfg.get("models", {}),
            "environment": cfg.get("environment", {}),
        }

        out_path = out_dir / f"{stage}.json"
        with out_path.open("w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)
        logger.info(f"âœ“ Stage config snapshot saved: {out_path}")
    except Exception as e:
        logger.warning(f"âš ï¸ Failed to save stage snapshot for {stage}: {e}")


def build_datamodule(cfg: Dict[str, Any], stage_cfg: Dict[str, Any]) -> VLMDataModule:
    ip = _resolve_stage_image_processing(cfg, stage_cfg)
    csv_train, csv_val = _resolve_stage_data(cfg, stage_cfg)

    # Vision processorê°€ ìë™ ì •ê·œí™”ë¥¼ ì‹¤í–‰í•˜ë„ë¡ mean/stdê°€ ì—†ìœ¼ë©´ Noneìœ¼ë¡œ ìœ ì§€
    image_mean = ip.get("image_mean", None)
    image_std = ip.get("image_std", None)
    dm = VLMDataModule(
        csv_train=csv_train,
        csv_val=csv_val,
        batch_size=stage_cfg.get("batch_size", 1),  # Tunerê°€ ìµœì  í¬ê¸°ë¥¼ ì°¾ì„ ê²ƒ
        num_workers=cfg.get("training", {}).get("num_workers", 16),
        image_size=tuple(ip.get("image_size", [224, 224])),
        tokenizer_name=(
            cfg.get("models", {}).get("language_model_name")
            or cfg.get("models", {}).get("lm_model", "Qwen/Qwen2.5-0.5B-Instruct")
        ),
        # Allow "auto" to use tokenizer.model_max_length with cap from config
        max_text_length=stage_cfg.get("max_text_length", cfg.get("data", {}).get("max_text_length", 256)),
        crop_strategy=ip.get("crop_strategy", "e2p"),
        system_msg=cfg.get("system_messages", {}).get("default", None),
        # Image processing extras
        overlap_ratio=ip.get("overlap_ratio", 0.5),
        fov_deg=ip.get("fov_deg", 90.0),
        image_mean=image_mean,
        image_std=image_std,
        use_vision_processor=ip.get("use_vision_processor", False),
        vision_model_name=ip.get("vision_model_name", cfg.get("models", {}).get("vision_model_name")),
        anyres_patch_size=ip.get("anyres_patch_size", 336),
        anyres_max_patches=ip.get("anyres_max_patches", 12),
        normalize=ip.get("normalize", True),
        auto_max_text_length_cap=int(cfg.get("data", {}).get("auto_max_text_length_cap", 8192)),
        auto_max_text_length_floor=int(cfg.get("data", {}).get("auto_max_text_length_floor", 512)),
        auto_max_text_length_scan_limit=int(cfg.get("data", {}).get("auto_max_text_length_scan_limit", 1000)),
    )
    return dm

def build_model(cfg: Dict[str, Any], stage: str, stage_cfg: Dict[str, Any], pretrained_dir_override: Optional[str] = None) -> VLMModule:
    # ModelConfig: config.jsonì„ í‰íƒ„í™”í•˜ì—¬ ë¡œë”©
    model_config = ConfigManager.load_config(os.environ.get("PANOVLM_CONFIG", "config.json"))

    # í•™ìŠµë¥ /LoRAë§Œ ì™¸ë¶€ë¡œ
    lr = stage_cfg.get("lr", 2e-5)
    use_lora_cfg = cfg.get("lora", {})
    
    # ì‚¬ì „í•™ìŠµ ë””ë ‰í† ë¦¬ (override > config)
    pretrained_dir = pretrained_dir_override or cfg.get("paths", {}).get("pretrained_dir")

    module = VLMModule(
        stage=stage,
        model_config=model_config,
        lr=lr,
        use_lora_cfg=use_lora_cfg,
        pretrained_dir=pretrained_dir
    )
    return module

def build_logger_and_callbacks(cfg: Dict[str, Any], stage: str, stage_cfg: Dict[str, Any], dm: VLMDataModule, lit_model: VLMModule):
    runs_dir = cfg.get("paths", {}).get("runs_dir", "runs")
    prefix   = cfg.get("training", {}).get("prefix", "panovlm")
    crop     = dm.hparams.crop_strategy
    resampler= (
        cfg.get("models", {}).get("resampler_type")
        or cfg.get("models", {}).get("resampler", "mlp")
    )
    ckpt_dir = f"{runs_dir}/{prefix}_{crop}_{stage}_{resampler}"
    Path(ckpt_dir).mkdir(parents=True, exist_ok=True)

    # wandb
    wandb_logger = None
    try:
        # í™˜ê²½ë³€ìˆ˜ ì„¸íŒ… (ë³´ì•ˆí‚¤ëŠ” í™˜ê²½ì—ì„œ). í”„ë¡œì íŠ¸ëª…ì€ JSONì—ì„œ ì§ì ‘ ì½ìŒ.
        env = cfg.get("environment", {})

        # ê¸°ì¡´ ëŸ° ë‹«ê¸°
        try:
            import wandb
            if wandb.run is not None:
                wandb.finish()
        except Exception:
            pass

        def _csv_name(csv_value) -> str:
            try:
                if isinstance(csv_value, (list, tuple)) and len(csv_value) > 0:
                    first = Path(str(csv_value[0]))
                    suffix = f"plus{len(csv_value)-1}" if len(csv_value) > 1 else ""
                    return f"{first.stem}{('_' + suffix) if suffix else ''}"
                return Path(str(csv_value)).stem
            except Exception:
                return "csv"

        run_name = f"{stage}_{_csv_name(dm.hparams.csv_train)}_{int(time.time())}"
        wandb_config = {
            "stage": stage,
            "batch_size": dm.hparams.batch_size,
            "lr": lit_model.hparams.lr,
            "epochs": stage_cfg.get("epochs"),
            "csv_train": dm.hparams.csv_train,
            "csv_val": dm.hparams.csv_val,
            "image_size": dm.hparams.image_size,
            "crop_strategy": dm.hparams.crop_strategy,
            "system_msg": dm.hparams.system_msg
        }

        project_name = (
            cfg.get("training", {}).get("wandb_project")
            or cfg.get("environment", {}).get("wandb_project")
            or "panovlm"
        )
        wandb_logger = WandbLogger(
            project=project_name,
            name=run_name,
            config=wandb_config,
            dir="./runs",
            save_dir="./runs"
        )
    except Exception as e:
        logger.warning(f"WandB logger init failed: {e}; continue without WandB.")

    # callbacks
    callbacks = [BatchSizeMonitorCallback()]
    # EarlyStopping (ë©”íŠ¸ë¦­ ë¡œê¹… ê°œì„ ë¨)
    early_stop = EarlyStopping(
        monitor="val_loss", patience=2, mode="min", verbose=True, check_on_train_epoch_end=False
    )
    callbacks.append(early_stop)

    # ModelCheckpoint: ìë™ ì €ì¥ (prefix/crop/stage/resampler ê¸°ë°˜ íŒŒì¼ëª…)
    filename_base = f"{prefix}_{crop}_{stage}_{resampler}_" + "{epoch:02d}-{val_loss:.4f}"
    ckpt_cb = ModelCheckpoint(
        dirpath=ckpt_dir,
        filename=filename_base,
        monitor="val_loss",
        mode="min",
        save_top_k=1,
        save_last=True,
        auto_insert_metric_name=False,
    )
    callbacks.append(ckpt_cb)

    return wandb_logger, callbacks, ckpt_dir

def run_stage(cfg: Dict[str, Any], stage: str, prev_artifact_dir: Optional[str] = None) -> str:
    logger.info(f"=== RUN STAGE: {stage} ===")

    # stage defaults (íŒŒì¼ì´ ì½”ë“œ ê¸°ë³¸ì„ ë®ìŒ)
    sdef = stage_defaults(cfg, stage)
    logger.info(f"[STAGE DEFAULTS] {sdef}")

    stage_ip = _resolve_stage_image_processing(cfg, sdef)
    stage_train_data, stage_val_data = _resolve_stage_data(cfg, sdef)
    _save_stage_snapshot(cfg, stage, sdef, stage_ip, stage_train_data, stage_val_data)

    # í˜„ì¬ ìŠ¤í…Œì´ì§€ run ë””ë ‰í† ë¦¬
    runs_dir = cfg.get("paths", {}).get("runs_dir", "runs")
    prefix   = cfg.get("training", {}).get("prefix", "panovlm")
    crop     = stage_ip.get("crop_strategy", "e2p")
    resampler= (
        cfg.get("models", {}).get("resampler_type")
        or cfg.get("models", {}).get("resampler", "mlp")
    )
    ckpt_dir = f"{runs_dir}/{prefix}_{crop}_{stage}_{resampler}"
    # DataModule
    dm = build_datamodule(cfg, sdef)

    # ëª¨ë¸ (í•„ìš” ì‹œ ì´ì „ ìŠ¤í…Œì´ì§€ safetensors ë””ë ‰í† ë¦¬ë¡œ ì´ˆê¸°í™”)
    lit_model = build_model(cfg, stage, sdef, pretrained_dir_override=prev_artifact_dir)

    # ë¡œê±°/ì½œë°±
    wandb_logger, callbacks, ckpt_dir = build_logger_and_callbacks(cfg, stage, sdef, dm, lit_model)

    # Trainer - ë””ë°”ì´ìŠ¤/ê°€ì†ê¸° ì„¤ì •ì„ JSONì—ì„œë§Œ ì œì–´
    trainer_kwargs = dict(
        logger=wandb_logger,
        callbacks=callbacks,
        val_check_interval=1.0,
        max_epochs=sdef.get("epochs", 1),
        precision="16-mixed",
        gradient_clip_val=1.0,
        default_root_dir=ckpt_dir,
        enable_checkpointing=True,
        enable_progress_bar=True,
        deterministic=False,
        benchmark=True,
        accumulate_grad_batches=sdef.get("accumulate_grad_batches", 2),
        strategy="ddp_find_unused_parameters_true",
    )

    # ê°€ì†ê¸°/ë””ë°”ì´ìŠ¤ ê²°ì •: config.environment.cuda_visible_devicesë¥¼ ì‚¬ìš©
    env_cfg = cfg.get("environment", {})
    if torch.cuda.is_available():
        trainer_kwargs["accelerator"] = "gpu"
        cuda_vis = str(env_cfg.get("cuda_visible_devices", "")).strip()
        if cuda_vis:
            # ì˜ˆ: "0", "1", "0,1"
            try:
                dev_list = [int(x) for x in cuda_vis.split(",") if x.strip() != ""]
                if len(dev_list) == 1:
                    trainer_kwargs["devices"] = dev_list
                elif len(dev_list) > 1:
                    trainer_kwargs["devices"] = dev_list
            except Exception:
                # ì˜ëª»ëœ ê°’ì¼ ê²½ìš° ìë™ ê²°ì •
                pass
    else:
        trainer_kwargs["accelerator"] = "cpu"

    trainer = pl.Trainer(**trainer_kwargs)

    # ë©”ëª¨ë¦¬ ìƒíƒœ ë¡œê¹…
    if torch.cuda.is_available():
        memory_allocated = torch.cuda.memory_allocated() / (1024**3)
        memory_reserved = torch.cuda.memory_reserved() / (1024**3)
        logger.info(f"ğŸ“Š GPU Memory after tuning - Allocated: {memory_allocated:.2f}GB, Reserved: {memory_reserved:.2f}GB")
    
    # í•™ìŠµ
    try:
        logger.info(f"Starting training (stage={stage})")
        t0 = time.time()
        trainer.fit(lit_model, datamodule=dm)
        logger.info(f"Training finished in {(time.time()-t0)/60:.1f} min")
    except Exception as e:
        logger.error(f"Training failed (stage={stage}): {e}")
        raise
    finally:
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    # ìë™ ì²´í¬í¬ì¸íŠ¸ ê²°ê³¼ ìš”ì•½ (ModelCheckpoint ì½œë°± ê¸°ì¤€)
    best_ckpt = None
    last_ckpt = None
    try:
        for cb in trainer.callbacks:
            if isinstance(cb, ModelCheckpoint):
                if getattr(cb, 'best_model_path', None):
                    best_ckpt = cb.best_model_path
                if getattr(cb, 'last_model_path', None):
                    last_ckpt = cb.last_model_path
        if best_ckpt:
            logger.info(f"ğŸ Best checkpoint: {best_ckpt}")
        if last_ckpt:
            logger.info(f"ğŸ§· Last checkpoint: {last_ckpt}")
    except Exception as _e:
        logger.warning(f"âš ï¸ Could not summarize checkpoints: {_e}")

    # LoRA ê°€ì¤‘ì¹˜ ë³„ë„ ì €ì¥ (ì˜µì…˜)
    if stage == "finetune" and lit_model.use_lora:
        try:
            lora_dir = str(Path(ckpt_dir) / "lora_weights")
            success = lit_model.model.save_lora_weights(lora_dir)
            if success:
                logger.info(f"âœ“ LoRA weights saved: {lora_dir}")
            else:
                logger.warning("âš ï¸ LoRA weight save returned False")
        except Exception as e:
            logger.warning(f"âš ï¸ Additional LoRA save failed: {e}")

    # ìƒì„¸í•œ ì‚¬ìš© ì•ˆë‚´
    logger.info("=" * 80)
    logger.info("ğŸ‰ í›ˆë ¨ ì™„ë£Œ! ì €ì¥ëœ ëª¨ë¸ ì‚¬ìš©ë²•:")
    logger.info("=" * 80)
    
    # ë¡œë”© ì˜ˆì‹œ ì¶œë ¥
    if best_ckpt:
        logger.info("ğŸ“– CKPT ë¡œë”© ì˜ˆì‹œ:")
        logger.info(f'   from panovlm.model import PanoramaVLM')
        logger.info(f'   model = PanoramaVLM.from_checkpoint("{best_ckpt}")')

    # ë‹¤ìŒ ìŠ¤í…Œì´ì§€ë¥¼ ìœ„í•´ ê°€ì¥ ì ì ˆí•œ ëª¨ë¸ ê²½ë¡œ ë°˜í™˜
    # ë‹¤ìŒ ìŠ¤í…Œì´ì§€ë¥¼ ìœ„í•´ ê°€ì¥ ì ì ˆí•œ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ë°˜í™˜
    if best_ckpt:
        return str(best_ckpt)
    if last_ckpt:
        return str(last_ckpt)
    logger.warning("âš ï¸ No checkpoint file found - returning stage directory")
    return str(ckpt_dir)

def run_all(cfg: Dict[str, Any]):
    # ë””ë°”ì´ìŠ¤/í”„ë¡œì íŠ¸ ë“±ì€ ëª¨ë‘ JSONìœ¼ë¡œ ì œì–´í•©ë‹ˆë‹¤.
    # wandb_api_keyë§Œ í™˜ê²½ë³€ìˆ˜ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.

    stages = get_stage_list(cfg)
    logger.info(f"Planned stages: {stages}")

    prev_artifact = None
    for st in stages:
        prev_artifact = run_stage(cfg, st, prev_artifact_dir=prev_artifact)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# main
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    cfg = load_config_dict()
    run_all(cfg)
