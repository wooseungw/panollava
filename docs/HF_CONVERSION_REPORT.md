# HuggingFace ë³€í™˜ ì™„ë£Œ ë³´ê³ ì„œ

## âœ… ë³€í™˜ ì„±ê³µ!

Lightning ì²´í¬í¬ì¸íŠ¸ê°€ HuggingFace í˜•ì‹ìœ¼ë¡œ ì„±ê³µì ìœ¼ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.

### ğŸ“Š ë³€í™˜ ê²°ê³¼

**ì…ë ¥**:
- Lightning checkpoint: `runs/SQ3_1_latent768_PE_e2p_finetune_qformer/last.ckpt`
- Stage: finetune (3ë‹¨ê³„ í•™ìŠµ ì™„ë£Œ)
- Resampler: QFormer
- LoRA: í™œì„±í™”ë¨

**ì¶œë ¥**:
- HF ëª¨ë¸ ë””ë ‰í† ë¦¬: `hf_checkpoints/panollava-vlm-qformer/`
- íŒŒì¼ êµ¬ì„±:
  - `config.json` (1.4 KB) - ëª¨ë¸ ì„¤ì •
  - `pytorch_model.bin` (3.0 GB) - ëª¨ë¸ ê°€ì¤‘ì¹˜
  - `README.md` (689 B) - ëª¨ë¸ ì¹´ë“œ

### ğŸ¯ ëª¨ë¸ ìƒì„¸ ì •ë³´

```json
{
  "vision": "google/siglip-base-patch16-224",
  "text": "Qwen/Qwen3-0.6B",
  "resampler": "qformer",
  "latent_dimension": 768,
  "crop_strategy": "e2p",
  "use_lora": true,
  "overlap_ratio": 0.5
}
```

### ğŸ“¦ ìƒì„±ëœ íŒŒì¼

```
hf_checkpoints/panollava-vlm-qformer/
â”œâ”€â”€ config.json              # HuggingFace ì„¤ì • íŒŒì¼
â”œâ”€â”€ pytorch_model.bin         # ëª¨ë¸ ê°€ì¤‘ì¹˜ (3.0GB)
â””â”€â”€ README.md                 # ëª¨ë¸ ì¹´ë“œ
```

### ğŸš€ ì‚¬ìš© ë°©ë²•

#### 1. ë¡œì»¬ì—ì„œ ë¡œë“œ

```python
from transformers import AutoModelForVision2Seq, AutoProcessor
from PIL import Image

# ëª¨ë¸ ë¡œë“œ
model = AutoModelForVision2Seq.from_pretrained(
    "hf_checkpoints/panollava-vlm-qformer",
    trust_remote_code=True,
    dtype="auto",
    device_map="auto"
)

# Processor ë¡œë“œ (ì´ë¯¸ì§€ ì²˜ë¦¬ + í† í¬ë‚˜ì´ì €)
processor = AutoProcessor.from_pretrained(
    "hf_checkpoints/panollava-vlm-qformer",
    trust_remote_code=True
)

# ì¶”ë¡ 
image = Image.open("panorama.jpg")
inputs = processor(
    text="Describe this panoramic scene",
    images=image,
    return_tensors="pt"
).to(model.device)

outputs = model.generate(**inputs, max_new_tokens=100)
response = processor.decode(outputs[0], skip_special_tokens=True)
print(response)
```

#### 2. HuggingFace Hubì— ì—…ë¡œë“œ

```python
from huggingface_hub import login

# Hub ë¡œê·¸ì¸
login(token="your_hf_token")

# í‘¸ì‹œ
model.push_to_hub("your-username/panollava-vlm")
processor.push_to_hub("your-username/panollava-vlm")
```

#### 3. Hubì—ì„œ ì§ì ‘ ë¡œë“œ

```python
# Hubì— ì—…ë¡œë“œ í›„
model = AutoModelForVision2Seq.from_pretrained(
    "your-username/panollava-vlm",
    trust_remote_code=True
)
```

### ğŸ”„ ì¶”ê°€ ì²´í¬í¬ì¸íŠ¸ ë³€í™˜

ë‹¤ë¥¸ ì²´í¬í¬ì¸íŠ¸ë„ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
# Stage 1 (VICReg)
python scripts/convert_checkpoint_simple.py \
  --lightning-ckpt runs/SQ3_1_latent768_PE_e2p_vision_qformer/last.ckpt \
  --output-dir hf_checkpoints/panollava-stage1-vicreg \
  --model-type vicreg

# Stage 2 (Resampler)
python scripts/convert_checkpoint_simple.py \
  --lightning-ckpt runs/SQ3_1_latent768_PE_e2p_resampler_qformer/last.ckpt \
  --output-dir hf_checkpoints/panollava-stage2-resampler \
  --model-type conditional-generation

# MLP Resampler ë²„ì „
python scripts/convert_checkpoint_simple.py \
  --lightning-ckpt runs/SQ3_1_latent768_PE_e2p_vision_mlp/last.ckpt \
  --output-dir hf_checkpoints/panollava-vlm-mlp \
  --model-type conditional-generation
```

### ğŸ“ ë³€í™˜ í”„ë¡œì„¸ìŠ¤

1. **Checkpoint ë¡œë“œ**: Lightning `.ckpt` íŒŒì¼ì—ì„œ state_dictì™€ hyperparameters ì¶”ì¶œ
2. **Key ë³€í™˜**: `model.` prefix ì œê±° (Lightning â†’ HF í˜•ì‹)
3. **Config ìƒì„±**: PanoLLaVaConfig ê°ì²´ ìƒì„± ë° ì €ì¥
4. **Weights ì €ì¥**: `pytorch_model.bin`ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì €ì¥
5. **Model Card**: README.md ìë™ ìƒì„±

### ğŸ› ï¸ ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸

ë‘ ê°€ì§€ ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ ì œê³µ:

1. **`convert_checkpoint_simple.py`** (ê¶Œì¥) âœ…
   - ë¹ ë¥¸ ë³€í™˜ (ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì•ˆ í•¨)
   - Config + Weightsë§Œ ì €ì¥
   - ë©”ëª¨ë¦¬ íš¨ìœ¨ì 

2. **`convert_to_hf.py`** (ê³ ê¸‰)
   - ì „ì²´ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ê²€ì¦
   - Missing/unexpected keys ë¦¬í¬íŠ¸
   - Hub ì§ì ‘ ì—…ë¡œë“œ ì§€ì› (`--push-to-hub`)

### âš ï¸ ì¤‘ìš” ì‚¬í•­

1. **trust_remote_code=True í•„ìˆ˜**
   - ì»¤ìŠ¤í…€ ëª¨ë¸ í´ë˜ìŠ¤ì´ë¯€ë¡œ ë¡œë“œ ì‹œ í•­ìƒ í•„ìš”

2. **Processor ì„¤ì •**
   - ì´ë¯¸ì§€ ì²˜ë¦¬: PanoramaImageProcessor ì‚¬ìš©
   - í…ìŠ¤íŠ¸: Qwen tokenizer ì‚¬ìš©
   - Vision token: `<|vision|>` ìë™ ì¶”ê°€

3. **LoRA ê°€ì¤‘ì¹˜**
   - LoRA adapterê°€ ë©”ì¸ ê°€ì¤‘ì¹˜ì— ë³‘í•©ë˜ì–´ ì €ì¥ë¨
   - ë³„ë„ì˜ LoRA íŒŒì¼ ì—†ì´ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥

### ğŸ“ˆ ë‹¤ìŒ ë‹¨ê³„

- [ ] HuggingFace Hubì— ì—…ë¡œë“œ
- [ ] Model Card ìƒì„¸ ì‘ì„±
- [ ] Demo ì•± ë§Œë“¤ê¸° (Gradio/Streamlit)
- [ ] ë‹¤ë¥¸ ì²´í¬í¬ì¸íŠ¸ë“¤ë„ ë³€í™˜
- [ ] Quantization (GGUF, GPTQ ë“±)

### ğŸ‰ ê²°ë¡ 

PanoLLaVA ëª¨ë¸ì´ HuggingFace ìƒíƒœê³„ì™€ ì™„ì „íˆ í˜¸í™˜ë˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤!

- âœ… Config ì €ì¥ ì™„ë£Œ
- âœ… Weights ì €ì¥ ì™„ë£Œ  
- âœ… Model Card ìƒì„± ì™„ë£Œ
- âœ… AutoModelë¡œ ë¡œë“œ ê°€ëŠ¥
- âœ… Hub ì—…ë¡œë“œ ì¤€ë¹„ ì™„ë£Œ

ì´ì œ HuggingFaceì˜ ëª¨ë“  ë„êµ¬(Trainer, Pipeline, Accelerate ë“±)ì™€ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!
