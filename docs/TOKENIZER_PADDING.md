# í† í¬ë‚˜ì´ì € íŒ¨ë”© ë°©í–¥ ì„¤ì • ê°€ì´ë“œ

## ê°œìš”

PanoLLaVAëŠ” ì´ì œ **LLM ëª¨ë¸ì˜ ì›ë˜ í† í¬ë‚˜ì´ì € ì„¤ì •ì„ ì¡´ì¤‘**í•˜ì—¬ íŒ¨ë”© ë°©í–¥ì„ ìë™ìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.

## ë³€ê²½ ì‚¬í•­

### Before (í•˜ë“œì½”ë”©)
```python
# í•­ìƒ "right" paddingìœ¼ë¡œ ê³ ì •
self.tokenizer.padding_side = "right"
```

**ë¬¸ì œì **:
- Llama, Qwen ë“± decoder-only ëª¨ë¸ì€ ë³´í†µ **left padding** ì‚¬ìš©
- ì›ë˜ ì„¤ì • ë¬´ì‹œë¡œ ì¸í•œ ì ì¬ì  ì„±ëŠ¥ ì €í•˜
- ëª¨ë¸ íƒ€ì…ì— ê´€ê³„ì—†ì´ ì¼ê´„ ì ìš©

### After (ìë™ ê°ì§€)
```python
# 1. ì›ë˜ í† í¬ë‚˜ì´ì € ì„¤ì • ì €ì¥
self._original_padding_side = self.tokenizer.padding_side

# 2. ì›ë˜ ì„¤ì • ìš°ì„  ì‚¬ìš©
if original_side:
    self.tokenizer.padding_side = original_side
    print(f"Padding side: '{original_side}' (from original tokenizer)")
```

## íŒ¨ë”© ë°©í–¥ ê²°ì • ë¡œì§

ìš°ì„ ìˆœìœ„ ìˆœì„œ:

1. **ì›ë˜ í† í¬ë‚˜ì´ì € ì„¤ì •** (ìµœìš°ì„ )
   - `AutoTokenizer.from_pretrained()`ë¡œ ë¡œë”©í•œ ì›ë³¸ ì„¤ì • ì‚¬ìš©
   
2. **ëª¨ë¸ íƒ€ì…ë³„ ê¶Œì¥ ì„¤ì •** (fallback)
   - Llama, Mistral, Qwen â†’ `left` padding
   - T5, BART â†’ `right` padding
   
3. **ê¸°ë³¸ê°’** (ìµœí›„ ìˆ˜ë‹¨)
   - `right` padding

## ëª¨ë¸ë³„ íŒ¨ë”© ë°©í–¥

| ëª¨ë¸ | ê¸°ë³¸ Padding | ì´ìœ  |
|------|-------------|------|
| Llama | `left` | Decoder-only, ìƒì„± ì‹œ ì™¼ìª½ íŒ¨ë”© í•„ìš” |
| Qwen | `left` | Decoder-only, ì™¼ìª½ íŒ¨ë”© ê¶Œì¥ |
| Mistral | `left` | Decoder-only ì•„í‚¤í…ì²˜ |
| Gemma | `left` | Decoder-only ì•„í‚¤í…ì²˜ |
| T5 | `right` | Encoder-decoder, ì˜¤ë¥¸ìª½ íŒ¨ë”© |
| BART | `right` | Encoder-decoder ì•„í‚¤í…ì²˜ |

## ë¡œê·¸ ë©”ì‹œì§€

### ì›ë˜ ì„¤ì • ì‚¬ìš©
```
[Tokenizer Setup] Padding side: 'left' (from original tokenizer config)
```

### ê¶Œì¥ ì„¤ì • ì‚¬ìš©
```
[Tokenizer Setup] Padding side: 'left' (recommended for Qwen/Qwen3-0.6B)
```

### ê¸°ë³¸ê°’ ì‚¬ìš©
```
[Tokenizer Setup] Padding side: 'right' (default)
```

## ì˜ˆì‹œ

### Qwen ëª¨ë¸
```python
from panovlm.models.model import PanoramaVLM
from panovlm.config import ModelConfig

config = ModelConfig(
    vision_name='google/siglip-base-patch16-224',
    language_model_name='Qwen/Qwen3-0.6B',  # Left padding
)

model = PanoramaVLM(config=config)
# [Tokenizer Setup] Padding side: 'left' (from original tokenizer config)

print(model.tokenizer.padding_side)  # 'left'
```

### Llama ëª¨ë¸
```python
config = ModelConfig(
    vision_name='google/siglip-base-patch16-224',
    language_model_name='meta-llama/Llama-3.2-1B',  # Left padding
)

model = PanoramaVLM(config=config)
# [Tokenizer Setup] Padding side: 'left' (from original tokenizer config)

print(model.tokenizer.padding_side)  # 'left'
```

### T5 ëª¨ë¸ (Encoder-Decoder)
```python
config = ModelConfig(
    vision_name='google/siglip-base-patch16-224',
    language_model_name='google/flan-t5-base',  # Right padding
)

model = PanoramaVLM(config=config)
# [Tokenizer Setup] Padding side: 'right' (from original tokenizer config)

print(model.tokenizer.padding_side)  # 'right'
```

## ìˆ˜ë™ ì˜¤ë²„ë¼ì´ë“œ

í•„ìš”í•œ ê²½ìš° ìˆ˜ë™ìœ¼ë¡œ íŒ¨ë”© ë°©í–¥ì„ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
# ëª¨ë¸ ìƒì„± í›„
model = PanoramaVLM(config=config)

# íŒ¨ë”© ë°©í–¥ ìˆ˜ë™ ë³€ê²½ (ê¶Œì¥í•˜ì§€ ì•ŠìŒ)
model.tokenizer.padding_side = 'right'
print(f"Manual override: {model.tokenizer.padding_side}")
```

âš ï¸ **ì£¼ì˜**: ìˆ˜ë™ ë³€ê²½ì€ ëª¨ë¸ì˜ ì›ë˜ ì„¤ê³„ì™€ ë§ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê¶Œì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

## Left Padding vs Right Padding

### Left Padding (Decoder-only ëª¨ë¸ ê¶Œì¥)

```
Input:  "Describe the image"
Tokens: [PAD] [PAD] [PAD] Describe the image

ì¥ì :
âœ… ìƒì„± ì‹œ ë§ˆì§€ë§‰ í† í°ì´ ì¤‘ìš” (attention mask í™œìš©)
âœ… Autoregressive generationì— ìµœì 
âœ… Llama, Qwen ë“±ì˜ ê¸°ë³¸ ì„¤ì •

ë‹¨ì :
âš ï¸ Position encodingì´ ì˜¬ë°”ë¥´ê²Œ ë™ì‘í•´ì•¼ í•¨
```

### Right Padding (Encoder-decoder ê¶Œì¥)

```
Input:  "Describe the image"
Tokens: Describe the image [PAD] [PAD] [PAD]

ì¥ì :
âœ… Encoder ì…ë ¥ì— ìì—°ìŠ¤ëŸ¬ì›€
âœ… ìœ„ì¹˜ ì •ë³´ê°€ ìˆœì°¨ì 
âœ… T5, BARTì˜ ê¸°ë³¸ ì„¤ì •

ë‹¨ì :
âš ï¸ Decoder-only ìƒì„±ì—ëŠ” ë¹„íš¨ìœ¨ì 
```

## ë””ë²„ê¹…

### í˜„ì¬ íŒ¨ë”© ì„¤ì • í™•ì¸
```python
print(f"Padding side: {model.tokenizer.padding_side}")
print(f"Pad token: {model.tokenizer.pad_token}")
print(f"Pad token ID: {model.tokenizer.pad_token_id}")
```

### íŒ¨ë”© ë™ì‘ í…ŒìŠ¤íŠ¸
```python
from transformers import AutoTokenizer

# ì›ë³¸ í† í¬ë‚˜ì´ì € ë¡œë”©
tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen3-0.6B")
print(f"Original padding_side: {tokenizer.padding_side}")

# íŒ¨ë”© í…ŒìŠ¤íŠ¸
texts = ["Short", "This is a much longer sentence"]
encoded = tokenizer(texts, padding=True, return_tensors='pt')
print(encoded['input_ids'])
```

## ê´€ë ¨ íŒŒì¼

- **ëª¨ë¸ ì½”ë“œ**: `src/panovlm/models/model.py`
  - `__init__`: ì›ë˜ íŒ¨ë”© ì„¤ì • ì €ì¥
  - `_setup_tokenizer()`: íŒ¨ë”© ë°©í–¥ êµ¬ì„±

## ì°¸ê³  ìë£Œ

- [HuggingFace Tokenizer Padding](https://huggingface.co/docs/transformers/pad_truncation)
- [Left vs Right Padding in Language Models](https://discuss.huggingface.co/t/why-does-the-falcon-qlora-tutorial-use-left-padding/57654)
- [Qwen2 Tokenizer](https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct/blob/main/tokenizer_config.json)

## ìš”ì•½

âœ… **ìë™ ê°ì§€**: LLM ì›ë˜ ì„¤ì •ì„ ìë™ìœ¼ë¡œ ê°ì§€í•˜ì—¬ ì ìš©  
âœ… **ì•ˆì „í•œ Fallback**: ì›ë˜ ì„¤ì •ì´ ì—†ìœ¼ë©´ ëª¨ë¸ íƒ€ì…ë³„ ê¶Œì¥ê°’ ì‚¬ìš©  
âœ… **ëª…í™•í•œ ë¡œê·¸**: ì–´ë–¤ ì„¤ì •ì´ ì ìš©ë˜ì—ˆëŠ”ì§€ ëª…í™•íˆ í‘œì‹œ  
âœ… **í•˜ìœ„ í˜¸í™˜**: ê¸°ì¡´ ì½”ë“œ ë™ì‘ ë³´ì¥  

ì´ì œ ê° LLM ëª¨ë¸ì˜ íŠ¹ì„±ì— ë§ëŠ” ìµœì ì˜ íŒ¨ë”© ë°©í–¥ì´ ìë™ìœ¼ë¡œ ì„¤ì •ë©ë‹ˆë‹¤! ğŸ¯
