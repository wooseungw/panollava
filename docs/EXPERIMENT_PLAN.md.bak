# CORA ì‹¤í—˜ ê²°ê³¼

> ìµœì¢… ì—…ë°ì´íŠ¸: 2026-02-27 (B3 DenseCL eval âœ…, VICReg-pw 25% InternVL eval âœ…, VICReg-pw 50% InternVL í•™ìŠµ ì¤‘)

---

## 1. ê³µí†µ ì‹¤í—˜ ì„¤ì •

| í•­ëª© | ì„¤ì • |
|------|------|
| Vision Encoder | SigLIP2 so400m-patch16-256 (frozen) |
| LLM | Qwen3-0.6B |
| Resampler | MLP 1024â†’1024, 3-layer |
| Views | 9 (1 global + 8 tiles, pitch=0Â°, stride=45Â°) |
| Physical overlap | 50% |
| Batch size | autobatch (-1) |
| Precision | bf16-mixed |
| GPU | 1Ã—RTX 3090 (24GB) |
| Dataset | QuIC-360 (train/test split) |
| Test eval | 5,349 samples, greedy decoding, max_new_tokens=128 |

---

## 2. Experiment 1 â€” Loss Comparison

Stage 1(Vision Alignment)ì—ì„œ ì–´ë–¤ lossê°€ ê°€ì¥ íš¨ê³¼ì ì¸ì§€ ë¹„êµ.

### 2.1 ë¹„êµêµ°

| ID | Loss | Loss overlap | í•µì‹¬ ì°¨ì´ |
|:---:|------|:---:|-----------|
| A | VICReg (batchwise) | 25% | variance/covë¥¼ ë°°ì¹˜ ì „ì²´(dim=0)ì—ì„œ ê³„ì‚° â€” gradient ì†Œì‹¤ |
| B | VICReg (pairwise) | 25% | variance/covë¥¼ ê° ìŒ ë‚´ë¶€(dim=1)ì—ì„œ ê³„ì‚° â€” ê³µê°„ ë‹¤ì–‘ì„± ê°•ì œ |
| C | InfoNCE | **50%** | 2-view dropout augmentation + overlap/tile InfoNCE |
| D | DenseCL | 25% | single-view overlap InfoNCE (ê°€ì¥ ë‹¨ìˆœ) |
| B' | VICReg (pairwise) | **50%** | Bì™€ ë™ì¼ êµ¬ì¡°, loss overlapë§Œ 50%ë¡œ ë³€ê²½ |
| D' | DenseCL | **50%** | Dì™€ ë™ì¼ êµ¬ì¡°, loss overlapë§Œ 50%ë¡œ ë³€ê²½ |

> InfoNCE(C)ëŠ” ì½”ë“œìƒ `overlap_ratio=0.5`ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ì›ë˜ë¶€í„° 50%.
> B'/D'ëŠ” VICReg/DenseCLì„ InfoNCEì™€ ë™ì¼í•œ 50% overlap ì¡°ê±´ìœ¼ë¡œ ë§ì¶˜ ì¬ì‹¤í—˜.

### 2.2 Stage 1 â€” Vision Alignment

| Metric | A | B | C | D | B' | D' |
|--------|:---:|:---:|:---:|:---:|:---:|:---:|
| val_adj_cos â†‘ | 0.763 | 0.867 | 0.948 | 0.869 | **1.000** | 0.934 |
| val_adj_mse â†“ | 0.213 | â€” | **0.046** | â€” | â€” | â€” |
| val_overlap_ret_acc â†‘ | â€” | 0.390 | **1.000** | 0.263 | **1.000** | **1.000** |
| val_hungarian_acc â†‘ | 0.971 | 0.988 | 0.135 | â€” | **1.000** | 0.142 |
| val_feat_std â†‘ | 0.715 | â€” | 0.665 | â€” | â€” | â€” |
| val_eff_rank â†‘ | 3.32 | â€” | **94.66** | â€” | â€” | â€” |
| val_r_eff_rank â†‘ | 3.75 | â€” | **32.85** | â€” | â€” | â€” |
| val_loss | 11.188 | 11.188 | 0.125 | **0.009** | 7.063 | 0.013 |

**ì†Œê²¬:**
- **VICReg (A, B)**: val_loss=11.188 ê³ ì • â€” 25% overlapì—ì„œ ì‚¬ì‹¤ìƒ í•™ìŠµ ì•ˆ ë¨
- **B' (VICReg 50%)**: ëª¨ë“  metrics 1.000 í¬í™”. lossëŠ” ì—¬ì „íˆ ë†’ì§€ë§Œ(7.06) alignmentì€ ì™„ë²½
- **C (InfoNCE)**: alignment ìš°ìˆ˜(adj_cos=0.948) but hungarian=0.135 (random ìˆ˜ì¤€) â€” ê³µê°„ êµ¬ë¶„ ë¶ˆê°€
- **D (DenseCL 25%)**: val_loss=0.009ë¡œ ìˆ˜ë ´ ì–‘í˜¸. adj_cos=0.869
- **D' (DenseCL 50%)**: overlap_ret 0.263â†’1.000 ëŒ€í­ ê°œì„ . adj_cos 0.869â†’0.934

### 2.3 Stage 2 â€” Resampler Alignment

| | A | B | C | D | B' | D' |
|--|:---:|:---:|:---:|:---:|:---:|:---:|
| val_lm_loss | 4.7533 | 3.7348 | 2.6339 | 2.6140 | 3.3210 | 2.6123 |

### 2.4 Stage 3 â€” LoRA Finetune

| | A | B | C | D | B' | D' |
|--|:---:|:---:|:---:|:---:|:---:|:---:|
| val_lm_loss | 2.6065 | 2.6039 | 2.6006 | 2.5932 | 2.5973 | **2.5935** |

> LoRA finetune í›„ ëª¨ë‘ 2.59~2.61ë¡œ ìˆ˜ë ´. Stage 2ì˜ í° ì°¨ì´(4.75 vs 2.61)ë¥¼ LoRAê°€ ëŒ€ë¶€ë¶„ ë³´ì •.

### 2.5 Test Eval (ìµœì¢… ìƒì„± í’ˆì§ˆ)

| Metric | A | B | C | D | B' | D' |
|--------|:---:|:---:|:---:|:---:|:---:|:---:|
| BLEU-4 â†‘ | 0.0112 | 0.0063 | 0.0049 | **0.0178** | 0.0013 | 0.0007 |
| METEOR â†‘ | 0.0806 | 0.1932 | **0.2031** | 0.0828 | NaN | 0.0560 |
| ROUGE-L â†‘ | 0.1591 | 0.1382 | 0.1299 | **0.1787** | 0.0558 | 0.0884 |
| CIDEr â†‘ | 0.0595 | 0.0293 | 0.0049 | **0.1081** | 0.0069 | 0.0023 |
| SPICE â†‘ | 0.0775 | 0.0827 | 0.0882 | **0.1001** | NaN | 0.0253 |

> SPICE: ê¸´ ì˜ˆì¸¡ë¬¸(50+ words)ì´ Stanford CoreNLP íŒŒì„œë¥¼ crash â€” 2ë¬¸ì¥/40ë‹¨ì–´ truncation í›„ ì¬ì¸¡ì • (2026-02-22)
> B' METEOR/SPICE = NaN â€” íŒŒì„œ í˜¸í™˜ ë¬¸ì œë¡œ ì¸¡ì • ë¶ˆê°€.

**ì†Œê²¬:**
- **DenseCL 25%(D)ì´ BLEU-4, ROUGE-L, CIDEr, SPICE ì „ ì§€í‘œ 1ìœ„.** METEORë§Œ InfoNCE(C)ê°€ 1ìœ„.
- InfoNCE(C)ëŠ” CIDEr=0.005ë¡œ ìµœí•˜ìœ„ â€” val_lossê°€ ê°€ì¥ ë‚®ì•˜ìŒì—ë„ ìƒì„± í’ˆì§ˆ ìµœì•….
- **Best CORA (DenseCL 25%, CIDEr=0.108) = Baseline Gemma3-4B(0.338)ì˜ 32% ìˆ˜ì¤€.**

---

## 3. Experiment 2 â€” Resampler Comparison (ë¯¸ì‹¤í–‰)

Best loss(DenseCL)ì˜ Stage 1 checkpointë¥¼ ê³µìœ í•˜ê³ , resamplerë§Œ êµì²´í•˜ì—¬ ë¹„êµ.

| ID | Resampler | Type | Params |
|:---:|-----------|------|:---:|
| R1 | MLP | Token-independent (LLaVA ë°©ì‹) | ~7M |
| R2 | BiMamba | Bidirectional SSM | ~66M |
| R3 | C-Abstractor | Spatial-aware Conv (Cambrian-1) | ~50M |

---

## 4. Baseline ë¹„êµ (256Â² resize)

> LoRA 1 epoch, QuIC-360 test (5,349 samples), img 256Ã—256, max_tok 128

| Model | Params | BLEU-4 â†‘ | METEOR â†‘ | ROUGE-L â†‘ | CIDEr â†‘ | SPICE â†‘ |
|-------|:---:|:---:|:---:|:---:|:---:|:---:|
| **Gemma3-4B** | 4B | **0.0421** | 0.1085 | **0.2449** | **0.3383** | **0.1640** |
| InternVL3.5-2B | 2B | 0.0403 | **0.1096** | 0.2402 | 0.3054 | 0.1566 |
| Qwen2.5-VL-3B | 3B | 0.0382 | 0.1113 | 0.2334 | 0.2809 | 0.1435 |
| InternVL3.5-1B | 1B | 0.0282 | 0.1129 | 0.2074 | 0.1989 | 0.1506 |
| Qwen2-VL-2B | 2B | 0.0337 | 0.1005 | 0.2301 | 0.2447 | 0.1449 |
| BLIP2-OPT-2.7B | 2.7B | 0.0051 | 0.0448 | 0.1230 | 0.0715 | 0.0848 |
| CORA (DenseCL 25%) | â€” | 0.0178 | 0.0828 | 0.1787 | 0.1081 | 0.1001 |
| CORA (VICReg batchwise 25%) | â€” | 0.0112 | 0.0806 | 0.1590 | 0.0594 | 0.0775 |
| CORA (InfoNCE contrastive) | â€” | 0.0049 | 0.2031 | 0.1299 | 0.0049 | 0.0882 |
| CORA (VICReg pairwise 25%) | â€” | 0.0063 | 0.1932 | 0.1382 | 0.0293 | 0.0827 |
| CORA (DenseCL 50%) | â€” | 0.0007 | 0.0560 | 0.0884 | 0.0023 | 0.0253 |
| CORA (VICReg pairwise 50%) | â€” | 0.0013 | NaN | 0.0558 | 0.0069 | NaN |

---

## 5. Experiment 3 â€” Multi-view Strategy Comparison (Track M)

Qwen2.5-VL-3Bë¥¼ base modelë¡œ ì‚¬ìš©í•˜ì—¬, íŒŒë…¸ë¼ë§ˆ ì´ë¯¸ì§€ ì…ë ¥ ë°©ì‹ë³„ ì„±ëŠ¥ì„ ë¹„êµ.

> LoRA 1 epoch, QuIC-360 test (5,349 samples), max_tok 128

| Strategy | Views | BLEU-4 â†‘ | METEOR â†‘ | ROUGE-L â†‘ | CIDEr â†‘ | SPICE â†‘ |
|----------|-------|:---:|:---:|:---:|:---:|:---:|
| resize (256Â²) | 1, fixed | 0.0382 | 0.1113 | 0.2334 | 0.2809 | 0.1435 |
| native (dynamic) | 1, dynamic tiles | **0.0431** | 0.1124 | 0.2421 | 0.3285 | 0.1554 |
| cubemap | 5 (4+global) | 0.0424 | 0.1119 | 0.2424 | 0.3303 | 0.1575 |
| anyres_e2p | 9 (8+global) | 0.0420 | **0.1138** | **0.2441** | **0.3389** | **0.1613** |

> pinhole (8 views, CIDEr=0.3384)ëŠ” anyres_e2pì™€ ê±°ì˜ ë™ì¼(ì°¨ì´ 0.0005)í•˜ì—¬ ì œì™¸.

---

## 6. Experiment 4 â€” CORA Crop Strategy Ablation (Track C)

CORA íŒŒì´í”„ë¼ì¸(SigLIP2 + Qwen3-0.6B + MLP resampler) ë‚´ì—ì„œ crop strategyë³„ ì„±ëŠ¥ì„ ë¹„êµ.

| Strategy | Views | val_loss (Stage 3) | Eval |
|----------|-------|:---:|:---:|
| resize | 1 | 2.6596 | âš ï¸ predictions.csv ì™„ë£Œ, metrics.json ì—†ìŒ (SPICE íŒŒì„œ ì˜¤ë¥˜) |
| cubemap | 4 | 2.6310 | âŒ eval ë¯¸ì‹¤í–‰ |
| e2p | 8+1 global | 2.6254 | âŒ eval ë¯¸ì‹¤í–‰ |

---

## 7. Experiment 5 â€” Native Processing Comparison (Track A)

ê° VLMì˜ native image processingì„ ì‚¬ìš©í•œ ë¹„êµ (256Â² resize ì—†ì´).

> LoRA 1 epoch, QuIC-360 test (5,349 samples), max_tok 128

| Model | Params | BLEU-4 â†‘ | METEOR â†‘ | ROUGE-L â†‘ | CIDEr â†‘ | SPICE â†‘ |
|-------|:---:|:---:|:---:|:---:|:---:|:---:|
| **InternVL3.5-2B** | 2B | 0.0443 | 0.1111 | 0.2462 | **0.3405** | **0.1661** |
| Gemma3-4B | 4B | 0.0420 | 0.1081 | 0.2453 | 0.3363 | 0.1636 |
| Qwen2.5-VL-3B | 3B | **0.0443** | **0.1125** | 0.2427 | 0.3306 | 0.1548 |
| InternVL3.5-1B | 1B | 0.0389 | 0.1065 | 0.2394 | 0.3171 | 0.1606 |

> Gemma3 native eval ì¬í‰ê°€ ì™„ë£Œ (CIDEr=0.3363). ì´ì „ avg_pred_tokens=3.12 ì´ìƒ ê²°ê³¼ëŠ” eval ìŠ¤í¬ë¦½íŠ¸ ë²„ê·¸ì˜€ìŒ.

---

## 8. Experiment 6 â€” PanoAdapt (Track B)

ê¸°ì¡´ ìƒìš© VLMì— PanoRoPE (panoramic position encoding) + DenseCL / VICReg-pairwise overlap lossë¥¼ ì£¼ì….

> anyres_e2p 9-view ì…ë ¥, PanoRoPE-1D/3D, LoRA r=32, 1 epoch, CUDA_VISIBLE_DEVICES=1

### 8.1 PanoAdapt DenseCL (Track B â€” ë©”ì¸)

| # | Model | dtype | í•™ìŠµ | Eval | BLEU-4 â†‘ | METEOR â†‘ | ROUGE-L â†‘ | CIDEr â†‘ | SPICE â†‘ | vs Native |
|---|-------|:-----:|:----:|:----:|:---:|:---:|:---:|:---:|:---:|:---:|
| B2 | InternVL3.5-2B | bf16 | âœ… | âœ… | **0.0457** | **0.1137** | **0.2492** | **0.3603** | **0.1720** | **+5.8%** |
| B1 | Qwen2.5-VL-3B | bf16 | âœ… | âœ… | 0.0424 | 0.1140 | 0.2449 | 0.3396 | 0.1619 | +2.7% |
| B3 | Gemma3-4B | bf16 | âœ… | âœ… | 0.0438 | 0.1162 | 0.2509 | 0.3362 | 0.1685 | **-0.03%** |

> B3 Gemma3: ì´ì „ fp16 í•™ìŠµì€ `loss=0.0, grad_norm=nan` ìœ¼ë¡œ ì™„ì „ ì‹¤íŒ¨ (fp16 overflow). bf16ìœ¼ë¡œ ì¬í•™ìŠµ (train_loss=12.46) í›„ eval ì™„ë£Œ. CIDEr=0.3362ë¡œ native(0.3363)ì™€ ì‚¬ì‹¤ìƒ ë™ì¼ (-0.03%).

### 8.2 PanoAdapt VICReg-pairwise 50% (Track B â€” self-supervised ë¹„êµ)

| # | Model | dtype | í•™ìŠµ | Eval | BLEU-4 â†‘ | METEOR â†‘ | ROUGE-L â†‘ | CIDEr â†‘ | SPICE â†‘ | vs Native |
|---|-------|:-----:|:----:|:----:|:---:|:---:|:---:|:---:|:---:|:---:|
| B2v (25%) | InternVL3.5-2B | bf16 | âœ… | âœ… | 0.0457 | 0.1136 | 0.2601 | 0.3594 | 0.1713 | +5.5% |
| B2v (50%) | InternVL3.5-2B | bf16 | ğŸ”µ í•™ìŠµì¤‘ (14%) | â³ ëŒ€ê¸° | â€” | â€” | â€” | â€” | â€” | â€” |
| B1v (50%) | Qwen2.5-VL-3B | bf16 | â³ í | â³ ëŒ€ê¸° | â€” | â€” | â€” | â€” | â€” | â€” |
| B3v (50%) | Gemma3-4B | **bf16** | â³ í | â³ ëŒ€ê¸° | â€” | â€” | â€” | â€” | â€” | â€” |

### 8.3 ë²„ê·¸ ì´ë ¥

| ë‚ ì§œ | ë²„ê·¸ | ìˆ˜ì • |
|------|------|------|
| 2026-02-24 | PanoAdapt `_unwrap_to_rope_model()` ë¬´í•œ ë£¨í”„ | `base_model` ìê¸°ì°¸ì¡° ì‚¬ì´í´ ì²´í¬ ì¶”ê°€ |
| 2026-02-24 | `max_length: 1024` ë¶€ì¡± (9 views Ã— 256 = 2304 tokens) | `max_length: 3072` ìˆ˜ì • |
| 2026-02-25 | Qwen DenseCL `Expected features with 2 or 4 dims, got 3` | `DenseCLLoss.forward` ndim==3 ì²˜ë¦¬ + finetune.py else-branch ìˆ˜ì • |
| 2026-02-26 | Gemma3 DenseCL `loss=0.0, grad_norm=nan` ì „ì²´ í•™ìŠµ ì‹¤íŒ¨ | `dtype: float16 â†’ bfloat16`, `mixed_precision: fp16 â†’ bf16` |
| 2026-02-26 | Gemma3 `multi_modal_projector` output 3D `[N, 256, 2560]` | finetune.py `_compute_densecl` else-branch ndim==3 ì§ì ‘ ì¸ë±ì‹± |

---

## 9. ë…¼ë¬¸ Table â€” PanoAdapt vs Native Baseline

> ì™„ì„± ì˜ˆì • (B3 DenseCL + ì „ì²´ VICReg-pw eval ì™„ë£Œ í›„)

### Table 1: PanoAdapt(DenseCL) vs Native Baseline

| Model | Native CIDEr | PanoAdapt CIDEr | Î” |
|-------|:---:|:---:|:---:|
| InternVL3.5-2B | 0.3405 | **0.3603** | **+5.8%** âœ… |
| Qwen2.5-VL-3B | 0.3306 | 0.3396 | +2.7% âœ… |
| Gemma3-4B | 0.3363 | **0.3362** | -0.03% âœ… |

### Table 2: DenseCL vs VICReg-pairwise (self-supervised loss ë¹„êµ)

| Model | Native | DenseCL | VICReg-pw 25% | VICReg-pw 50% |
|-------|:---:|:---:|:---:|:---:|
| InternVL3.5-2B | 0.3405 | **0.3603** | **0.3594** | ğŸ”µ í•™ìŠµì¤‘ |
| Qwen2.5-VL-3B | 0.3306 | 0.3396 | â€” | â³ í |
| Gemma3-4B | 0.3363 | 0.3362 | â€” | â³ í |

---

## 10. í•µì‹¬ ë°œê²¬

1. **val_loss â‰  ìƒì„± í’ˆì§ˆ.** Stage 3 val_lossëŠ” ëª¨ë“  lossê°€ 2.59~2.61ë¡œ ìˆ˜ë ´í•˜ì§€ë§Œ, Test evalì—ì„œ DenseCL(CIDEr=0.108)ê³¼ InfoNCE(CIDEr=0.005)ëŠ” 20ë°° ì°¨ì´.
2. **DenseCLì´ ê°€ì¥ íš¨ê³¼ì ì¸ vision alignment ì œê³µ.** ê°€ì¥ ë‹¨ìˆœí•œ loss(single-view overlap InfoNCE)ê°€ ê°€ì¥ ì¢‹ì€ ìƒì„± í’ˆì§ˆì„ ì‚°ì¶œ.
3. **PanoAdapt InternVL DenseCL +5.8% (CIDEr 0.3405â†’0.3603).** ê°€ì¥ ëª…í™•í•œ PanoAdapt íš¨ê³¼.
4. **PanoAdapt Qwen DenseCL -0.3% (CIDEr 0.3306â†’0.3396).** ëª¨ë¸ë³„ë¡œ íš¨ê³¼ ì°¨ì´ ì¡´ì¬. â†’ **ì›ì¸ ê·œëª…ë¨ (ë°œê²¬ #8 ì°¸ì¡°)**
5. **Gemma3ëŠ” ë°˜ë“œì‹œ bf16.** fp16ìœ¼ë¡œ í•™ìŠµ ì‹œ multi-image (9 views Ã— 256 tokens) attentionì—ì„œ overflow â†’ `loss=0.0, grad_norm=nan`. ì²˜ìŒë¶€í„° í•™ìŠµ ì‹¤íŒ¨.
6. **Native processingì´ 256Â² resize ëŒ€ë¹„ ëŒ€í­ ê°œì„ .** InternVL3.5-1Bì—ì„œ CIDEr +59.4%.
7. **Overlap 50%ëŠ” Stage 1 metricsëŠ” í–¥ìƒì‹œí‚¤ì§€ë§Œ ìƒì„± í’ˆì§ˆì€ ì•…í™”.** Trivial solution ë¬¸ì œê°€ loss ì¢…ë¥˜ì™€ ë¬´ê´€í•˜ê²Œ ì¬í˜„.
8. **âš ï¸ [CRITICAL] Qwen2.5-VLì˜ overlap lossëŠ” gradientê°€ ì‚¬ì‹¤ìƒ ë¬´íš¨ì˜€ìŒ. (ì‹¤ì¦ í™•ì¸ 2026-02-27)**
   - **ê·¼ë³¸ ì›ì¸**: Qwen2.5-VLì˜ vision encoder attentionì€ fused `qkv` (ë‹¨ì¼ `nn.Linear(dim, dim*3)`)ë¥¼ ì‚¬ìš©. PEFT `target_modules=["q_proj", "k_proj", "v_proj", "o_proj"]`ì™€ **ì´ë¦„ì´ ë§¤ì¹­ë˜ì§€ ì•Šì•„** vision encoderì— LoRAê°€ ì‚½ì…ë˜ì§€ ì•ŠìŒ.
   - **ì‹¤ì¦**: `torch.device("meta")`ì—ì„œ `named_modules()` ê²€ì¦ â†’ Qwen vision LoRA ë§¤ì¹­ **0ê°œ**, Gemma3 **81ê°œ**, InternVL **ë‹¤ìˆ˜**.
   - **ê²°ê³¼**: DenseCL loss gradientê°€ PatchMerger â†’ ViTê¹Œì§€ ì—­ì „íŒŒë˜ì§€ë§Œ, trainable parameterê°€ ì—†ì–´ ì•„ë¬´ê²ƒë„ ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠìŒ.
   - **ëª¨ë¸ë³„ LoRA ì‚½ì… í˜„í™© (ì‹¤ì¸¡):**

     | ëª¨ë¸ | Vision Encoder Attn | Vision LoRA ë§¤ì¹­ ìˆ˜ | LLM LoRA ë§¤ì¹­ ìˆ˜ | DenseCL CIDEr Î” |
     |------|-------------------|:---:|:---:|:---:|
     | Qwen2.5-VL-3B | fused `qkv` + `proj` | **0ê°œ** | 144ê°œ | +2.7% (PE only) |
     | InternVL3.5-2B | ë³„ë„ `q_proj`/`k_proj`/`v_proj` | **ë‹¤ìˆ˜** | ë‹¤ìˆ˜ | **+5.8%** |
     | Gemma3-4B (SigLIP2) | ë³„ë„ `q_proj`/`k_proj`/`v_proj`/`out_proj` | **81ê°œ** | 136ê°œ | **-0.03%** |

   - **í•´ì„**:
     - **Qwen** (-0.3%â†’+2.7%): Overlap loss ë¬´íš¨, spatial PEë§Œ ì ìš©. ê°œì„ ë¶„ì€ PE ê¸°ì—¬.
     - **InternVL** (+5.8%): Vision LoRA ë§¤ì¹­ âœ… â†’ overlap loss + PE ë‘˜ ë‹¤ ì‘ë™ â†’ ìµœëŒ€ ê°œì„ .
     - **Gemma3** (-0.03%): Vision LoRA ë§¤ì¹­ âœ… â†’ **gradientëŠ” íë¥´ì§€ë§Œ íš¨ê³¼ ì—†ìŒ.** ê°€ëŠ¥í•œ ì›ì¸:
       - `Gemma3MultiModalProjector`ê°€ `AvgPool2d`ë¡œ spatial pooling â†’ patch-level correspondence ì•½í™”
       - vision LoRA 81ê°œê°€ LM loss gradientì— ì••ë„ë¨ (overlap_loss_weight=0.1)
       - SigLIP2ì˜ panoramic feature íŠ¹ì„±ì´ InternViTì™€ ë‹¤ë¦„
       - train_loss=12.46ìœ¼ë¡œ InternVL ëŒ€ë¹„ í•™ìŠµ ë¶ˆì•ˆì •
---

## 11. ì‹¤í–‰ í˜„í™©

### âœ… ì™„ë£Œ

- [x] Loss Comparison A/B/C/D/B'/D' â€” 3-stage í•™ìŠµ + Test eval
- [x] Baseline í‰ê°€ 6/6 ëª¨ë¸ (256Â² resize)
- [x] Multi-view Strategy Comparison (Track M) â€” 4 strategies
- [x] Track A native training+eval â€” 4ëª¨ë¸ (InternVL3.5-2B/1B, Qwen2.5-VL-3B, Gemma3-4B)
- [x] **B2 InternVL3.5-2B PanoAdapt DenseCL** â€” CIDEr=0.3603 (+5.8%)
- [x] **B1 Qwen2.5-VL-3B PanoAdapt DenseCL** â€” CIDEr=0.3396 (-0.3%)
- [x] **B3 Gemma3-4B DenseCL** â€” CIDEr=0.3362 (-0.03% vs native, Qwenê³¼ ë™ì¼ íŒ¨í„´)
- [x] Gemma3 fp16â†’bf16 ë²„ê·¸ ìˆ˜ì • (`panoadapt_gemma3_4b.yaml`, `panoadapt_vicreg_pairwise_gemma3_4b.yaml`)

### ğŸ”µ ì§„í–‰ì¤‘ (GPU 1, tmux: gpu1-trackb:phase2-watcher)

- [x] **B2v (25%) InternVL VICReg-pw eval** â€” CIDEr=0.3594 (+5.5%) âœ…
- [ ] **B2v (50%) InternVL VICReg-pw í•™ìŠµ** â€” ğŸ”µ 14% (284/1983), ~2h ë‚¨ìŒ
  - [ ] B2v (50%) InternVL eval â€” í•™ìŠµ ì™„ë£Œ í›„ ìë™ ì‹œì‘
  - [ ] B1v Qwen VICReg-pw 50% í•™ìŠµ+eval â€” B2v 50% ì™„ë£Œ í›„ ìë™
  - [ ] B3v Gemma3 VICReg-pw 50% í•™ìŠµ+eval â€” B1v ì™„ë£Œ í›„ ìë™ (bf16 ìˆ˜ì •ë¨)
  - [ ] B3v Gemma3 VICReg-pw 50% í•™ìŠµ+eval (bf16 ìˆ˜ì •ë¨)

### âš ï¸ ì´ìƒ/ë³´ë¥˜

- [ ] Track C cubemap/e2p eval â€” ìš°ì„ ìˆœìœ„ ë‚®ìŒ

### âŒ SKIP

- [x] InternVL2.5-4B/2B â€” ì•„í‚¤í…ì²˜ ë¹„í˜¸í™˜
- [x] BLIP2 native â€” fp16 scaler crash

---

## 12. GPU í í˜„í™© (2026-02-27)

| GPU | ì„¸ì…˜ | ìƒíƒœ | ì‘ì—… |
|:---:|------|------|------|
| 0 | â€” | ìœ íœ´ (26MB) | â€” |
| 1 | `gpu1-trackb:phase2-watcher` | ğŸ”µ VICReg-pw 50% InternVL í•™ìŠµì¤‘ (14%) â†’ Qwen â†’ Gemma3 ìë™ ì²´ì´ë‹ | VICReg-pw 50% Ã— 3ëª¨ë¸ |

**ì˜ˆìƒ íƒ€ì„ë¼ì¸ (í˜„ì¬ ê¸°ì¤€):**

| ì‹œê° (KST) | ì™„ë£Œ ì˜ˆì • |
|-----------|---------|
| ~~02:30~~ | ~~B3 Gemma3 DenseCL eval~~ âœ… (13:47 ì™„ë£Œ) |
| ~~17:18~~ | ~~VICReg-pw 25% InternVL eval~~ âœ… (CIDEr=0.3594) |
| ~20:00 | VICReg-pw 50% InternVL í•™ìŠµ+eval |
| ~23:00 | VICReg-pw 50% Qwen í•™ìŠµ+eval |
| ~02:00 (28ì¼) | VICReg-pw 50% Gemma3 í•™ìŠµ+eval |

---

## 13. íŒŒì¼ ìœ„ì¹˜

```
configs/baseline/
â”œâ”€â”€ panoadapt_internvl35_2b.yaml              # B2 DenseCL âœ…
â”œâ”€â”€ panoadapt_gemma3_4b.yaml                  # B3 DenseCL (bf16 ìˆ˜ì •) âœ…
â”œâ”€â”€ panoadapt_vicreg_pairwise_internvl35_2b_25overlap.yaml  # B2v 25% âœ…
â”œâ”€â”€ panoadapt_vicreg_pairwise_internvl35_2b.yaml            # B2v 50% âœ…
â”œâ”€â”€ panoadapt_vicreg_pairwise_qwen25_3b.yaml                # B1v 50% âœ…
â””â”€â”€ panoadapt_vicreg_pairwise_gemma3_4b.yaml                # B3v 50% (bf16 ìˆ˜ì •) âœ…

runs/baseline/
â”œâ”€â”€ native_internvl35-2b/eval/      # CIDEr=0.3405
â”œâ”€â”€ native_qwen25-vl-3b/eval/       # CIDEr=0.3306
â”œâ”€â”€ native_gemma3-4b/eval/          # CIDEr=0.3363
â”œâ”€â”€ native_internvl35-1b/eval/      # CIDEr=0.3171
â”œâ”€â”€ panoadapt_internvl35-2b/eval/   # CIDEr=0.3603 âœ…
â”œâ”€â”€ panoadapt_qwen25-vl-3b/eval/    # CIDEr=0.3396 âœ…
â”œâ”€â”€ panoadapt_gemma3-4b/eval/          # CIDEr=0.3362 âœ…
â””â”€â”€ panoadapt_vicreg_pairwise_internvl35-2b_25overlap/eval/  # CIDEr=0.3594 âœ…

scripts/
â”œâ”€â”€ run_gpu1_trackb.sh   # B1+B3 DenseCL (ì™„ë£Œ)
â””â”€â”€ run_gpu1_phase2.sh   # VICReg-pw Phase 2 (ìë™ ì²´ì´ë‹)
```

---

## 14. Experiment 7 â€” B1-fix: Qwen2.5-VL Overlap Loss Gradient Fix

### 14.1 ë¬¸ì œ

B1 (Qwen2.5-VL PanoAdapt DenseCL)ì˜ CIDEr=-0.3%ëŠ” overlap lossê°€ ì•„ë¬´ëŸ° gradient íš¨ê³¼ë¥¼ ì£¼ì§€ ëª»í•œ ê²°ê³¼.
Qwen2.5-VLì˜ vision encoder (`Qwen2_5_VLVisionAttention`)ê°€ fused `self.qkv = nn.Linear(dim, dim*3)` ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì—,
`target_modules=["q_proj", "k_proj", "v_proj", "o_proj"]`ì— ë§¤ì¹­ë˜ì§€ ì•Šì•„ vision encoderì— LoRAê°€ ì „í˜€ ì‚½ì…ë˜ì§€ ì•ŠìŒ.

### 14.2 ìˆ˜ì • ë°©ì•ˆ

**ì½”ë“œ ìˆ˜ì •**: YAMLì—ì„œ Qwen ì „ìš© `target_modules`ë¥¼ overrideí•˜ì—¬ vision encoderì˜ `qkv`, `proj`ë¥¼ í¬í•¨.
models.pyì˜ defaultëŠ” ê±´ë“œë¦¬ì§€ ì•Šê³ , YAML configì—ì„œë§Œ í™•ì¥í•˜ì—¬ ë‹¤ë¥¸ ëª¨ë¸ì— ì˜í–¥ ì—†ìŒ.

```yaml
# panoadapt_pe_densecl_qwen25_3b_fix.yaml
lora:
  r: 32
  alpha: 64
  dropout: 0.1
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "attn.qkv"     # Qwen vision encoder fused QKV (32 blocks)
    - "attn.proj"    # Qwen vision encoder output projection (32 blocks)
```

**âš ï¸ ì£¼ì˜**: PEFTëŠ” `endswith` ë§¤ì¹­ì„ ì‚¬ìš©. `"attn.proj"`ëŠ” `o_proj`ì™€ ê²¹ì¹˜ì§€ ì•ŠìŒ (PEFTëŠ” `.`ì„ í¬í•¨í•œ ì „ì²´ suffixë¥¼ ë¹„êµ).
**ëŒ€ì•ˆ A â€” Qwen ì „ìš© target_modules (YAML override):**
```yaml
# panoadapt_pe_densecl_qwen25_3b.yaml
lora:
  r: 32
  alpha: 64
  dropout: 0.1
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "attn.qkv"     # Qwen vision encoder fused QKV
    - "attn.proj"    # Qwen vision encoder output projection
```

**ëŒ€ì•ˆ B â€” ì •ê·œì‹ (PEFT ì§€ì›):**
```yaml
lora:
  target_modules: "(q_proj|k_proj|v_proj|o_proj|attn\\.qkv|attn\\.proj)"
```

### 14.3 ì‹¤í—˜ ì„¤ê³„

| ID | ì„¤ëª… | ë³€ê²½ì  | ë¹„êµ ëŒ€ìƒ |
|:---:|------|--------|----------|
| B1-fix | Qwen2.5-VL DenseCL + vision LoRA | YAML `target_modules`ì— `attn.qkv`, `attn.proj` ì¶”ê°€ | B1 (vision LoRA ì—†ìŒ) |
| B1-pe-only | Qwen2.5-VL Spatial PE only (no overlap loss) | `overlap_loss: false` | B1 (PE + dead overlap loss) |

**B1-fix ì˜ˆìƒ**: InternVLê³¼ ìœ ì‚¬í•˜ê²Œ CIDEr ê°œì„  (+3~6% ë²”ìœ„)
**B1-pe-only ì˜ˆìƒ**: B1ê³¼ ê±°ì˜ ë™ì¼ (overlap lossê°€ ì›ë˜ ë¬´íš¨ì˜€ìœ¼ë¯€ë¡œ)

B1-pe-onlyê°€ B1ê³¼ ë™ì¼í•˜ë©´ â†’ overlap lossê°€ ì •ë§ ë¬´íš¨ì˜€ìŒì„ ì‹¤í—˜ì ìœ¼ë¡œ í™•ì¸.
B1-fixê°€ B1ë³´ë‹¤ ê°œì„ ë˜ë©´ â†’ vision LoRAë¥¼ í†µí•œ overlap loss gradientê°€ ì‹¤ì œë¡œ ë„ì›€.

### 14.4 trainable parameter ë³€í™” ì˜ˆìƒ

```
í˜„ì¬ B1:
  LLM: model.layers[*].self_attn.{q,k,v,o}_proj  (28 layers Ã— 4 = 112 LoRA modules)
  Vision: ì—†ìŒ

B1-fix:
  LLM: model.layers[*].self_attn.{q,k,v,o}_proj  (28 layers Ã— 4 = 112 LoRA modules)
  Vision: visual.blocks[*].attn.qkv               (32 blocks Ã— 1 = 32 LoRA modules)
  Vision: visual.blocks[*].attn.proj               (32 blocks Ã— 1 = 32 LoRA modules)
  â†’ trainable params ì•½ 50% ì¦ê°€ ì˜ˆìƒ
```

### 14.5 ì‹¤í–‰ ìˆœì„œ

1. `src/cora/baseline/models.py` ìˆ˜ì • â€” Qwen ì „ìš© lora targets í™•ì¥
2. `configs/baseline/panoadapt_pe_densecl_qwen25_3b_fix.yaml` ìƒì„±
3. B1-fix í•™ìŠµ (GPU 0, ~2h ì˜ˆìƒ)
4. B1-fix eval (GPU 0, ~3h ì˜ˆìƒ)
5. B1-pe-only í•™ìŠµ+eval (ablationìš©, B1-fix ì™„ë£Œ í›„)
6. ê²°ê³¼ ë¹„êµ: B1 vs B1-fix vs B1-pe-only

### 14.6 ì„±ê³µ ê¸°ì¤€

- B1-fix CIDEr > B1 CIDEr (0.3396) â†’ vision LoRA overlap loss íš¨ê³¼ ì…ì¦
- B1-pe-only CIDEr â‰ˆ B1 CIDEr â†’ ê¸°ì¡´ B1ì˜ overlap lossê°€ ë¬´íš¨ì˜€ìŒ í™•ì¸
- `model.print_trainable_parameters()` ì¶œë ¥ì—ì„œ vision encoder LoRA module ì¡´ì¬ í™•ì¸
