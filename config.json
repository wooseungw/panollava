{
  "paths": {
    "checkpoint_pattern": "runs/{prefix}_{crop_strategy}_{stage}_{resampler}/best.ckpt",
    "runs_dir": "runs",
    "csv_train": "data/quic360/train.csv",
    "csv_val": "data/quic360/valid.csv"
  },
  "models": {
    "vision_name": "google/siglip-base-patch16-224",
    "lm_model": "Qwen/Qwen2.5-0.5B-Instruct",
    "resampler": "mlp",
    "latent_dimension": 1536,
    "resampler_depth": 2,
    "resampler_hidden_dim": 1536,
    "resampler_use_ln": true
  },
  "image_processing": {
    "crop_strategy": "e2p",
    "image_size": [224, 224],
    "overlap_ratio": 0.5,
    "fov_deg": 90.0,
    "image_mean": [0.485, 0.456, 0.406],
    "image_std": [0.229, 0.224, 0.225],
    "use_vision_processor": true,
    "anyres_patch_size": 336,
    "anyres_max_patches": 12,
    "normalize": true
  },
  "training": {
    "prefix": "SiglipQwen25_it_vichead_",
    "default_stage": "finetune",
    "stages": ["vision", "resampler", "finetune"],
    "num_workers": 16,
    "epochs": 1,
    "batch_size": 8,
    "lr": 5e-5,
    "max_text_length": 256,
    "system_msg": "You are a helpful assistant.",
    "wandb_project": "panollava-training",
    "vision": {
      "epochs": 2,
      "lr": 1e-4,
      "batch_size": 16,
      "vicreg_loss_weight": 1.0,
      "vicreg_similarity_weight": 25.0,
      "vicreg_variance_weight": 25.0,
      "vicreg_covariance_weight": 1.0,
      "max_text_length": 32
    },
    "resampler": {
      "epochs": 1,
      "lr": 2e-6,
      "batch_size": 4,
      "vicreg_loss_weight": 0.0,
      "max_text_length": 32
    },
    "finetune": {
      "epochs": 1,
      "lr": 2e-6,
      "batch_size": 4,
      "vicreg_loss_weight": 0.0,
      "max_text_length": 32
    }
  },
  "environment": {
    "cuda_visible_devices": "1",
    "wandb_project": "panollava-training"
  },
  "data": {
    "csv_train": "data/quic360/train.csv",
    "csv_val": "data/quic360/valid.csv",
    "max_text_length": 256
  },
  "system_messages": {
    "default": "You are a helpful assistant."
  },
  "lora": {
    "use_lora": true,
    "rank": 32,
    "alpha": 64,
    "dropout": 0.1,
    "target_modules": [
      "q_proj",
      "k_proj", 
      "v_proj",
      "o_proj",
      "gate_proj",
      "up_proj",
      "down_proj"
    ],
    "save_lora_only": false
  }
}