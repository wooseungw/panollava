#!/usr/bin/env python3
# coding: utf-8
"""
PanoramaVLM ëª¨ë¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
==============================

í›ˆë ¨ê³¼ í‰ê°€ ê°„ ì¼ê´€ëœ ëª¨ë¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.
ìƒˆë¡œìš´ í†µí•© ì¸í„°í˜ì´ìŠ¤ì™€ ê¸°ì¡´ ì½”ë“œ ê°„ì˜ ë¸Œë¦¿ì§€ ì—­í• ì„ í•©ë‹ˆë‹¤.
"""

import torch
from pathlib import Path
from typing import Optional, Union, Dict, Any
import logging

logger = logging.getLogger(__name__)

def load_panorama_model(
    checkpoint_path: Union[str, Path], 
    lora_weights_path: Optional[Union[str, Path]] = None,
    device: str = "auto",
    use_new_interface: bool = True,
    **kwargs
):
    """
    í†µí•©ëœ PanoramaVLM ëª¨ë¸ ë¡œë”© í•¨ìˆ˜
    
    í›ˆë ¨ê³¼ í‰ê°€ì—ì„œ ì¼ê´€ëœ ë°©ì‹ìœ¼ë¡œ ëª¨ë¸ì„ ë¡œë”©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
    ìƒˆë¡œìš´ ì¸í„°í˜ì´ìŠ¤ë¥¼ ìš°ì„  ì‚¬ìš©í•˜ê³ , ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±í•©ë‹ˆë‹¤.
    
    Args:
        checkpoint_path: ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ
        lora_weights_path: LoRA ê°€ì¤‘ì¹˜ ê²½ë¡œ (ì„ íƒì )
        device: ë””ë°”ì´ìŠ¤ ì„¤ì • ("auto", "cuda", "cpu")
        use_new_interface: ìƒˆë¡œìš´ ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš© ì—¬ë¶€
        **kwargs: ì¶”ê°€ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë“¤
        
    Returns:
        ë¡œë“œëœ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
        
    Example:
        # ê¸°ë³¸ ì‚¬ìš©ë²•
        model = load_panorama_model("runs/best.ckpt")
        
        # í‰ê°€ìš© (eval.pyì™€ í˜¸í™˜)
        model = load_panorama_model("runs/best.ckpt", device="cuda")
        
        # í›ˆë ¨ìš© (train.pyì—ì„œ resume ì‹œ)
        model = load_panorama_model("runs/best.ckpt", use_new_interface=False)
    """
    checkpoint_path = Path(checkpoint_path)
    
    if use_new_interface:
        try:
            # ìƒˆë¡œìš´ í†µí•© ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš©
            from panovlm.model import PanoramaVLM
            
            logger.info(f"ğŸš€ ìƒˆë¡œìš´ ì¸í„°í˜ì´ìŠ¤ë¡œ ëª¨ë¸ ë¡œë”©: {checkpoint_path}")
            
            if checkpoint_path.is_dir():
                # ë””ë ‰í† ë¦¬ì¸ ê²½ìš° from_pretrained ì‚¬ìš©
                model = PanoramaVLM.from_pretrained(str(checkpoint_path), device=device, **kwargs)
            else:
                # íŒŒì¼ì¸ ê²½ìš° from_checkpoint ì‚¬ìš©
                model = PanoramaVLM.from_checkpoint(
                    str(checkpoint_path), 
                    lora_weights_path=str(lora_weights_path) if lora_weights_path else None,
                    device=device, 
                    **kwargs
                )
            
            logger.info("âœ… ìƒˆë¡œìš´ ì¸í„°í˜ì´ìŠ¤ë¡œ ë¡œë”© ì„±ê³µ")
            return model
            
        except Exception as e:
            logger.warning(f"âš ï¸ ìƒˆë¡œìš´ ì¸í„°í˜ì´ìŠ¤ ë¡œë”© ì‹¤íŒ¨: {e}")
            logger.info("ğŸ”„ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±...")
    
    # ê¸°ì¡´ ë°©ì‹ ì‚¬ìš© (í›ˆë ¨ ì½”ë“œì™€ í˜¸í™˜)
    try:
        from train import VLMModule
        
        logger.info(f"ğŸ”§ ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ë¡œ ëª¨ë¸ ë¡œë”©: {checkpoint_path}")
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        if device == "auto":
            device_obj = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            device_obj = torch.device(device)
        
        # Lightning ë°©ì‹ìœ¼ë¡œ ë¡œë”©
        model = VLMModule.load_from_checkpoint(
            str(checkpoint_path),
            map_location=device_obj,
            strict=False,
            **kwargs
        )
        
        # LoRA ê°€ì¤‘ì¹˜ ë¡œë”© (í•„ìš”í•œ ê²½ìš°)
        if lora_weights_path and Path(lora_weights_path).exists():
            logger.info(f"ğŸ”§ LoRA ê°€ì¤‘ì¹˜ ë¡œë”©: {lora_weights_path}")
            success = model.model.load_lora_weights(str(lora_weights_path))
            if success:
                logger.info("âœ… LoRA ê°€ì¤‘ì¹˜ ë¡œë”© ì„±ê³µ")
            else:
                logger.warning("âš ï¸ LoRA ê°€ì¤‘ì¹˜ ë¡œë”© ì‹¤íŒ¨")
        
        model.eval()
        model = model.to(device_obj)
        
        logger.info("âœ… ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ë¡œ ë¡œë”© ì„±ê³µ")
        return model
        
    except Exception as e:
        logger.error(f"âŒ ëª¨ë“  ë¡œë”© ë°©ì‹ ì‹¤íŒ¨: {e}")
        raise


def save_panorama_model(
    model, 
    save_path: Union[str, Path],
    save_format: str = "all",
    save_lora_separately: bool = True
):
    """
    PanoramaVLM ëª¨ë¸ì„ ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥
    
    Args:
        model: ì €ì¥í•  ëª¨ë¸ (VLMModule ë˜ëŠ” PanoramaVLM)
        save_path: ì €ì¥ ê²½ë¡œ
        save_format: ì €ì¥ í˜•ì‹ ("all", "hf", "lightning", "safetensors")
        save_lora_separately: LoRA ê°€ì¤‘ì¹˜ ë³„ë„ ì €ì¥ ì—¬ë¶€
    """
    save_path = Path(save_path)
    save_path.mkdir(parents=True, exist_ok=True)
    
    # ì‹¤ì œ PanoramaVLM ëª¨ë¸ ì¶”ì¶œ
    if hasattr(model, 'model') and hasattr(model.model, 'save_pretrained'):
        # VLMModuleì¸ ê²½ìš°
        panorama_model = model.model
        lightning_model = model
    elif hasattr(model, 'save_pretrained'):
        # ì´ë¯¸ PanoramaVLMì¸ ê²½ìš°
        panorama_model = model
        lightning_model = None
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…: {type(model)}")
    
    logger.info(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘: {save_path} (í˜•ì‹: {save_format})")
    
    if save_format in ("all", "hf"):
        # HuggingFace ìŠ¤íƒ€ì¼ ì €ì¥
        hf_path = save_path / "hf_model"
        panorama_model.save_pretrained(str(hf_path), save_lora_separately=save_lora_separately)
        logger.info(f"âœ… HuggingFace ìŠ¤íƒ€ì¼ ì €ì¥: {hf_path}")
    
    if save_format in ("all", "lightning") and lightning_model is not None:
        # Lightning ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        lightning_path = save_path / "lightning_model.ckpt"
        torch.save(lightning_model.state_dict(), lightning_path)
        logger.info(f"âœ… Lightning ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {lightning_path}")
    
    if save_format in ("all", "safetensors"):
        # SafeTensors ì €ì¥
        safetensors_path = save_path / "model.safetensors"
        try:
            from safetensors.torch import save_file
            save_file(panorama_model.state_dict(), safetensors_path)
            logger.info(f"âœ… SafeTensors ì €ì¥: {safetensors_path}")
        except ImportError:
            logger.warning("âš ï¸ SafeTensors íŒ¨í‚¤ì§€ê°€ ì—†ì–´ ê±´ë„ˆëœ€")
    
    logger.info(f"ğŸ‰ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}")


def get_model_info(model) -> Dict[str, Any]:
    """
    ëª¨ë¸ì˜ ìƒì„¸ ì •ë³´ë¥¼ ë°˜í™˜
    
    Args:
        model: ë¶„ì„í•  ëª¨ë¸
        
    Returns:
        ëª¨ë¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬
    """
    # ì‹¤ì œ PanoramaVLM ëª¨ë¸ ì¶”ì¶œ
    if hasattr(model, 'model'):
        panorama_model = model.model
        is_lightning = True
    else:
        panorama_model = model
        is_lightning = False
    
    info = {
        "model_type": type(panorama_model).__name__,
        "is_lightning_wrapper": is_lightning,
        "total_parameters": sum(p.numel() for p in panorama_model.parameters()),
        "trainable_parameters": sum(p.numel() for p in panorama_model.parameters() if p.requires_grad),
        "device": str(next(panorama_model.parameters()).device),
        "training_mode": panorama_model.training,
    }
    
    # LoRA ì •ë³´ ì¶”ê°€
    if hasattr(panorama_model, 'get_lora_info'):
        lora_info = panorama_model.get_lora_info()
        info["lora_info"] = lora_info
    
    # ëª¨ë¸ êµ¬ì„± ì •ë³´ ì¶”ê°€
    try:
        info.update({
            "vision_model": getattr(panorama_model.vision_encoder.config, 'name_or_path', 'unknown'),
            "language_model": getattr(panorama_model.language_model.config, 'name_or_path', 'unknown'),
            "max_text_length": getattr(panorama_model, 'max_text_length', 'unknown'),
            "vicreg_loss_weight": getattr(panorama_model, 'vicreg_loss_weight', 'unknown'),
        })
    except Exception:
        pass
    
    return info


def print_model_info(model):
    """
    ëª¨ë¸ ì •ë³´ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥
    """
    info = get_model_info(model)
    
    print("=" * 60)
    print("ğŸ” ëª¨ë¸ ì •ë³´")
    print("=" * 60)
    
    print(f"ğŸ“Š ê¸°ë³¸ ì •ë³´:")
    print(f"   - ëª¨ë¸ íƒ€ì…: {info['model_type']}")
    print(f"   - Lightning ë˜í¼: {info['is_lightning_wrapper']}")
    print(f"   - ë””ë°”ì´ìŠ¤: {info['device']}")
    print(f"   - í›ˆë ¨ ëª¨ë“œ: {info['training_mode']}")
    
    print(f"\nğŸ“ˆ íŒŒë¼ë¯¸í„° ì •ë³´:")
    total = info['total_parameters']
    trainable = info['trainable_parameters']
    print(f"   - ì „ì²´ íŒŒë¼ë¯¸í„°: {total:,}")
    print(f"   - í›ˆë ¨ ê°€ëŠ¥: {trainable:,} ({trainable/total*100:.1f}%)")
    
    if 'lora_info' in info and info['lora_info'].get('is_lora_enabled', False):
        lora = info['lora_info']
        print(f"\nğŸ¯ LoRA ì •ë³´:")
        print(f"   - í™œì„±í™”: {lora['is_lora_enabled']}")
        print(f"   - Rank: {lora.get('lora_r', 'N/A')}")
        print(f"   - Alpha: {lora.get('lora_alpha', 'N/A')}")
        print(f"   - Dropout: {lora.get('lora_dropout', 'N/A')}")
    
    if 'vision_model' in info:
        print(f"\nğŸ–¼ï¸  ëª¨ë¸ êµ¬ì„±:")
        print(f"   - Vision: {info['vision_model']}")
        print(f"   - Language: {info['language_model']}")
        print(f"   - Max text length: {info['max_text_length']}")
        print(f"   - VICReg weight: {info['vicreg_loss_weight']}")
    
    print("=" * 60)


# í¸ì˜ í•¨ìˆ˜ë“¤
def quick_load(checkpoint_path: str, **kwargs):
    """ë¹ ë¥¸ ëª¨ë¸ ë¡œë”© (ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•)"""
    return load_panorama_model(checkpoint_path, **kwargs)


def load_for_training(checkpoint_path: str, **kwargs):
    """í›ˆë ¨ìš© ëª¨ë¸ ë¡œë”© (Lightning ë°©ì‹)"""
    return load_panorama_model(checkpoint_path, use_new_interface=False, **kwargs)


def load_for_inference(checkpoint_path: str, **kwargs):
    """ì¶”ë¡ ìš© ëª¨ë¸ ë¡œë”© (ìƒˆ ì¸í„°í˜ì´ìŠ¤)"""
    return load_panorama_model(checkpoint_path, use_new_interface=True, **kwargs)


if __name__ == "__main__":
    # ì‚¬ìš© ì˜ˆì‹œ
    import argparse
    
    parser = argparse.ArgumentParser(description="ëª¨ë¸ ìœ í‹¸ë¦¬í‹° í…ŒìŠ¤íŠ¸")
    parser.add_argument("--checkpoint", required=True, help="ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ")
    parser.add_argument("--info-only", action="store_true", help="ì •ë³´ë§Œ ì¶œë ¥")
    
    args = parser.parse_args()
    
    try:
        print(f"ğŸš€ ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸: {args.checkpoint}")
        model = quick_load(args.checkpoint)
        
        print_model_info(model)
        
        if not args.info_only:
            print("\nâœ… ëª¨ë¸ ë¡œë”© ë° ì •ë³´ ì¶œë ¥ ì„±ê³µ!")
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")