#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë°ì´í„°ì…‹ ë°°ì¹˜ ì¶œë ¥ ì‹œê°í™” ë° ë¶„ì„ í…ŒìŠ¤íŠ¸
===========================================

ìƒˆë¡œ êµ¬ì„±ëœ ChatPanoDatasetì˜ í•œ ë°°ì¹˜ ì¶œë ¥ì„ ìƒì„¸íˆ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” í…ŒìŠ¤íŠ¸ ì½”ë“œì…ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. Train/Eval ëª¨ë“œë³„ ë°°ì¹˜ ì¶œë ¥ ë¶„ì„
2. í† í°í™” ê²°ê³¼ ë° ë¼ë²¨ ì‹œê°í™”
3. ì´ë¯¸ì§€ ì²˜ë¦¬ ê²°ê³¼ í™•ì¸
4. ë°°ì¹˜ êµ¬ì¡° ë° ë©”íƒ€ë°ì´í„° ë¶„ì„
5. í…ìŠ¤íŠ¸ í¬ë§·íŒ… ê²°ê³¼ í™•ì¸
"""

import os
import sys
import torch
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from pathlib import Path
from PIL import Image
from torch.utils.data import DataLoader
from transformers import AutoTokenizer
import pandas as pd

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
sys.path.append('/data/1_personal/4_SWWOO/panollava')

from panovlm.dataset import ChatPanoDataset, custom_collate_fn
from panovlm.processors.pano_llava_processor import PanoLLaVAProcessor
from panovlm.processors.image import PanoramaImageProcessor
from panovlm.processors.universal_text_formatter import UniversalTextFormatter
from transformers import AutoTokenizer

# matplotlib í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = ['DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

def setup_test_environment():
    """í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •"""
    print("=" * 80)
    print("ğŸ”§ ë°ì´í„°ì…‹ ë°°ì¹˜ ì‹œê°í™” í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 80)
    
    # ì„¤ì •ê°’
    config = {
        'csv_path': "data/quic360/downtest.csv",
        'vision_model': "google/siglip-base-patch16-224",
        'language_model': "Qwen/Qwen2.5-0.5B-Instruct",
        'batch_size': 16,
        'max_text_length': 256,
        'image_size': (224, 224),
        'crop_strategy': "e2p",
        'device': "cuda" if torch.cuda.is_available() else "cpu"
    }
    
    print(f"ğŸ“ CSV ê²½ë¡œ: {config['csv_path']}")
    print(f"ğŸ’» ë””ë°”ì´ìŠ¤: {config['device']}")
    print(f"ğŸ—ï¸  ë°°ì¹˜ í¬ê¸°: {config['batch_size']}")
    print(f"ğŸ“ ìµœëŒ€ í…ìŠ¤íŠ¸ ê¸¸ì´: {config['max_text_length']}")
    
    # CSV íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not Path(config['csv_path']).exists():
        raise FileNotFoundError(f"CSV íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {config['csv_path']}")
    
    return config

def create_processors(config):
    """í”„ë¡œì„¸ì„œ ë° í† í¬ë‚˜ì´ì € ìƒì„±"""
    print("\nğŸ“Š í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì¤‘...")
    
    # ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œ
    img_proc = PanoramaImageProcessor(
        image_size=config['image_size'],
        crop_strategy=config['crop_strategy']
    )
    
    # í† í¬ë‚˜ì´ì €
    tokenizer = AutoTokenizer.from_pretrained(config['language_model'])
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token or tokenizer.bos_token
    
    # í†µí•© í”„ë¡œì„¸ì„œ
    processor = PanoLLaVAProcessor(
        img_proc=img_proc,
        max_length=config['max_text_length']
    )
    
    print(f"âœ… í”„ë¡œì„¸ì„œ ì¤€ë¹„ ì™„ë£Œ")
    print(f"   - ì´ë¯¸ì§€ í¬ê¸°: {config['image_size']}")
    print(f"   - í¬ë¡­ ì „ëµ: {config['crop_strategy']}")
    print(f"   - ë·° ê°œìˆ˜: {img_proc.num_views}")
    print(f"   - í† í¬ë‚˜ì´ì €: {config['language_model']}")
    
    return processor, tokenizer

def analyze_dataset_info(csv_path):
    """ë°ì´í„°ì…‹ ê¸°ë³¸ ì •ë³´ ë¶„ì„"""
    print("\nğŸ“Š ë°ì´í„°ì…‹ ê¸°ë³¸ ì •ë³´:")
    
    df = pd.read_csv(csv_path)
    print(f"   - ì´ ìƒ˜í”Œ ìˆ˜: {len(df)}")
    print(f"   - ì»¬ëŸ¼: {list(df.columns)}")
    
    # ê° ì»¬ëŸ¼ í†µê³„
    for col in df.columns:
        if col == 'url':
            print(f"   - {col}: ì´ë¯¸ì§€ ê²½ë¡œ ({df[col].nunique()}ê°œ ê³ ìœ  ê²½ë¡œ)")
        elif col == 'query':
            avg_len = df[col].str.len().mean()
            print(f"   - {col}: í‰ê·  ê¸¸ì´ {avg_len:.1f}ì")
        elif col == 'annotation':
            avg_len = df[col].str.len().mean()
            null_count = df[col].isnull().sum()
            print(f"   - {col}: í‰ê·  ê¸¸ì´ {avg_len:.1f}ì, ê²°ì¸¡ê°’ {null_count}ê°œ")
    
    return df

def create_datasets(csv_path, processor, tokenizer):
    """Train/Eval ëª¨ë“œ ë°ì´í„°ì…‹ ìƒì„±"""
    print("\nğŸ—ï¸  ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
    
    # Train ëª¨ë“œ ë°ì´í„°ì…‹
    train_dataset = ChatPanoDataset(
        csv_path=csv_path,
        processor=processor,
        tokenizer=tokenizer,
        mode="train",
        include_reference=True
    )
    
    # Eval ëª¨ë“œ ë°ì´í„°ì…‹
    eval_dataset = ChatPanoDataset(
        csv_path=csv_path,
        processor=processor,
        tokenizer=tokenizer,
        mode="eval",
        include_reference=True
    )
    
    print(f"âœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ")
    print(f"   - Train ìƒ˜í”Œ: {len(train_dataset)}")
    print(f"   - Eval ìƒ˜í”Œ: {len(eval_dataset)}")
    
    return train_dataset, eval_dataset

def visualize_single_sample(dataset, sample_idx=0, mode_name=""):
    """ë‹¨ì¼ ìƒ˜í”Œ ìƒì„¸ ë¶„ì„"""
    print(f"\nğŸ” {mode_name} ëª¨ë“œ ìƒ˜í”Œ #{sample_idx} ë¶„ì„:")
    
    try:
        sample = dataset[sample_idx]
        
        # ê¸°ë³¸ ì •ë³´
        print(f"   - ì´ë¯¸ì§€ ê²½ë¡œ: {sample.get('image_path', 'N/A')}")
        print(f"   - ìƒ˜í”Œ ID: {sample.get('sample_id', 'N/A')}")
        
        # í…ì„œ ì •ë³´
        if 'pixel_values' in sample:
            pv_shape = sample['pixel_values'].shape
            print(f"   - ì´ë¯¸ì§€ í…ì„œ: {pv_shape}")
            print(f"     * ë·° ìˆ˜: {pv_shape[0] if len(pv_shape) >= 4 else 'N/A'}")
            print(f"     * ì±„ë„: {pv_shape[-3] if len(pv_shape) >= 3 else 'N/A'}")
            print(f"     * í¬ê¸°: {pv_shape[-2:] if len(pv_shape) >= 2 else 'N/A'}")
        
        # í…ìŠ¤íŠ¸ ì •ë³´
        if 'input_ids' in sample:
            input_len = sample['input_ids'].shape[-1]
            print(f"   - ì…ë ¥ í† í° ê¸¸ì´: {input_len}")
            
            # í† í° ë””ì½”ë”© (ì²˜ìŒ 50ê°œì™€ ë§ˆì§€ë§‰ 20ê°œë§Œ)
            input_ids = sample['input_ids']
            if input_ids.dim() > 1:
                input_ids = input_ids.squeeze(0)
            
            # ì „ì²´ í…ìŠ¤íŠ¸ ë””ì½”ë”©
            try:
                decoded_text = dataset.tokenizer.decode(input_ids, skip_special_tokens=False)
                print(f"   - ì…ë ¥ í…ìŠ¤íŠ¸ : {decoded_text[:]}")
                
                # íŠ¹ìˆ˜ í† í° ë¶„ì„
                special_tokens = []
                for token_id in input_ids[:].tolist():  # ì²« 20ê°œ í† í°ë§Œ
                    token = dataset.tokenizer.decode([token_id])
                    if token in dataset.tokenizer.special_tokens_map.values():
                        special_tokens.append(f"'{token}'")
                
                if special_tokens:
                    print(f"   - íŠ¹ìˆ˜ í† í°: {', '.join(special_tokens)}")
                
            except Exception as e:
                print(f"   - í…ìŠ¤íŠ¸ ë””ì½”ë”© ì˜¤ë¥˜: {e}")
        
        # ë¼ë²¨ ì •ë³´
        if 'labels' in sample and sample['labels'] is not None:
            labels = sample['labels']
            if labels.dim() > 1:
                labels = labels.squeeze(0)
            
            # IGNORE_INDEXê°€ ì•„ë‹Œ ë¼ë²¨ë§Œ ê³„ì‚°
            valid_labels = labels[labels != dataset.IGNORE_INDEX]
            print(f"   - ë¼ë²¨ ê¸¸ì´: {len(labels)} (ìœ íš¨: {len(valid_labels)})")
            
            if len(valid_labels) > 0:
                try:
                    # ìœ íš¨í•œ ë¼ë²¨ë§Œ ë””ì½”ë”©
                    decoded_labels = dataset.tokenizer.decode(valid_labels, skip_special_tokens=False)
                    print(f"   - ë¼ë²¨ í…ìŠ¤íŠ¸: {decoded_labels[:]}")
                except Exception as e:
                    print(f"   - ë¼ë²¨ ë””ì½”ë”© ì˜¤ë¥˜: {e}")
        else:
            print(f"   - ë¼ë²¨: ì—†ìŒ (mode={dataset.mode})")
        
        # ì°¸ì¡° í…ìŠ¤íŠ¸
        if 'reference' in sample:
            ref_text = sample['reference']
            if ref_text:
                print(f"   - ì°¸ì¡° í…ìŠ¤íŠ¸: {ref_text[:]}")
            else:
                print(f"   - ì°¸ì¡° í…ìŠ¤íŠ¸: ì—†ìŒ")
        
        # í¬ë§·íŒ…ëœ ì…ë ¥ í…ìŠ¤íŠ¸
        if 'input_text' in sample:
            input_text = sample['input_text']
            print(f"   - í¬ë§·íŒ…ëœ ì…ë ¥: {input_text[:]}")
        
        return sample
        
    except Exception as e:
        print(f"âŒ ìƒ˜í”Œ {sample_idx} ë¶„ì„ ì˜¤ë¥˜: {e}")
        return None

def visualize_batch(dataloader, mode_name="", max_samples=2):
    """ë°°ì¹˜ ë¶„ì„ ë° ì‹œê°í™”"""
    print(f"\nğŸ“¦ {mode_name} ëª¨ë“œ ë°°ì¹˜ ë¶„ì„:")
    
    try:
        # ì²« ë²ˆì§¸ ë°°ì¹˜ ê°€ì ¸ì˜¤ê¸°
        batch = next(iter(dataloader))
        
        # ë°°ì¹˜ ê¸°ë³¸ ì •ë³´
        batch_size = len(batch.get('input_ids', []))
        print(f"   - ë°°ì¹˜ í¬ê¸°: {batch_size}")
        print(f"   - ë°°ì¹˜ í‚¤: {list(batch.keys())}")
        
        # ê° í‚¤ë³„ ìƒì„¸ ì •ë³´
        for key, value in batch.items():
            if isinstance(value, torch.Tensor):
                print(f"   - {key}: {value.shape} ({value.dtype})")
            elif isinstance(value, list):
                print(f"   - {key}: ë¦¬ìŠ¤íŠ¸ (ê¸¸ì´: {len(value)})")
                if value and isinstance(value[0], str):
                    # ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ê¸¸ì´ ì •ë³´
                    lengths = [len(s) for s in value]
                    print(f"     * ë¬¸ìì—´ ê¸¸ì´: {lengths}")
            else:
                print(f"   - {key}: {type(value)}")
        
        # ê°œë³„ ìƒ˜í”Œ ë¶„ì„ (ìµœëŒ€ max_samplesê°œ)
        for i in range(min(batch_size, max_samples)):
            print(f"\n   ğŸ“‹ ë°°ì¹˜ ë‚´ ìƒ˜í”Œ #{i}:")
            
            # í…ìŠ¤íŠ¸ ê´€ë ¨
            if 'input_text' in batch:
                text = batch['input_text'][i] if i < len(batch['input_text']) else 'N/A'
                print(f"      - ì…ë ¥ í…ìŠ¤íŠ¸: {text[:]}")
            
            if 'reference' in batch:
                ref = batch['reference'][i] if i < len(batch['reference']) else 'N/A'
                if ref:
                    print(f"      - ì°¸ì¡° í…ìŠ¤íŠ¸: {ref[:]}")
                else:
                    print(f"      - ì°¸ì¡° í…ìŠ¤íŠ¸: ì—†ìŒ")
            
            # í† í° ê¸¸ì´
            if 'input_ids' in batch and isinstance(batch['input_ids'], torch.Tensor):
                token_len = batch['input_ids'][i].shape[-1] if i < batch['input_ids'].shape[0] else 0
                print(f"      - í† í° ê¸¸ì´: {token_len}")
                
                # ìœ íš¨í•œ í† í° ê°œìˆ˜ (íŒ¨ë”© ì œì™¸)
                if 'attention_mask' in batch and isinstance(batch['attention_mask'], torch.Tensor):
                    valid_tokens = batch['attention_mask'][i].sum().item() if i < batch['attention_mask'].shape[0] else 0
                    print(f"      - ìœ íš¨ í† í°: {valid_tokens}")
            
            # ë¼ë²¨ ì •ë³´
            if 'labels' in batch and batch['labels'] is not None:
                if isinstance(batch['labels'], torch.Tensor) and i < batch['labels'].shape[0]:
                    labels = batch['labels'][i]
                    valid_labels = (labels != -100).sum().item()
                    print(f"      - ìœ íš¨ ë¼ë²¨: {valid_labels}")
            
            # ì´ë¯¸ì§€ ì •ë³´
            if 'pixel_values' in batch and isinstance(batch['pixel_values'], torch.Tensor):
                if i < batch['pixel_values'].shape[0]:
                    img_shape = batch['pixel_values'][i].shape
                    print(f"      - ì´ë¯¸ì§€ shape: {img_shape}")
        
        return batch
        
    except Exception as e:
        print(f"âŒ ë°°ì¹˜ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return None

def create_visualization_plot(train_sample, eval_sample, train_batch, eval_batch):
    """ì‹œê°í™” í”Œë¡¯ ìƒì„±"""
    print(f"\nğŸ¨ ì‹œê°í™” ìƒì„± ì¤‘...")
    
    try:
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('ChatPanoDataset ë°°ì¹˜ ë¶„ì„', fontsize=16, fontweight='bold')
        
        # 1. ì´ë¯¸ì§€ ë·° ì‹œê°í™” (Train)
        ax = axes[0, 0]
        if train_sample and 'pixel_values' in train_sample:
            pv = train_sample['pixel_values']
            if pv.shape[0] > 0:  # ì²« ë²ˆì§¸ ë·° í‘œì‹œ
                img_tensor = pv[0]  # (C, H, W)
                # ì •ê·œí™” í•´ì œ (ëŒ€ëµì )
                img_np = img_tensor.permute(1, 2, 0).numpy()
                img_np = np.clip(img_np * 0.229 + 0.485, 0, 1)  # ëŒ€ëµì  ì—­ì •ê·œí™”
                ax.imshow(img_np)
                ax.set_title(f'Train - ì²« ë²ˆì§¸ ë·°\n{img_tensor.shape}')
        ax.axis('off')
        
        # 2. ì´ë¯¸ì§€ ë·° ì‹œê°í™” (Eval)
        ax = axes[0, 1]
        if eval_sample and 'pixel_values' in eval_sample:
            pv = eval_sample['pixel_values']
            if pv.shape[0] > 0:
                img_tensor = pv[0]
                img_np = img_tensor.permute(1, 2, 0).numpy()
                img_np = np.clip(img_np * 0.229 + 0.485, 0, 1)
                ax.imshow(img_np)
                ax.set_title(f'Eval - ì²« ë²ˆì§¸ ë·°\n{img_tensor.shape}')
        ax.axis('off')
        
        # 3. í…ìŠ¤íŠ¸ ê¸¸ì´ ë¹„êµ
        ax = axes[0, 2]
        modes = ['Train', 'Eval']
        input_lengths = []
        label_lengths = []
        
        for sample in [train_sample, eval_sample]:
            if sample:
                # Input ê¸¸ì´
                if 'input_ids' in sample:
                    input_len = sample['input_ids'].shape[-1]
                    input_lengths.append(input_len)
                else:
                    input_lengths.append(0)
                
                # Label ê¸¸ì´ (ìœ íš¨í•œ ê²ƒë§Œ)
                if 'labels' in sample and sample['labels'] is not None:
                    labels = sample['labels']
                    if labels.dim() > 1:
                        labels = labels.squeeze(0)
                    valid_labels = (labels != -100).sum().item()
                    label_lengths.append(valid_labels)
                else:
                    label_lengths.append(0)
            else:
                input_lengths.append(0)
                label_lengths.append(0)
        
        x = np.arange(len(modes))
        width = 0.35
        ax.bar(x - width/2, input_lengths, width, label='Input í† í°', alpha=0.8)
        ax.bar(x + width/2, label_lengths, width, label='Label í† í°', alpha=0.8)
        ax.set_xlabel('ëª¨ë“œ')
        ax.set_ylabel('í† í° ìˆ˜')
        ax.set_title('í† í° ê¸¸ì´ ë¹„êµ')
        ax.set_xticks(x)
        ax.set_xticklabels(modes)
        ax.legend()
        ax.grid(axis='y', alpha=0.3)
        
        # 4. ë°°ì¹˜ í¬ê¸° ë¹„êµ
        ax = axes[1, 0]
        batch_info = []
        batch_names = ['Train Batch', 'Eval Batch']
        
        for batch in [train_batch, eval_batch]:
            if batch and 'input_ids' in batch:
                batch_size = batch['input_ids'].shape[0] if isinstance(batch['input_ids'], torch.Tensor) else len(batch['input_ids'])
                seq_len = batch['input_ids'].shape[1] if isinstance(batch['input_ids'], torch.Tensor) else 0
                batch_info.append((batch_size, seq_len))
            else:
                batch_info.append((0, 0))
        
        batch_sizes = [info[0] for info in batch_info]
        seq_lens = [info[1] for info in batch_info]
        
        x = np.arange(len(batch_names))
        ax.bar(x, batch_sizes, alpha=0.8, color='skyblue')
        ax.set_xlabel('ë°°ì¹˜')
        ax.set_ylabel('ë°°ì¹˜ í¬ê¸°')
        ax.set_title('ë°°ì¹˜ í¬ê¸°')
        ax.set_xticks(x)
        ax.set_xticklabels(batch_names)
        
        # ë°°ì¹˜ í¬ê¸°ë¥¼ ë§‰ëŒ€ ìœ„ì— í‘œì‹œ
        for i, v in enumerate(batch_sizes):
            ax.text(i, v + 0.1, str(v), ha='center', va='bottom')
        
        # 5. ì‹œí€€ìŠ¤ ê¸¸ì´
        ax = axes[1, 1]
        ax.bar(x, seq_lens, alpha=0.8, color='lightcoral')
        ax.set_xlabel('ë°°ì¹˜')
        ax.set_ylabel('ì‹œí€€ìŠ¤ ê¸¸ì´')
        ax.set_title('ì‹œí€€ìŠ¤ ê¸¸ì´')
        ax.set_xticks(x)
        ax.set_xticklabels(batch_names)
        
        for i, v in enumerate(seq_lens):
            ax.text(i, v + 5, str(v), ha='center', va='bottom')
        
        # 6. ë°ì´í„° êµ¬ì„± ìš”ì•½
        ax = axes[1, 2]
        ax.axis('off')
        
        # í…ìŠ¤íŠ¸ ìš”ì•½ ì •ë³´
        summary_text = "ğŸ“Š ë°ì´í„°ì…‹ êµ¬ì„± ìš”ì•½\n\n"
        
        if train_sample:
            summary_text += "ğŸ”¹ Train ëª¨ë“œ:\n"
            summary_text += f"  â€¢ Labels: {'ìˆìŒ' if 'labels' in train_sample and train_sample['labels'] is not None else 'ì—†ìŒ'}\n"
            summary_text += f"  â€¢ Reference: {'ìˆìŒ' if 'reference' in train_sample and train_sample['reference'] else 'ì—†ìŒ'}\n"
            summary_text += f"  â€¢ ì´ë¯¸ì§€ ë·°: {train_sample['pixel_values'].shape[0] if 'pixel_values' in train_sample else 0}ê°œ\n\n"
        
        if eval_sample:
            summary_text += "ğŸ”¹ Eval ëª¨ë“œ:\n"
            summary_text += f"  â€¢ Labels: {'ìˆìŒ' if 'labels' in eval_sample and eval_sample['labels'] is not None else 'ì—†ìŒ'}\n"
            summary_text += f"  â€¢ Reference: {'ìˆìŒ' if 'reference' in eval_sample and eval_sample['reference'] else 'ì—†ìŒ'}\n"
            summary_text += f"  â€¢ ì´ë¯¸ì§€ ë·°: {eval_sample['pixel_values'].shape[0] if 'pixel_values' in eval_sample else 0}ê°œ\n\n"
        
        summary_text += "ğŸ”¹ ì£¼ìš” ì°¨ì´ì :\n"
        summary_text += "  â€¢ Train: í•™ìŠµìš© ë¼ë²¨ í¬í•¨\n"
        summary_text += "  â€¢ Eval: ìƒì„±ìš©, ë¼ë²¨ ì œì™¸\n"
        summary_text += "  â€¢ ë‘˜ ë‹¤: ì°¸ì¡° í…ìŠ¤íŠ¸ ì œê³µ"
        
        ax.text(0.05, 0.95, summary_text, transform=ax.transAxes, 
               fontsize=10, verticalalignment='top', fontfamily='monospace',
               bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgray", alpha=0.8))
        
        plt.tight_layout()
        
        # ì €ì¥
        output_path = "/data/1_personal/4_SWWOO/panollava/dataset_batch_analysis.png"
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        print(f"âœ… ì‹œê°í™” ì €ì¥ë¨: {output_path}")
        
        plt.show()
        
    except Exception as e:
        print(f"âŒ ì‹œê°í™” ì˜¤ë¥˜: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # 1. í™˜ê²½ ì„¤ì •
        config = setup_test_environment()
        
        # 2. ë°ì´í„°ì…‹ ì •ë³´ ë¶„ì„
        df_info = analyze_dataset_info(config['csv_path'])
        
        # 3. í”„ë¡œì„¸ì„œ ìƒì„±
        processor, tokenizer = create_processors(config)
        
        # 4. ë°ì´í„°ì…‹ ìƒì„±
        train_dataset, eval_dataset = create_datasets(
            config['csv_path'], processor, tokenizer
        )
        
        # 5. ë‹¨ì¼ ìƒ˜í”Œ ë¶„ì„
        train_sample = visualize_single_sample(train_dataset, 0, "Train")
        eval_sample = visualize_single_sample(eval_dataset, 0, "Eval")
        
        # 6. DataLoader ìƒì„±
        train_loader = DataLoader(
            train_dataset, 
            batch_size=config['batch_size'], 
            collate_fn=custom_collate_fn,
            shuffle=False  # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ìˆœì„œ ê³ ì •
        )
        
        eval_loader = DataLoader(
            eval_dataset, 
            batch_size=config['batch_size'], 
            collate_fn=custom_collate_fn,
            shuffle=False
        )
        
        # 7. ë°°ì¹˜ ë¶„ì„
        train_batch = visualize_batch(train_loader, "Train", max_samples=config['batch_size'])
        eval_batch = visualize_batch(eval_loader, "Eval", max_samples=config['batch_size'])
        
        # 8. ì‹œê°í™” ìƒì„±
        create_visualization_plot(train_sample, eval_sample, train_batch, eval_batch)
        
        # 9. ìš”ì•½ ë¦¬í¬íŠ¸
        print("\n" + "="*80)
        print("ğŸ“‹ ìµœì¢… ìš”ì•½ ë¦¬í¬íŠ¸")
        print("="*80)
        print(f"âœ… Train ë°ì´í„°ì…‹: {len(train_dataset)} ìƒ˜í”Œ")
        print(f"âœ… Eval ë°ì´í„°ì…‹: {len(eval_dataset)} ìƒ˜í”Œ")
        print(f"âœ… ë°°ì¹˜ í¬ê¸°: {config['batch_size']}")
        print(f"âœ… ì´ë¯¸ì§€ ë·° ìˆ˜: {processor.img_proc.num_views}")
        print(f"âœ… ìµœëŒ€ í† í° ê¸¸ì´: {config['max_text_length']}")
        
        if train_sample:
            print(f"âœ… Train ìƒ˜í”Œ êµ¬ì„±: ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ + ë¼ë²¨")
        if eval_sample:
            print(f"âœ… Eval ìƒ˜í”Œ êµ¬ì„±: ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ (ë¼ë²¨ ì—†ìŒ)")
        
        print("\nğŸ¯ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
