#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Extract Metadata from Checkpoint
================================

ì²´í¬í¬ì¸íŠ¸ íŒŒì¼(.ckpt)ì—ì„œ `hyper_parameters`ë¥¼ ì¶”ì¶œí•˜ì—¬ 
ê°™ì€ ë””ë ‰í† ë¦¬ì— `checkpoint_metadata.json`ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python scripts/extract_metadata.py --checkpoint runs/.../last.ckpt
"""

import argparse
import torch
import json
import os
from pathlib import Path
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def convert_to_serializable(obj):
    """JSON ì§ë ¬í™”ë¥¼ ìœ„í•´ íƒ€ì…ì„ ë³€í™˜í•©ë‹ˆë‹¤."""
    if isinstance(obj, (torch.Tensor,)):
        return obj.item() if obj.numel() == 1 else obj.tolist()
    elif isinstance(obj, (set, tuple)):
        return list(obj)
    elif isinstance(obj, Path):
        return str(obj)
    return obj

def extract_metadata(ckpt_path: Path):
    if not ckpt_path.exists():
        logger.error(f"âŒ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ckpt_path}")
        return

    logger.info(f"ğŸ“‚ Loading checkpoint: {ckpt_path}")
    try:
        # CPUë¡œ ë¡œë“œí•˜ì—¬ ë©”ëª¨ë¦¬ ì ˆì•½
        ckpt = torch.load(ckpt_path, map_location='cpu')
        
        if 'hyper_parameters' not in ckpt:
            logger.warning(f"âš ï¸ 'hyper_parameters' key not found in {ckpt_path.name}")
            return

        hparams = ckpt['hyper_parameters']
        logger.info(f"âœ… Extracted {len(hparams)} hyperparameters")

        # ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        serializable_hparams = {k: convert_to_serializable(v) for k, v in hparams.items()}

        # êµ¬ì¡°í™”ëœ ë©”íƒ€ë°ì´í„° ìƒì„±
        # eval.pyê°€ ê¸°ëŒ€í•˜ëŠ” êµ¬ì¡°ì— ë§ì¶°ì„œ ë§¤í•‘
        metadata = {
            "source_checkpoint": str(ckpt_path.name),
            "experiment_name": serializable_hparams.get("experiment_name", "unknown"),
            "stage": serializable_hparams.get("stage", "unknown"),
            "model_config": {
                "vision_name": serializable_hparams.get("vision_name"),
                "language_model_name": serializable_hparams.get("language_model_name"),
                "resampler_type": serializable_hparams.get("resampler_type"),
                "latent_dimension": serializable_hparams.get("latent_dimension"),
                "image_size": serializable_hparams.get("image_size"),
            },
            "training_config": {
                "crop_strategy": serializable_hparams.get("crop_strategy"),
                "fov_deg": serializable_hparams.get("fov_deg"),
                "overlap_ratio": serializable_hparams.get("model_overlap_ratio"), # ì´ë¦„ ì°¨ì´ ì£¼ì˜
                "use_vision_processor": serializable_hparams.get("use_vision_processor", True),
                "normalize": serializable_hparams.get("normalize", True),
            },
            # ì›ë³¸ ë°ì´í„°ë„ í¬í•¨ (ë””ë²„ê¹…ìš©)
            "raw_hyper_parameters": serializable_hparams
        }
        
        # ì¼ë¶€ í•„ìˆ˜ í•„ë“œ ê¸°ë³¸ê°’ ì±„ìš°ê¸° (Noneì¸ ê²½ìš°)
        if metadata["training_config"]["overlap_ratio"] is None:
             metadata["training_config"]["overlap_ratio"] = serializable_hparams.get("overlap_ratio", 0.5)
        
        # FOV ë° Crop Strategy ê¸°ë³¸ê°’ ì•ˆì „ì¥ì¹˜
        logger.info(f"   [DEBUG] Before defaults - fov_deg: {metadata['training_config']['fov_deg']}, crop_strategy: {metadata['training_config']['crop_strategy']}")
        
        if metadata["training_config"]["fov_deg"] is None:
             metadata["training_config"]["fov_deg"] = 90.0
             logger.info("   [DEBUG] Applied default fov_deg=90.0")
             
        if metadata["training_config"]["crop_strategy"] is None:
             metadata["training_config"]["crop_strategy"] = "e2p"
             logger.info("   [DEBUG] Applied default crop_strategy='e2p'")

        # ì €ì¥ ê²½ë¡œ: ì²´í¬í¬ì¸íŠ¸ì™€ ê°™ì€ ë””ë ‰í† ë¦¬
        output_path = ckpt_path.parent / "checkpoint_metadata.json"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
            
        logger.info(f"ğŸ’¾ Saved metadata to: {output_path}")
        logger.info(f"   - Resampler: {metadata['model_config']['resampler_type']}")
        logger.info(f"   - Latent Dim: {metadata['model_config']['latent_dimension']}")
        
    except Exception as e:
        logger.error(f"âŒ Failed to extract metadata: {e}")

def main():
    parser = argparse.ArgumentParser(description="Extract hyperparameters from checkpoint")
    parser.add_argument('--checkpoint', type=str, required=True, help='Path to .ckpt file')
    args = parser.parse_args()

    extract_metadata(Path(args.checkpoint))

if __name__ == "__main__":
    main()
